<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 28]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [PBFD and PDFD: Formally Defined and Verified Methodologies and Empirical Evaluation for Scalable Full-Stack Software Engineering](https://arxiv.org/abs/2510.00002)
*Dong Liu*

Main category: cs.SE

TL;DR: This paper presents two formally verified software development methodologies, PBFD and PDFD, that use advanced graph and state machine models to enforce structural correctness and scalability in industrial settings. With the novel Three-Level Encapsulation for fast hierarchical data management, PBFD has shown dramatic performance improvements in real-world enterprise deployment. Both approaches are supported by public tools and datasets to enable transparent academic and commercial use.


<details>
  <summary>Details</summary>
Motivation: There is a longstanding disconnect between formal methods and practical, scalable software engineering in industry. Existing graph-based methodologies lack rigorous enforcement of correctness in real-world scenarios and do not scale efficiently.

Method: The paper introduces Primary Breadth-First Development (PBFD) and Primary Depth-First Development (PDFD), two methodologies for full-stack software engineering, using layered directed graphs, unified state machines, and Communicating Sequential Processes (CSP) for formal modeling. Additionally, it proposes Three-Level Encapsulation (TLE), a bitmask-based encoding scheme for constant-time hierarchical data updates.

Result: PBFD achieved over 20 times faster development and 7-8 times faster query performance compared to popular industry alternatives, as validated through an eight-year enterprise use. Both PBFD and PDFD were implemented as open-source MVPs, and PDFD's implementation validated its correctness-first approach.

Conclusion: PBFD and PDFD present rigorously defined, formally verified, and scalable methodologies for full-stack software engineering, successfully bridging the gap between formal methods and practical development. Their formal specifications and open-source tools demonstrate both improved speed and structural correctness, supporting academic and industrial adoption.

Abstract: This paper introduces Primary Breadth-First Development (PBFD) and Primary
Depth-First Development (PDFD), two formally defined and verified methodologies
for scalable, industrial-grade full-stack software engineering. These
approaches bridge a longstanding gap between formal methods and real-world
development practice by enforcing structural correctness through
graph-theoretic modeling. Unlike prior graph-based approaches, PBFD and PDFD
operate over layered directed graphs and are formalized using unified state
machines and Communicating Sequential Processes (CSP) to ensure critical
properties, including bounded-refinement termination and structural
completeness. To coordinate hierarchical data at scale, we propose Three-Level
Encapsulation (TLE) - a novel, bitmask-based encoding scheme that delivers
provably constant-time updates. TLE's formal guarantees underpin PBFD's
industrial-scale performance and scalability. PBFD was empirically validated
through an eight-year enterprise deployment, demonstrating over 20x faster
development than Salesforce OmniScript and 7-8x faster query performance
compared to conventional relational models. Additionally, both methodologies
are supported by open-source MVPs, with PDFD's implementation conclusively
demonstrating its correctness-first design principles. Together, PBFD and PDFD
establish a reproducible, transparent framework that integrates formal
verification into practical software development. All formal specifications,
MVPs, and datasets are publicly available to foster academic research and
industrial-grade adoption.

</details>


### [2] [Semantic Zoom and Mini-Maps for Software Cities](https://arxiv.org/abs/2510.00003)
*Malte Hansen,Jens Bamberg,Noe Baumann,Wilhelm Hasselbring*

Main category: cs.SE

TL;DR: The paper improves visual scalability in 3D software city visualizations using semantic zoom and a mini-map, both proven useful in user studies. These features make it easier to navigate and understand large software systems, though further improvements are necessary.


<details>
  <summary>Details</summary>
Motivation: As visualizations for software architectures become larger and more complex, it's increasingly difficult for developers to comprehend them. There's a need for improved visual scalability so that both small and large amounts of data can be effectively displayed and understood.

Method: The paper presents two main methodological approaches: (1) semantic zoom, where the graphical representation dynamically changes with the camera's distance to objects; and (2) a 2D mini-map offering a top-down overview. These were implemented in a web-based tool called ExplorViz and evaluated via two user studies.

Result: The user studies demonstrated that both semantic zoom and mini-map are useful for navigating and comprehending large software visualizations. They received positive feedback, especially for use with large landscapes and collaborative tasks. Some implementation shortcomings were also identified for future improvement.

Conclusion: Semantic zoom and mini-map features significantly enhance the usability and scalability of 3D software visualization tools, supporting better program comprehension. The approaches are practical and well-received, though future refinements are needed.

Abstract: Software visualization tools can facilitate program comprehension by
providing visual metaphors, or abstractions that reduce the amount of textual
data that needs to be processed mentally. One way they do this is by enabling
developers to build an internal representation of the visualized software and
its architecture. However, as the amount of displayed data in the visualization
increases, the visualization itself can become more difficult to comprehend.
The ability to display small and large amounts of data in visualizations is
called visual scalability.
  In this paper, we present two approaches to address the challenge of visual
scalability in 3D software cities. First, we present an approach to semantic
zoom, in which the graphical representation of the software landscape changes
based on the virtual camera's distance from visual objects. Second, we augment
the visualization with a miniature two-dimensional top-view projection called
mini-map. We demonstrate our approach using an open-source implementation in
our software visualization tool ExplorViz. ExplorViz is web-based and uses the
3D city metaphor, focusing on live trace visualization.
  We evaluated our approaches in two separate user studies. The results
indicate that semantic zoom and the mini-map are both useful additions. User
feedback indicates that semantic zoom and mini-maps are especially useful for
large software landscapes and collaborative software exploration. The studies
indicate a good usability of our implemented approaches. However, some
shortcomings in our implementations have also been discovered, to be addressed
in future work.
  Video URL: https://youtu.be/LYtUeWvizjU

</details>


### [3] [HTML Structure Exploration in 3D Software Cities](https://arxiv.org/abs/2510.00004)
*Malte Hansen,David Moreno-Lumbreras,Wilhelm Hasselbring*

Main category: cs.SE

TL;DR: The paper improves the ExplorViz tool by integrating web interface visualization directly into 3D software analysis. Through a user study, it demonstrates benefits and shortcomings, suggesting future research to further support web interface exploration in software visualization.


<details>
  <summary>Details</summary>
Motivation: Existing software visualization tools typically exclude web interfaces, which are common in large software systems. There's a need to bridge this gap to facilitate better understanding and exploration of systems via their web interfaces.

Method: The paper extends ExplorViz, a web-based live tracing software visualization tool, by adding an embedded web view and a 3D visualization of the Document Object Model (DOM) for instrumented applications. This enables interaction with web interfaces and visual exploration of HTML content in same-origin contexts. A preliminary user study is performed to evaluate the approach.

Result: The user study provides insights into how the enhanced tool can be used, its benefits, and its shortcomings. It identifies potential use cases and areas for further development in the visual exploration of web interfaces and joint visualization of software cities and HTML structure.

Conclusion: Visualizing web interfaces within software visualization tools like ExplorViz enhances user interaction and aids in understanding software systems. There remains scope for improving the visualization and exploring further use cases based on user feedback.

Abstract: Software visualization, which uses data from dynamic program analysis, can
help to explore and understand the behavior of software systems. It is common
that large software systems offer a web interface for user interaction.
Usually, available web interfaces are not regarded in software visualization
tools. This paper introduces additions to the web-based live tracing software
visualization tool ExplorViz: We add an embedded web view for instrumented
applications in the 3D visualization to ease interaction with the given
applications and enable the exploration of the thereby displayed HTML content.
Namely, the Document Object Model (DOM) is visualized via a three-dimensional
representation of the HTML structure in same-origin contexts.
  Our visualization approach is evaluated in a preliminary user study. The
study results give insights into the potential use cases, benefits, and
shortcomings of our implemented approach. Based on our study results, we
propose directions for further research to support the visual exploration of
web interfaces and explore use cases for the combined visualization of software
cities and HTML structure.
  Video URL: https://youtu.be/wBWKlbvzOOE

</details>


### [4] [VibeCodeHPC: An Agent-Based Iterative Prompting Auto-Tuner for HPC Code Generation Using LLMs](https://arxiv.org/abs/2510.00031)
*Shun-ichiro Hayashi,Koki Morita,Daichi Mukunoki,Tetsuya Hoshino,Takahiro Katagiri*

Main category: cs.SE

TL;DR: VibeCodeHPC automatically tunes HPC code using multi-agent LLMs, assigning distinct roles to maximize collaboration. Tested on CPU-to-GPU code conversion, it yields higher-quality results faster, while its dynamic system improves error detection over using a single agent.


<details>
  <summary>Details</summary>
Motivation: Optimizing HPC programs often requires significant manual effort. Automatic tuning and code generation, especially for heterogeneous systems like CPUs and GPUs, are challenging tasks that could benefit from intelligent automation.

Method: VibeCodeHPC utilizes multi-agent Large Language Models (LLMs), each assigned specific roles—Project Manager, System Engineer, Programmer, and Continuous Delivery. These agents collaborate iteratively, dynamically deploying resources and monitoring their activity to automatically generate and optimize code.

Result: In a case study, VibeCodeHPC successfully converted a CPU-based matrix multiplication code in C to optimized GPU code using CUDA. The multi-agent (collaborative) approach outperformed single-agent setups in both code quality and efficiency. Dynamic agent deployment also improved issue and requirement violation detection.

Conclusion: VibeCodeHPC, by leveraging multi-agent LLM collaboration and dynamic resource management, provides a more effective method for automatic tuning and code generation in HPC compared to traditional or solo-agent approaches.

Abstract: We propose VibeCodeHPC, an automatic tuning system for HPC programs based on
multi-agent LLMs for code generation. VibeCodeHPC tunes programs through
multi-agent role allocation and iterative prompt refinement. We describe the
system configuration with four roles: Project Manager (PM), System Engineer
(SE), Programmer (PG), and Continuous Delivery (CD). We introduce dynamic agent
deployment and activity monitoring functions to facilitate effective
multi-agent collaboration. In our case study, we convert and optimize CPU-based
matrix-matrix multiplication code written in C to GPU code using CUDA. The
multi-agent configuration of VibeCodeHPC achieved higher-quality code
generation per unit time compared to a solo-agent configuration. Additionally,
the dynamic agent deployment and activity monitoring capabilities facilitated
more effective identification of requirement violations and other issues.

</details>


### [5] [A Scalable Framework for Safety Assurance of Self-Driving Vehicles based on Assurance 2.0](https://arxiv.org/abs/2510.00092)
*Shufeng Chen,Mariat James Elizebeth,Robab Aghazadeh Chakherlou,Xingyu Zhao,Eric Barbier,Siddartha Khastgir,Paul Jennings*

Main category: cs.SE

TL;DR: The paper introduces Assurance 2.0, a framework for assuring complex autonomous systems using structured decomposition and adapted models like 5M1E. It enables rigorous and transparent assurance across the development lifecycle, but some challenges like confidence measurement and automation remain.


<details>
  <summary>Details</summary>
Motivation: Modern autonomous systems present complex assurance challenges due to their adaptability and autonomy. Traditional models lack flexibility and rigor when addressing safety and transparency in these systems, motivating the development of a new framework.

Method: The paper builds on the Claims-Argument-Evidence (CAE) model and introduces reusable assurance theories and explicit counterarguments (defeaters). It utilizes a decomposition framework instantiated through a structured template and a three-tiered decomposition strategy. In a case study, the framework is applied to the self-driving vehicle development lifecycle, decomposing it into Requirements Engineering, Verification and Validation, and Post-Deployment phases, and further analyzing each using an adapted 5M1E model.

Result: The decomposition frameworks identify a comprehensive set of safety arguments and measure corresponding evidence for assurance in autonomous system development. The use of the adapted 5M1E model ensures thorough coverage and fine-grained traceability across all stages of the product lifecycle.

Conclusion: Assurance 2.0, with its new decomposition frameworks and adapted 5M1E model, enhances rigor, transparency, and adaptability in assuring complex autonomous systems. However, challenges remain in confidence measurement, doubt management, automation, and the practical handling of defeaters and biases.

Abstract: Assurance 2.0 is a modern framework developed to address the assurance
challenges of increasingly complex, adaptive, and autonomous systems. Building
on the traditional Claims-Argument-Evidence (CAE) model, it introduces reusable
assurance theories and explicit counterarguments (defeaters) to enhance rigor,
transparency, and adaptability. It supports continuous, incremental assurance,
enabling innovation without compromising safety. However, limitations persist
in confidence measurement, residual doubt management, automation support, and
the practical handling of defeaters and confirmation bias. This paper presents
\textcolor{black}{a set of decomposition frameworks to identify a complete set
of safety arguments and measure their corresponding evidence.} Grounded in the
Assurance 2.0 paradigm, the framework is instantiated through a structured
template and employs a three-tiered decomposition strategy. \textcolor{black}{A
case study regarding the application of the decomposition framework in the
end-to-end (E2E) AI-based Self-Driving Vehicle (SDV) development is also
presented in this paper.} At the top level, the SDV development is divided into
three critical phases: Requirements Engineering (RE), Verification and
Validation (VnV), and Post-Deployment (PD). Each phase is further decomposed
according to its Product Development Lifecycle (PDLC). To ensure comprehensive
coverage, each PDLC is analyzed using an adapted 5M1E model (Man, Machine,
Method, Material, Measurement, and Environment). Originally developed for
manufacturing quality control, the 5M1E model is reinterpreted and contextually
mapped to the assurance domain. This enables a multi-dimensional decomposition
that supports fine-grained traceability of safety claims, evidence, and
potential defeaters.

</details>


### [6] [Container Orchestration Patterns for Optimizing Resource Use](https://arxiv.org/abs/2510.00197)
*Diogo Maia,Filipe Correia,André Restivo,Paulo Queiroz*

Main category: cs.SE

TL;DR: The paper addresses the complexity of service orchestration in service-based architectures by identifying and defining three core resource optimization patterns—Preemptive Scheduling, Service Balancing, and Garbage Collection—through analysis of literature and tools. These patterns aim to standardize best practices, improve resource management, and encourage wider industry adoption.


<details>
  <summary>Details</summary>
Motivation: Service orchestration in service-based architectures is challenging, especially for newcomers, due to lack of clarity and standardization in existing resources and practices.

Method: The authors analyzed existing literature and tools to identify and define common orchestration practices.

Result: Three key orchestration resource optimization patterns were identified and defined: Preemptive Scheduling, Service Balancing, and Garbage Collection. Each pattern addresses a distinct optimization challenge in service orchestration.

Conclusion: These foundational patterns can improve orchestration practices and facilitate broader adoption of service-based architectures by providing clear, standardized approaches.

Abstract: Service-based architectures provide substantial benefits, yet service
orchestration remains a challenge, particularly for newcomers. While various
resources on orchestration techniques exist, they often lack clarity and
standardization, making best practices difficult to implement and limiting
their adoption within the software industry.
  To address this gap, we analyzed existing literature and tools to identify
common orchestration practices. Based on our findings, we define three key
orchestration resource optimization patterns: {\sc Preemptive Scheduling}, {\sc
Service Balancing}, and {\sc Garbage Collection}. {\sc Preemptive Scheduling}
allows the allocation of sufficient resources for services of higher priority
in stressful situations, while {\sc Service Balancing} enables a restructuring
of the nodes to allow better resource usage. To end, {\sc Garbage Collection}
creates cleanup mechanisms to better understand the system's resource usage and
optimize it. These patterns serve as foundational elements for improving
orchestration practices and fostering broader adoption in service-based
architectures.

</details>


### [7] [Which Programming Language and Model Work Best With LLM-as-a-Judge For Code Retrieval?](https://arxiv.org/abs/2510.00324)
*Lucas Roberts,Denisa Roberts*

Main category: cs.SE

TL;DR: This paper explores how large language models can automate code search and annotation, reducing reliance on costly human expertise. Key findings highlight the impact of retriever types and programming languages on AI-human agreement in relevance judgments and propose transpilers to expand benchmarks. The proposed techniques can make code search more scalable and effective across various languages.


<details>
  <summary>Details</summary>
Motivation: Code search is crucial for developers but hampered by the high cost and expertise required for annotating search results. Current advancements in natural language search have outpaced code search mainly due to these annotation challenges.

Method: The authors leverage Large Language Models (LLMs) to retrieve code snippets at the function level and automatically generate annotations for search results. They study both sparse and semantic representations and evaluate LLM performance across multiple programming languages using human annotations and LLM-as-a-Judge models. They also propose using transpilers to create scalable code search benchmark datasets for different languages.

Result: The study finds that both the choice of code retriever and programming language affects the alignment between human and AI relevance judgments. Sparse and semantic representations show varying performance across languages. Using transpilers can effectively expand benchmark datasets, and human-AI agreement rates are comparable to human-human agreement rates in the worst case scenario.

Conclusion: LLMs, combined with appropriate retriever representations and transpilers, can significantly improve scalability and relevance alignment in code search tasks across programming languages. This work demonstrates practical and scalable methods for benchmarking and improving code search tools with AI annotation.

Abstract: Code search is an important information retrieval application. Benefits of
better code search include faster new developer on-boarding, reduced software
maintenance, and ease of understanding for large repositories. Despite
improvements in search algorithms and search benchmarks, the domain of code
search has lagged behind. One reason is the high cost of human annotation for
code queries and answers. While humans may annotate search results in general
text QA systems, code annotations require specialized knowledge of a
programming language (PL), as well as domain specific software engineering
knowledge. In this work we study the use of Large Language Models (LLMs) to
retrieve code at the level of functions and to generate annotations for code
search results. We compare the impact of the retriever representation (sparse
vs. semantic), programming language, and LLM by comparing human annotations
across several popular languages (C, Java, Javascript, Go, and Python). We
focus on repositories that implement common data structures likely to be
implemented in any PLs. For the same human annotations, we compare several
LLM-as-a-Judge models to evaluate programming language and other affinities
between LLMs. We find that the chosen retriever and PL exhibit affinities that
can be leveraged to improve alignment of human and AI relevance determinations,
with significant performance implications. We also find differences in
representation (sparse vs. semantic) across PLs that impact alignment of human
and AI relevance determinations. We propose using transpilers to bootstrap
scalable code search benchmark datasets in other PLs and in a case study
demonstrate that human-AI relevance agreement rates largely match the (worst
case) human-human agreement under study. The application code used in this work
is available at \href{https://github.com/rlucas7/code-searcher/}{this github
repo}.

</details>


### [8] [Vibe Coding in Practice: Motivations, Challenges, and a Future Outlook -- a Grey Literature Review](https://arxiv.org/abs/2510.00328)
*Ahmed Fawzy,Amjed Tahir,Kelly Blincoe*

Main category: cs.SE

TL;DR: AI code generation tools enable fast prototyping by non-experts, but users (vibe coders) often overlook code quality assurance, leading to unreliable software. Understanding these practices is crucial to prevent quality crises in AI-driven development.


<details>
  <summary>Details</summary>
Motivation: AI code generation tools have become widely used by novices and non-developers for faster application development, but little is known about users' motivations, experiences, and QA practices.

Method: A systematic grey literature review of 101 practitioner sources, analyzing 518 firsthand accounts of vibe coding practices, challenges, and limitations.

Result: The study reveals that vibe coders prioritize speed and accessibility, leading to quick results but flawed code. Most users neglect QA, often skipping testing or relying solely on the AI's output, resulting in vulnerable software and developers unable to debug issues.

Conclusion: Vibe coding accelerates prototyping and lowers entry barriers but compromises reliability and maintainability, posing risks for software quality and necessitating attention from tool designers and teams.

Abstract: AI code generation tools are transforming software development, especially
for novice and non-software developers, by enabling them to write code and
build applications faster and with little to no human intervention. Vibe coding
is the practice where users rely on AI code generation tools through intuition
and trial-and-error without necessarily understanding the underlying code.
Despite widespread adoption, no research has systematically investigated why
users engage in vibe coding, what they experience while doing so, and how they
approach quality assurance (QA) and perceive the quality of the AI-generated
code. To this end, we conduct a systematic grey literature review of 101
practitioner sources, extracting 518 firsthand behavioral accounts about vibe
coding practices, challenges, and limitations. Our analysis reveals a
speed-quality trade-off paradox, where vibe coders are motivated by speed and
accessibility, often experiencing rapid ``instant success and flow'', yet most
perceive the resulting code as fast but flawed. QA practices are frequently
overlooked, with many skipping testing, relying on the models' or tools'
outputs without modification, or delegating checks back to the AI code
generation tools. This creates a new class of vulnerable software developers,
particularly those who build a product but are unable to debug it when issues
arise. We argue that vibe coding lowers barriers and accelerates prototyping,
but at the cost of reliability and maintainability. These insights carry
implications for tool designers and software development teams. Understanding
how vibe coding is practiced today is crucial for guiding its responsible use
and preventing a broader QA crisis in AI-assisted development.

</details>


### [9] [Beyond Pass/Fail: The Story of Learning-Based Testing](https://arxiv.org/abs/2510.00450)
*Sheikh Md. Mushfiqur Rahman,Nasir Eisty*

Main category: cs.SE

TL;DR: This paper reviews the current state and potential of Learning-Based Testing (LBT), summarizing its theoretical backing, practical applications, and underused value in software testing. The findings suggest that LBT is a promising technique for effective and efficient software testing, with proven benefits in both academia and industry.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this paper is to provide a comprehensive overview of Learning-Based Testing (LBT), a promising approach that combines learning and software testing to improve test coverage and behavioral adequacy, especially for large and complex software systems. As LBT is relatively underutilized and still in its early stages, the authors aim to highlight its development, effectiveness, and potential benefits for researchers and practitioners.

Method: This paper employs a systematic literature review methodology. The authors collect, review, and synthesize existing research, implementations, frameworks, tools, and case studies related to LBT across different types of programs (procedural and reactive). They also evaluate the evolution, state-of-the-art, and industrial application of LBT tools.

Result: The paper presents a detailed synthesis of LBT's theoretical foundations and practical applications. It highlights successful case studies in industrial contexts, confirms LBT's efficacy for commercial software testing, and shows a variety of available tools and frameworks. The review demonstrates LBT's evolution and underexploited potential in the software testing field.

Conclusion: The paper concludes that LBT is a promising and effective approach for comprehensive software testing, especially suitable for complex and large systems. Despite its early development stage, LBT's theoretical and practical evidence suggests significant benefits for both researchers and industry practitioners. The authors encourage further exploration and adoption of LBT to realize its potential in software quality assurance.

Abstract: Learning-Based Testing (LBT) merges learning and testing processes to achieve
both testing and behavioral adequacy. LBT utilizes active learning to infer the
model of the System Under Test (SUT), enabling scalability for large and
complex programs by requiring only a minimal set of initial test cases. The
core principle of LBT is that the SUT's behavior can be thoroughly inferred by
progressively generating test cases and subjecting the SUT to testing, thereby
ensuring comprehensive testing. Despite being in its early stages, LBT has a
solid foundation of theoretical research demonstrating its efficacy in testing
both procedural and reactive programs. This paper provides a systematic
literature review of various LBT implementations across different program types
and evaluates the current state of research in this field. We explore diverse
theoretical frameworks, existing tools, and libraries within the LBT domain to
illustrate the concept's evolution and current research status. Additionally,
we examine case studies involving the application of LBT tools in industrial
settings, highlighting their potential and effectiveness in commercial software
testing. This systematic literature review aims to offer researchers a
comprehensive perspective on the inception and development of LBT, presenting
it as a promising technique in software testing. By unveiling LBT's
underutilized potential, this paper seeks to significantly benefit the
practitioners and research community.

</details>


### [10] [Analyzing Latent Concepts in Code Language Models](https://arxiv.org/abs/2510.00476)
*Arushi Sharma,Vedant Pungliya,Christopher J. Quinn,Ali Jannesari*

Main category: cs.SE

TL;DR: This paper presents a novel interpretability tool, CoCoA, for code-related language models, which organizes internal representations into human-friendly concept clusters, enables better explanations, and shows improved user understanding over traditional attribution techniques.


<details>
  <summary>Details</summary>
Motivation: Interpreting the behaviors of large language models (LLMs) trained on code is difficult, yet essential for ensuring trust, transparency, and robustness in high-stakes applications.

Method: The paper introduces Code Concept Analysis (CoCoA), a global post-hoc interpretability framework. CoCoA clusters contextualized token embeddings into human-interpretable concept groups using a hybrid annotation pipeline that combines static analysis with prompt-engineered LLMs for scalable labeling. It analyzes the distribution of concepts across model layers and fine-tuning tasks, and integrates concept analysis with local attribution methods to ground explanations.

Result: CoCoA identifies stable and interpretable concept clusters related to code structure and semantics, revealing latent model interactions and biases. The framework's concept-augmented explanations improve the coherence and interpretability of token-level saliency, outperforming standard attribution methods (Integrated Gradients) by significantly increasing explainability in user studies.

Conclusion: Code Concept Analysis provides a scalable and effective method for interpreting code LLMs, discovering meaningful semantic and syntactic concepts that persist across perturbations and tasks, and improving human understanding of model predictions.

Abstract: Interpreting the internal behavior of large language models trained on code
remains a critical challenge, particularly for applications demanding trust,
transparency, and semantic robustness. We propose Code Concept Analysis
(CoCoA): a global post-hoc interpretability framework that uncovers emergent
lexical, syntactic, and semantic structures in a code language model's
representation space by clustering contextualized token embeddings into
human-interpretable concept groups. We propose a hybrid annotation pipeline
that combines static analysis tool-based syntactic alignment with
prompt-engineered large language models (LLMs), enabling scalable labeling of
latent concepts across abstraction levels. We analyse the distribution of
concepts across layers and across three finetuning tasks. Emergent concept
clusters can help identify unexpected latent interactions and be used to
identify trends and biases within the model's learned representations. We
further integrate LCA with local attribution methods to produce
concept-grounded explanations, improving the coherence and interpretability of
token-level saliency. Empirical evaluations across multiple models and tasks
show that LCA discovers concepts that remain stable under semantic-preserving
perturbations (average Cluster Sensitivity Index, CSI = 0.288) and evolve
predictably with fine-tuning. In a user study, concept-augmented explanations
disambiguate token roles. In a user study on the programming-language
classification task, concept-augmented explanations disambiguated token roles
and improved human-centric explainability by 37 percentage points compared with
token-level attributions using Integrated Gradients.

</details>


### [11] [CodeChemist: Functional Knowledge Transfer for Low-Resource Code Generation via Test-Time Scaling](https://arxiv.org/abs/2510.00501)
*Kaixin Wang,Tianlin Li,Xiaoyu Zhang,Aishan Liu,Xianglong Liu,Ziqi Liu,Zhiqiang Zhang,Jun Zhou,and Bin Shi*

Main category: cs.SE

TL;DR: CodeChemist transfers knowledge from high-resource to low-resource programming languages at test time by generating test cases and intelligently sampling code, significantly improving CodeLLM code generation for low-resource languages without retraining the model.


<details>
  <summary>Details</summary>
Motivation: CodeLLMs show uneven performance across programming languages, particularly underperforming for low-resource languages due to limited training data. Addressing this discrepancy is crucial for broader applicability of code generation models.

Method: CodeChemist introduces a test-time scaling framework that transfers functional knowledge from high-resource to low-resource languages. It generates and executes code in high-resource languages to create test cases, then uses multi-temperature hedged sampling to generate code in low-resource languages. Code snippets are evaluated based on the pass rate of the test cases, with the best one selected.

Result: Extensive experiments demonstrate that CodeChemist outperforms existing test-time scaling approaches, leading to significant performance improvements in code generation for low-resource programming languages. Importantly, this is achieved without any model retraining.

Conclusion: CodeChemist offers an efficient and effective solution for improving CodeLLM performance in low-resource languages by leveraging functional knowledge transfer from high-resource languages at test time, enhancing code generation without extra training.

Abstract: Code Large Language Models (CodeLLMs) are increasingly used in code
generation tasks across a wide range of applications. However, their
performance is often inconsistent across different programming languages (PLs),
with low-resource PLs suffering the most due to limited training data. In this
paper, we present CodeChemist, a novel and efficient framework for test-time
scaling that enables functional knowledge transfer from high-resource to
low-resource PLs using generated test cases. CodeChemist first generates and
executes code in high-resource PLs to create test cases that encapsulate
functional knowledge. It then uses multi-temperature hedged sampling to
generate code snippets in the low-resource PL and selects the best one based on
the pass rate of the test cases. Our extensive experiments show that
CodeChemist outperforms existing test-time scaling approaches, boosting the
performance of code generation for low-resource PLs without requiring any model
retraining.

</details>


### [12] [Architectural Transformations and Emerging Verification Demands in AI-Enabled Cyber-Physical Systems](https://arxiv.org/abs/2510.00519)
*Hadiza Umar Yusuf,Khouloud Gaaloul*

Main category: cs.SE

TL;DR: This paper highlights how adding AI to CPS changes system structure and verification needs compared to traditional models, emphasizing new complexities and adaptation requirements.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the lack of understanding regarding the effects of integrating AI into CPS, specifically in terms of architecture, operational complexity, and verification practices.

Method: The paper investigates architectural differences between AI-driven and traditional control models, specifically those designed in Simulink. It analyzes how these differences impact system verification.

Result: The study reveals specific distinctions between AI-driven and traditional CPS control architectures and discusses their respective implications for verification.

Conclusion: Integrating AI into CPS significantly alters architectural design and system complexity, necessitating changes in verification approaches.

Abstract: In the world of Cyber-Physical Systems (CPS), a captivating real-time fusion
occurs where digital technology meets the physical world. This synergy has been
significantly transformed by the integration of artificial intelligence (AI), a
move that dramatically enhances system adaptability and introduces a layer of
complexity that impacts CPS control optimization and reliability. Despite
advancements in AI integration, a significant gap remains in understanding how
this shift affects CPS architecture, operational complexity, and verification
practices. The extended abstract addresses this gap by investigating
architectural distinctions between AI-driven and traditional control models
designed in Simulink and their respective implications for system verification.

</details>


### [13] [LSPFuzz: Hunting Bugs in Language Servers](https://arxiv.org/abs/2510.00532)
*Hengcheng Zhu,Songqiang Chen,Valerio Terragni,Lili Wei,Jiarong Wu,Yepang Liu,Shing-Chi Cheung*

Main category: cs.SE

TL;DR: LSPFuzz is a specialized fuzzer that systematically tests LSP servers by mutating both source code and editor actions, uncovering dozens of previously unknown bugs and vulnerabilities. This tool surpasses conventional fuzzers, enhances server reliability, and sets new directions for research in LSP server testing.


<details>
  <summary>Details</summary>
Motivation: The widespread adoption of the Language Server Protocol (LSP) has improved code intelligence integration in modern software development, but the reliability and security of LSP servers remain major concerns. Crashes can disable vital features and vulnerabilities can expose developers to risks, especially when editing untrusted code. Prior to this work, no specific testing techniques targeted LSP server robustness.

Method: The paper introduces LSPFuzz, a grey-box hybrid fuzzer designed specifically for LSP server testing. LSPFuzz employs a two-stage mutation pipeline: first, it applies syntax-aware mutations to source code, and then performs context-aware dispatching of editor operations. This holistic approach effectively tests combinations of code and editor actions that can trigger bugs.

Result: LSPFuzz was evaluated on four popular LSP servers and demonstrated better effectiveness than traditional fuzzers. It discovered 51 previously unknown bugs, of which 42 were confirmed by developers, 26 were fixed, and two were assigned CVE numbers, highlighting the tool's impact on improving LSP server reliability and security.

Conclusion: LSPFuzz provides a practical and effective solution for systematically testing LSP servers. It not only improves code intelligence reliability but also lays a foundation for future research in LSP server quality assurance. The results affirm the value of targeted, holistic mutation-based fuzzing for complex protocol implementations.

Abstract: The Language Server Protocol (LSP) has revolutionized the integration of code
intelligence in modern software development. There are approximately 300 LSP
server implementations for various languages and 50 editors offering LSP
integration. However, the reliability of LSP servers is a growing concern, as
crashes can disable all code intelligence features and significantly impact
productivity, while vulnerabilities can put developers at risk even when
editing untrusted source code. Despite the widespread adoption of LSP, no
existing techniques specifically target LSP server testing. To bridge this gap,
we present LSPFuzz, a grey-box hybrid fuzzer for systematic LSP server testing.
Our key insight is that effective LSP server testing requires holistic mutation
of source code and editor operations, as bugs often manifest from their
combinations. To satisfy the sophisticated constraints of LSP and effectively
explore the input space, we employ a two-stage mutation pipeline: syntax-aware
mutations to source code, followed by context-aware dispatching of editor
operations. We evaluated LSPFuzz on four widely used LSP servers. LSPFuzz
demonstrated superior performance compared to baseline fuzzers, and uncovered
previously unknown bugs in real-world LSP servers. Of the 51 bugs we reported,
42 have been confirmed, 26 have been fixed by developers, and two have been
assigned CVE numbers. Our work advances the quality assurance of LSP servers,
providing both a practical tool and foundational insights for future research
in this domain.

</details>


### [14] [AI-Driven Self-Evolving Software: A Promising Path Toward Software Automation](https://arxiv.org/abs/2510.00591)
*Liyi Cai,Yijie Ren,Yitong Zhang,Jia Li*

Main category: cs.SE

TL;DR: This paper proposes and tests a self-evolving software system powered by AI that autonomously develops and maintains software based on user input. The results show promising scalability and automation, suggesting a path toward fully automated software engineering.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the limitations of current AI-driven software development, which still largely requires explicit human intervention. The authors aim to explore whether AI can move beyond being just an assistant to developers, to become a core, autonomous component of software, enabling true end-to-end automation.

Method: This paper introduces the concept of AI-Driven Self-Evolving Software and demonstrates its feasibility through a prototype. The prototype employs a multi-agent architecture designed to autonomously interpret user requirements, generate and validate code, and integrate new functionalities based on direct user interaction.

Result: The prototype successfully constructs and reuses functionalities across varied scenarios. Case studies indicate the system reliably scales up to more sophisticated applications.

Conclusion: The results provide early evidence that AI-Driven Self-Evolving Software can lead to genuine automated software development, moving AI from an assistant to an integral, autonomous role in software engineering. Publicly sharing code and cases helps further research and validation.

Abstract: Software automation has long been a central goal of software engineering,
striving for software development that proceeds without human intervention.
Recent efforts have leveraged Artificial Intelligence (AI) to advance software
automation with notable progress. However, current AI functions primarily as
assistants to human developers, leaving software development still dependent on
explicit human intervention. This raises a fundamental question: Can AI move
beyond its role as an assistant to become a core component of software, thereby
enabling genuine software automation? To investigate this vision, we introduce
AI-Driven Self-Evolving Software, a new form of software that evolves
continuously through direct interaction with users. We demonstrate the
feasibility of this idea with a lightweight prototype built on a multi-agent
architecture that autonomously interprets user requirements, generates and
validates code, and integrates new functionalities. Case studies across
multiple representative scenarios show that the prototype can reliably
construct and reuse functionality, providing early evidence that such software
systems can scale to more sophisticated applications and pave the way toward
truly automated software development. We make code and cases in this work
publicly available at https://anonymous.4open.science/r/live-software.

</details>


### [15] [PyTrim: A Practical Tool for Reducing Python Dependency Bloat](https://arxiv.org/abs/2510.00674)
*Konstantinos Karakatsanis,Georgios Alexopoulos,Ioannis Karyotakis,Foivos Timotheos Proestakis,Evangelos Talos,Panos Louridas,Dimitris Mitropoulos*

Main category: cs.SE

TL;DR: PYTRIM is an open-source system that automates the removal of unused dependencies from Python projects, achieving high accuracy and practical impact by eliminating manual cleanup, and is ready for community contributions.


<details>
  <summary>Details</summary>
Motivation: Dependency bloat in Python projects leads to higher maintenance costs and security risks, yet removing unused dependencies remains a manual and expertise-intensive process despite the existence of detection tools.

Method: The authors introduce PYTRIM, an automated, end-to-end system that removes unused dependencies—including imports and package declarations—from both source code and configuration files. PYTRIM employs a modular architecture to accept input from any dependency bloat detection tool and uniquely incorporates a dynamic analysis component for better recall.

Result: PYTRIM was evaluated on a dataset of 37 pull requests, achieving 98.3% accuracy in reproducing human changes. In practical use, PYTRIM trimmed dependencies in 39 out of 971 open-source packages, with 6 pull request contributions accepted and merged upstream.

Conclusion: PYTRIM effectively automates the removal of unused dependencies in Python projects, improving accuracy and reducing manual effort, and is openly available for community use and improvement.

Abstract: Dependency bloat is a persistent challenge in Python projects, which
increases maintenance costs and security risks. While numerous tools exist for
detecting unused dependencies in Python, removing these dependencies across the
source code and configuration files of a project requires manual effort and
expertise.
  To tackle this challenge we introduce PYTRIM, an end-to-end system to
automate this process. PYTRIM eliminates unused imports and package
declarations across a variety of file types, including Python source and
configuration files such as requirements.txt and setup.py. PYTRIM's modular
design makes it agnostic to the source of dependency bloat information,
enabling integration with any detection tool. Beyond its contribution when it
comes to automation, PYTRIM also incorporates a novel dynamic analysis
component that improves dependency detection recall.
  Our evaluation of PYTRIM's end-to-end effectiveness on a ground-truth dataset
of 37 merged pull requests from prior work, shows that PYTRIM achieves 98.3%
accuracy in replicating human-made changes. To show its practical impact, we
run PYTRIM on 971 open-source packages, identifying and trimming bloated
dependencies in 39 of them. For each case, we submit a corresponding pull
request, 6 of which have already been accepted and merged. PYTRIM is available
as an open-source project, encouraging community contributions and further
development.
  Video demonstration: https://youtu.be/LqTEdOUbJRI
  Code repository: https://github.com/TrimTeam/PyTrim

</details>


### [16] [TShape: Rescuing Machine Learning Models from Complex Shapelet Anomalies](https://arxiv.org/abs/2510.00680)
*Hang Cui,Jingjing Li,Haotian Si,Quan Zhou,Changhua Pei,Gaogang Xie,Dan Pei*

Main category: cs.SE

TL;DR: TShape is a new anomaly detection framework that leverages dual attention and multi-scale convolution to better detect complex shape anomalies in time series data, outperforming existing methods with a significant F1 score improvement and increased robustness.


<details>
  <summary>Details</summary>
Motivation: Accurate detection of complex anomalies in time series data is fundamental for reliable IT infrastructure operations. Current machine learning methods have difficulties identifying 'shapelet anomalies'—subtle but critical shape changes easily identified by experts, yet missed by algorithms.

Method: The paper proposes TShape, a framework using a patch-wise dual attention mechanism combined with multi-scale convolution. This approach enables modeling of both local, fine-grained shape features and broader contextual dependencies, which improves the detection of intricate sub-sequence anomalies.

Result: TShape achieves, on average, a 10% improvement in F1 score compared to state-of-the-art methods across five diverse benchmarks for industrial time series anomaly detection. Ablation studies and attention visualizations further support the effectiveness and robustness of its individual components.

Conclusion: TShape demonstrates superior performance and adaptability in identifying complex shapelet anomalies in time series data, making it suitable for use in unpredictable and highly dynamic environments found in IT infrastructures.

Abstract: Time series anomaly detection (TSAD) is critical for maintaining the
reliability of modern IT infrastructures, where complex anomalies frequently
arise in highly dynamic environments. In this paper, we present TShape, a novel
framework designed to address the challenges in industrial time series anomaly
detection. Existing methods often struggle to detect shapelet anomalies that
manifest as complex shape deviations, which appear obvious to human experts but
prove challenging for machine learning algorithms. TShape introduces a
patch-wise dual attention mechanism with multi-scale convolution to model
intricate sub-sequence variations by balancing local, fine-grained shape
features with global contextual dependencies. Our extensive evaluation on five
diverse benchmarks demonstrates that TShape outperforms existing
state-of-the-art models, achieving an average 10\% F1 score improvement in
anomaly detection. Additionally, ablation studies and attention visualizations
confirm the essential contributions of each component, highlighting the
robustness and adaptability of TShape to complex shapelet shapes in time series
data.

</details>


### [17] [Maven-Lockfile: High Integrity Rebuild of Past Java Releases](https://arxiv.org/abs/2510.00730)
*Larissa Schmid,Elias Lundell,Yogya Gamage,Benoit Baudry,Martin Monperrus*

Main category: cs.SE

TL;DR: Maven-Lockfile is a tool that brings modern lockfile support to Java's Maven, enabling secure and reproducible builds by capturing dependencies and their checksums. It works with minimal setup and detects tampering, addressing a major ecosystem gap.


<details>
  <summary>Details</summary>
Motivation: Maven, a widely used package manager for Java, does not natively support lockfiles, making it harder to achieve reproducible and secure builds in projects that depend on many third-party libraries.

Method: The authors introduce 'Maven-Lockfile', a tool that generates and updates lockfiles, capturing direct and transitive dependencies with checksums to ensure build integrity.

Result: Maven-Lockfile enables reproducible builds from historical commits and detects tampered artifacts, requiring minimal configuration.

Conclusion: Maven-Lockfile provides Java projects with improved build integrity and reproducibility, and offers a foundation for future research in Java software supply chain security.

Abstract: Modern software projects depend on many third-party libraries, complicating
reproducible and secure builds. Several package managers address this with the
generation of a lockfile that freezes dependency versions and can be used to
verify the integrity of dependencies. Yet, Maven, one of the most important
package managers in the Java ecosystem, lacks native support for a lockfile. We
present Maven-Lockfile to generate and update lockfiles, with support for
rebuilding projects from past versions. Our lockfiles capture all direct and
transitive dependencies with their checksums, enabling high integrity builds.
Our evaluation shows that Maven-Lockfile can reproduce builds from historical
commits and is able to detect tampered artifacts. With minimal configuration,
Maven-Lockfile equips Java projects with modern build integrity and build
reproducibility, and fosters future research on software supply chain security
in Java.

</details>


### [18] [AI Where It Matters: Where, Why, and How Developers Want AI Support in Daily Work](https://arxiv.org/abs/2510.00762)
*Rudrajit Choudhuri,Carmen Badea,Christian Bird,Jenna Butler,Rob DeLine,Brian Houck*

Main category: cs.SE

TL;DR: The paper maps out when, why, and how developers want or limit AI support across different software tasks, finding that needs and priorities for responsible AI vary by context (code, ops, mentoring), and offering tailored recommendations to guide future AI tool design.


<details>
  <summary>Details</summary>
Motivation: There is a lack of clear guidance on where developers most need and want support from generative AI, and on how such support should be designed responsibly.

Method: A large-scale mixed-methods study involving 860 developers, utilizing cognitive appraisal theory to analyze task evaluations and correlate them with AI adoption patterns and responsible AI priorities.

Result: Developers show strong current use of AI in coding and testing, seek to reduce toil in documentation and operations, and place clear boundaries for AI involvement in mentoring and relationship-building. Responsible AI priorities differ by task: reliability for systems-facing tasks, transparency and control for core work, and fairness for human-facing work.

Conclusion: The study provides a contextual, empirical mapping of developers' needs and preferences for AI assistance in software work, highlighting where AI adoption is suitable and where responsible design is critical.

Abstract: Generative AI is reshaping software work, yet we lack clear guidance on where
developers most need and want support, and how to design it responsibly. We
report a large-scale, mixed-methods study of N=860 developers that examines
where, why, and how they seek or limit AI help, providing the first task-aware,
empirically validated mapping from developers' perceptions of their tasks to AI
adoption patterns and responsible AI priorities. Using cognitive appraisal
theory, we show that task evaluations predict openness to and use of AI,
revealing distinct patterns: strong current use and a desire for improvement in
core work (e.g., coding, testing); high demand to reduce toil (e.g.,
documentation, operations); and clear limits for identity- and
relationship-centric work (e.g., mentoring). Priorities for responsible AI
support vary by context: reliability and security for systems-facing tasks;
transparency, alignment, and steerability to maintain control; and fairness and
inclusiveness for human-facing work. Our results offer concrete, contextual
guidance for delivering AI where it matters to developers and their work.

</details>


### [19] [Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning](https://arxiv.org/abs/2510.00881)
*Patrizio Migliarini,Mashal Afzal Memon,Marco Autili,Paola Inverardi*

Main category: cs.SE

TL;DR: The paper evaluates how well 16 large language models can reason about ethical dilemmas, finding high consistency with expert ethicists and suggesting LLMs could be useful for ethical decision-making in software engineering tools.


<details>
  <summary>Details</summary>
Motivation: Large Language Models (LLMs) are increasingly used in software engineering tools not just for coding tasks, but also for making judgments under uncertainty and in ethically relevant situations. Assessing whether these models can reason about ethics in a reliable way is essential for their responsible deployment.

Method: The authors introduce a fully automated framework to assess the ethical reasoning abilities of 16 LLMs. In a zero-shot setting, each model is evaluated using 30 real-world ethical dilemmas and asked to: (1) pick the most applicable ethical theory, (2) assess moral acceptability of actions, and (3) explain their reasoning. Model outputs are compared to expert ethicists' opinions using inter-model agreement metrics and qualitative analysis of explanations.

Result: LLMs demonstrated an average Theory Consistency Rate (TCR) of 73.3% and a Binary Agreement Rate (BAR) of 86.7% regarding moral acceptability, aligning closely with expert judgments. Divergences appeared mainly in ambiguous cases, but different models still showed strong conceptual convergence in their textual explanations.

Conclusion: Current LLMs have promising ethical reasoning capabilities, showing interpretable and theory-consistent outputs in most tested scenarios. They can potentially serve as scalable, auditable ethical inference engines in software engineering pipelines, though ambiguity in some cases warrants further attention.

Abstract: Large Language Models (LLMs) are increasingly integrated into software
engineering (SE) tools for tasks that extend beyond code synthesis, including
judgment under uncertainty and reasoning in ethically significant contexts. We
present a fully automated framework for assessing ethical reasoning
capabilities across 16 LLMs in a zero-shot setting, using 30 real-world
ethically charged scenarios. Each model is prompted to identify the most
applicable ethical theory to an action, assess its moral acceptability, and
explain the reasoning behind their choice. Responses are compared against
expert ethicists' choices using inter-model agreement metrics. Our results show
that LLMs achieve an average Theory Consistency Rate (TCR) of 73.3% and Binary
Agreement Rate (BAR) on moral acceptability of 86.7%, with interpretable
divergences concentrated in ethically ambiguous cases. A qualitative analysis
of free-text explanations reveals strong conceptual convergence across models
despite surface-level lexical diversity. These findings support the potential
viability of LLMs as ethical inference engines within SE pipelines, enabling
scalable, auditable, and adaptive integration of user-aligned ethical
reasoning. Our focus is the Ethical Interpreter component of a broader
profiling pipeline: we evaluate whether current LLMs exhibit sufficient
interpretive stability and theory-consistent reasoning to support automated
profiling.

</details>


### [20] [On Effective Semantic Translation for Code: A Study Based on Pseudocode](https://arxiv.org/abs/2510.00920)
*Songqiang Chen,Congying Xu,Jingyi Chen,Jialun Cao,Jiarong Wu,Shing-Chi Cheung*

Main category: cs.SE

TL;DR: This paper empirically shows that generating pseudocode as an intermediate step improves code translation by LLMs, especially for tough translations and low-resource languages, though the method depends on producing sufficiently clear and correct pseudocode. Hybrid strategies leveraging both direct and pseudocode-based approaches are recommended for best results.


<details>
  <summary>Details</summary>
Motivation: Large language models can translate code, but direct code-to-code translation often lacks accuracy. Inspired by intermediate-step methods in other tasks, this paper explores using pseudocode as a bridge to improve translation.

Method: The authors conducted an empirical study, comparing direct translation with pseudocode-based translation across 9,690 tasks involving six programming languages and five LLMs. They evaluated effectiveness, usage patterns, and limitations.

Result: Pseudocode-based translation improves code translation, especially when converting from flexible to rigid languages or in low-resource situations (e.g., Rust). It helps in translating complex logic and mitigating implementation distractions, but is limited by the quality of generated pseudocode (e.g., errors, incompleteness, ambiguity).

Conclusion: Combining direct and pseudocode-based approaches leads to better code translation accuracy. Pseudocode-based methods are notably advantageous in handling complex or low-resource scenarios, despite some limitations.

Abstract: Large language models (LLMs) show great potential in code translation.
However, accurate translation remains challenging when using the commonly
adopted direct code-to-code translation approach, which converts a program into
the target programming language (PL) in a single step. Inspired by the success
of incorporating intermediate steps to guide LLMs in resolving challenging
tasks, we explore pseudocode-based code translation, which emulates the human
semantic translation by first interpreting the program's intent and logic into
pseudocode and then implementing it in the target PL. We find that
pseudocode-based translation helps translate programs that direct translation
struggles to handle. Nonetheless, the effectiveness, advantages, and
limitations of this approach remain underexplored. To bridge this gap, we
present an empirical study on pseudocode-based code translation, aiming to
investigate its effectiveness in enhancing the direct translation approach,
illuminate its effective usage, and identify limitations hindering its
potential benefits. By comparing direct and pseudocode-based translation
approaches on 9,690 translation tasks across six PLs with five popular LLMs, we
demonstrate that pseudocode-based translation can effectively complement direct
translation, particularly when translating from flexible to rigid PLs or
dealing with low-resource Rust. Based on these findings, we suggest adopting
strategies that combine the complementary strengths of both approaches to
enhance code translation accuracy. We also reveal the advantages of
pseudocode-based translation in disentangling translations of complicated
programs and mitigating distractions from detailed implementations in original
programs, as well as its limitations due to incorrect, incomplete, or ambiguous
pseudocode.

</details>


### [21] [ChatGPT in Introductory Programming: Counterbalanced Evaluation of Code Quality, Conceptual Learning, and Student Perceptions](https://arxiv.org/abs/2510.00946)
*Shiza Andleeb,Brandon Kantorski,Jeffrey C. Carver*

Main category: cs.SE

TL;DR: Using ChatGPT in beginner programming courses improves code quality and speed, but doesn't always help students understand concepts. Students appreciate ChatGPT for practical help but worry about becoming dependent, so teachers should thoughtfully combine it with traditional teaching.


<details>
  <summary>Details</summary>
Motivation: To understand the effects of ChatGPT usage on beginner programmers' code quality, conceptual understanding, time efficiency, and attitudes in an introductory CS course.

Method: A quasi-experimental, counterbalanced study where students alternated between using and not using ChatGPT for two programming assignments in C. Code quality, conceptual knowledge, completion time, and student feedback were assessed using rubrics, surveys, and task timing.

Result: Access to ChatGPT led to higher code quality scores and quicker task completion. Conceptual understanding gains were inconsistent: lower for functions, higher for structures. Students liked ChatGPT for support, but worried about accuracy and skill development.

Conclusion: ChatGPT boosts code quality and productivity for beginners, but does not consistently improve conceptual understanding. It should be used alongside instructional methods that promote independent learning.

Abstract: Background: Large language models (LLMs) such as ChatGPT are increasingly
used in introductory programming courses to provide real-time code generation,
debugging, and explanations. While these tools can boost productivity and code
quality, concerns remain about over-reliance and potential impacts on
conceptual learning. Objective: To investigate how ChatGPT access affects code
quality, conceptual understanding, task completion times, and student
perceptions in a CS1 course. Methods: We conducted a counterbalanced,
quasi-experimental study in which students alternated between ChatGPT and
non-ChatGPT conditions across two programming assignments in C (functions and
structures). We evaluated their code submissions using multidimensional
rubrics, conceptual post-surveys, and task completion time. Results: Students
who had access to ChatGPT produced significantly higher rubric scores for code
quality and completed tasks in less time compared to those without access.
However, gains in conceptual understanding were mixed, lower for the functions
topic but higher for the structures topic. Students reported positive
experiences with ChatGPT, citing its value for debugging and practice, while
expressing concerns about accuracy and long-term skill development.
Conclusions: ChatGPT can enhance code quality and efficiency for novice
programmers, but may not uniformly improve conceptual understanding. Structured
integration and complementary instructional strategies are recommended to
foster independent problem-solving skills.

</details>


### [22] [Enhancing Software Testing Education: Understanding Where Students Struggle](https://arxiv.org/abs/2510.00957)
*Shiza Andleeb,Teo Mendoza,Lucas Cordova,Gursimran Walia,Jeffrey C. Carver*

Main category: cs.SE

TL;DR: Many students struggle with software testing concepts, especially decision coverage and exception handling. Analysis of assignment revisions in a senior software testing course shows students often make ineffective test suite changes. The insights point to the need for targeted instruction and improved feedback tools to better support student learning.


<details>
  <summary>Details</summary>
Motivation: Many computer science students have difficulty mastering software testing concepts necessary to build strong test suites. There is a need to understand which testing concepts are most frequently misunderstood and how misconceptions show up in students' revision behavior, especially as automated feedback tools are commonly used to support learning.

Method: The authors analyzed student submissions from two assignments in a senior-level software testing course, where an automated feedback tool was used. The research focused on examining the conceptual gaps and modification patterns when students revise their test suites.

Result: The study found that decision coverage and exception handling are persistent conceptual challenges for students. Most ineffective test suite revisions involved superficial or method-level changes that did not significantly improve code coverage.

Conclusion: Educators, researchers, and tool designers can use these findings to refine feedback systems and instructional approaches, specifically targeting persistent misconceptions. Addressing these issues can help students develop stronger and more maintainable test suites.

Abstract: Effective software testing is critical for producing reliable and secure
software, yet many computer science students struggle to master the
foundational concepts required to construct comprehensive test suites. While
automated feedback tools are widely used to support student learning, it
remains unclear which testing concepts are most frequently misunderstood and
how these misunderstandings are reflected in students' test suite revisions.
This study examines the specific testing concepts that lead students to make
ineffective changes, those that fail to improve code coverage, during test
suite development. Leveraging an automated feedback tool in a senior-level
software testing course, we analyzed student submissions from two assignments
to identify prevalent conceptual gaps and patterns of unproductive
modification. Our results reveal that decision coverage and exception handling
are persistent challenges, and that students most often make superficial or
method-level changes that do not enhance coverage. These findings provide
actionable insights for educators, researchers, and tool designers. By
pinpointing the concepts that most often contribute to poor testing outcomes,
we can refine feedback systems, target instruction to address persistent
misconceptions, and more effectively support students in developing robust,
maintainable test suites.

</details>


### [23] [Semantics-Aligned, Curriculum-Driven, and Reasoning-Enhanced Vulnerability Repair Framework](https://arxiv.org/abs/2510.01002)
*Chengran Yang,Ting Zhang,Jinfeng Jiang,Xin Zhou,Haoye Tian,Jieke Shi,Junkai Chen,Yikun Li,Eng Lieh Ouh,Lwin Khin Shar,David Lo*

Main category: cs.SE

TL;DR: SeCuRepair, a novel curriculum-driven and reasoning-enhanced framework for vulnerability repair, tackles key weaknesses in current AVR models. It outperforms existing methods by over 30% on major benchmarks by promoting semantic understanding and progressive learning.


<details>
  <summary>Details</summary>
Motivation: Current learning-based Automated Vulnerability Repair (AVR) methods show promise but struggle to generalize in real-world software, specifically due to limited cross-repository performance, inability to handle long-range code dependencies, and excessive reliance on simple lexical patterns.

Method: The authors propose SeCuRepair, a new framework that is semantics-aligned, curriculum-driven, and reasoning-enhanced. SeCuRepair introduces a 'reason-then-edit' approach where the model explains the fix before patching, uses semantics-aware reinforcement learning that rewards patches for syntactic and semantic alignment, and applies a difficulty-aware curriculum to train progressively from simple to complex repairs.

Result: SeCuRepair is evaluated on repository-level splits of BigVul and PrimeVul_AVR. It achieves significant improvements over baselines, outperforming the best previous methods by 34.52% on BigVul and 31.52% on PrimeVul_AVR (CodeBLEU metric). Ablation studies indicate each framework component is beneficial.

Conclusion: SeCuRepair effectively addresses major limitations of prior AVR methods, achieving much better generalization, handling complex repairs, and reducing reliance on lexical patterns. The approach offers a promising direction for robust automated vulnerability repair.

Abstract: Current learning-based Automated Vulnerability Repair (AVR) approaches, while
promising, often fail to generalize effectively in real-world scenarios. Our
diagnostic analysis reveals three fundamental weaknesses in state-of-the-art
AVR approaches: (1) limited cross-repository generalization, with performance
drops on unseen codebases; (2) inability to capture long-range dependencies,
causing a performance degradation on complex, multi-hunk repairs; and (3)
over-reliance on superficial lexical patterns, leading to significant
performance drops on vulnerabilities with minor syntactic variations like
variable renaming.
  To address these limitations, we propose SeCuRepair, a semantics-aligned,
curriculum-driven, and reasoning-enhanced framework for vulnerability repair.
At its core, SeCuRepair adopts a reason-then-edit paradigm, requiring the model
to articulate why and how a vulnerability should be fixed before generating the
patch. This explicit reasoning enforces a genuine understanding of repair logic
rather than superficial memorization of lexical patterns. SeCuRepair also moves
beyond traditional supervised fine-tuning and employs semantics-aware
reinforcement learning, rewarding patches for their syntactic and semantic
alignment with the oracle patch rather than mere token overlap. Complementing
this, a difficulty-aware curriculum progressively trains the model, starting
with simple fixes and advancing to complex, multi-hunk coordinated edits.
  We evaluate SeCuRepair on strict, repository-level splits of BigVul and newly
crafted PrimeVul_AVR datasets. SeCuRepair significantly outperforms all
baselines, surpassing the best-performing baselines by 34.52% on BigVul and
31.52% on PrimeVul\textsubscript{AVR} in terms of CodeBLEU, respectively.
Comprehensive ablation studies further confirm that each component of our
framework contributes to its final performance.

</details>


### [24] [Improving Code Localization with Repository Memory](https://arxiv.org/abs/2510.01003)
*Boshi Wang,Weijian Xu,Yunsheng Li,Mei Gao,Yujia Xie,Huan Sun,Dongdong Chen*

Main category: cs.SE

TL;DR: This paper enhances language agents for code localization by enabling them to remember and utilize repository commit history, leading to significant performance gains and making them behave more like experienced human developers.


<details>
  <summary>Details</summary>
Motivation: Code localization remains a key challenge in software engineering, especially for tasks like bug fixing. Existing language agent methods lack memory and therefore cannot build up repository knowledge over time, unlike human developers who rely on long-term memories to be more effective.

Method: This work augments language agents with memory by using a repository’s commit history, linked issues, and summaries of actively changed code sections. Tools are introduced to let agents retrieve and utilize this historical information, forming a non-parametric memory of recent commits and functionality changes, recognized through commit patterns.

Result: Augmenting memory in this manner significantly improves the performance of LocAgent, a state-of-the-art localization framework, on benchmarks including SWE-bench-verified and SWE-bench-live.

Conclusion: Integrating long-term, repository-specific memory into language agents makes them more capable at code localization tasks and allows them to more closely emulate the expertise of human developers, especially for long-duration tasks.

Abstract: Code localization is a fundamental challenge in repository-level software
engineering tasks such as bug fixing. While existing methods equip language
agents with comprehensive tools/interfaces to fetch information from the
repository, they overlook the critical aspect of memory, where each instance is
typically handled from scratch assuming no prior repository knowledge. In
contrast, human developers naturally build long-term repository memory, such as
the functionality of key modules and associations between various bug types and
their likely fix locations. In this work, we augment language agents with such
memory by leveraging a repository's commit history - a rich yet underutilized
resource that chronicles the codebase's evolution. We introduce tools that
allow the agent to retrieve from a non-parametric memory encompassing recent
historical commits and linked issues, as well as functionality summaries of
actively evolving parts of the codebase identified via commit patterns. We
demonstrate that augmenting such a memory can significantly improve LocAgent, a
state-of-the-art localization framework, on both SWE-bench-verified and the
more recent SWE-bench-live benchmarks. Our research contributes towards
developing agents that can accumulate and leverage past experience for
long-horizon tasks, more closely emulating the expertise of human developers.

</details>


### [25] [GenIA-E2ETest: A Generative AI-Based Approach for End-to-End Test Automation](https://arxiv.org/abs/2510.01024)
*Elvis Júnior,Alan Valejo,Jorge Valverde-Rebaza,Vânia de Oliveira Neves*

Main category: cs.SE

TL;DR: Manual E2E software testing is inefficient. GenIA-E2ETest uses generative AI to turn natural language into test scripts for web apps, achieving high correctness and recall with little manual adjustment, making E2E test automation easier and more widespread.


<details>
  <summary>Details</summary>
Motivation: Manual software testing is time-consuming and error-prone. Although LLMs have automated unit test generation, effective solutions for end-to-end (E2E) testing are lacking.

Method: The authors introduce GenIA-E2ETest, a system that uses generative AI to automatically generate executable E2E test scripts from natural language descriptions. They evaluate their system on two web applications, measuring metrics such as completeness, correctness, precision, recall, manual modification rate, and robustness.

Result: GenIA-E2ETest achieved an average of 77% in element metrics, 82% in execution precision, and 85% in execution recall, required only about 10% manual modification, and showed robust performance in common web scenarios. Some limitations were noted with context-dependent navigation and dynamic content.

Conclusion: GenIA-E2ETest demonstrates that generative AI can feasibly and effectively automate E2E web testing from natural language, substantially reducing manual work and making automated testing more accessible.

Abstract: Software testing is essential to ensure system quality, but it remains
time-consuming and error-prone when performed manually. Although recent
advances in Large Language Models (LLMs) have enabled automated test
generation, most existing solutions focus on unit testing and do not address
the challenges of end-to-end (E2E) testing, which validates complete
application workflows from user input to final system response. This paper
introduces GenIA-E2ETest, which leverages generative AI to generate executable
E2E test scripts from natural language descriptions automatically. We evaluated
the approach on two web applications, assessing completeness, correctness,
adaptation effort, and robustness. Results were encouraging: the scripts
achieved an average of 77% for both element metrics, 82% for precision of
execution, 85% for execution recall, required minimal manual adjustments
(average manual modification rate of 10%), and showed consistent performance in
typical web scenarios. Although some sensitivity to context-dependent
navigation and dynamic content was observed, the findings suggest that
GenIA-E2ETest is a practical and effective solution to accelerate E2E test
automation from natural language, reducing manual effort and broadening access
to automated testing.

</details>


### [26] [CodeGenLink: A Tool to Find the Likely Origin and License of Automatically Generated Code](https://arxiv.org/abs/2510.01077)
*Daniele Bifolco,Guido Annicchiarico,Pierluigi Barbiero,Massimiliano Di Penta,Fiorella Zampetti*

Main category: cs.SE

TL;DR: CodeGenLink helps developers trace the origins and licenses of code generated by LLMs by linking it to similar web code and filtering out unrelated sources, thus improving trust and legal safety.


<details>
  <summary>Details</summary>
Motivation: Developers are increasingly using LLMs for automated code generation, but they worry about trustworthiness, copyright, and the lack of provenance and licensing information compared to code sourced from the Web.

Method: The paper proposes CodeGenLink, a GitHub CoPilot extension for Visual Studio Code. It suggests URLs with code similar to generated snippets, and provides the likely license info. It combines LLM-powered searches with similarity analysis between generated and retrieved code.

Result: Preliminary results show CodeGenLink filters out unrelated URLs effectively and, when possible, supplies license details for the detected code origins.

Conclusion: CodeGenLink addresses developers' concerns by linking generated code to its probable web origin and providing license info, increasing the trust and traceability of LLM-generated code.

Abstract: Large Language Models (LLMs) are widely used in software development tasks
nowadays. Unlike reusing code taken from the Web, for LLMs' generated code,
developers are concerned about its lack of trustworthiness and possible
copyright or licensing violations, due to the lack of code provenance
information. This paper proposes CodeGenLink, a GitHub CoPilot extension for
Visual Studio Code aimed at (i) suggesting links containing code very similar
to automatically generated code, and (ii) whenever possible, indicating the
license of the likely origin of the code. CodeGenLink retrieves candidate links
by combining LLMs with their web search features and then performs similarity
analysis between the generated and retrieved code. Preliminary results show
that CodeGenLink effectively filters unrelated links via similarity analysis
and provides licensing information when available. Tool URL:
https://github.com/danielebifolco/CodeGenLink Tool Video:
https://youtu.be/M6nqjBf9_pw

</details>


### [27] [Developers' Perspectives on Software Licensing: Current Practices, Challenges, and Tools](https://arxiv.org/abs/2510.01096)
*Nathan Wintersgill,Trevor Stalnaker,Daniel Otten,Laura A. Heymann,Oscar Chaparro,Massimiliano Di Penta,Daniel M. German,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: Through surveys and interviews, this study identifies major challenges and practices in software license compliance, providing actionable insights and suggestions for improving compliance tools and guiding future research.


<details>
  <summary>Details</summary>
Motivation: Modern software heavily relies on open-source components, requiring developers to ensure compliance with varied licenses. Noncompliance can result in serious legal, financial, and reputational consequences, highlighting the importance of understanding developer practices in managing licensing.

Method: A joint team of software engineering and legal researchers conducted a survey with 58 developers, followed by seven in-depth interviews, to examine current practices, challenges, and tool usage in license compliance.

Result: The research produced 15 key findings about current practices, challenges, and tool use in software license compliance.

Conclusion: The paper discusses the significance of these findings, offers recommendations for improving licensing tools, and proposes future research directions.

Abstract: Most modern software products incorporate open-source components, requiring
development teams to maintain compliance with each component's licenses.
Noncompliance can lead to significant financial, legal, and reputational
repercussions. While some organizations may seek advice from legal
practitioners to assist with licensing tasks, developers still play a key role
in such a process. To this end, it is essential to understand how developers
approach license compliance tasks, the challenges they encounter, and the tools
that they use. This work studies these aspects of software licensing practices
through a study - conducted by a joint team of software engineering and legal
researchers - consisting of a survey with 58 software developers and seven
follow-up interviews. The study resulted in 15 key findings regarding the
current state of practice. We discuss the implications of our findings and
offer directions for future research as well as actionable recommendations for
licensing tools.

</details>


### [28] [When Shared Worlds Break: Demystifying Defects in Multi-User Extended Reality Software Systems](https://arxiv.org/abs/2510.01182)
*Shuqing Li,Chenran Zhang,Binchang Li,Cuiyun Gao,Michael R. Lyu*

Main category: cs.SE

TL;DR: This paper presents a first-of-its-kind empirical study of 2,649 multi-user XR bug reports, categorizing XR defects, highlighting major issues like sync failures and avatar glitches, revealing substantial system-breaking consequences, and offering guidance for more reliable XR experiences.


<details>
  <summary>Details</summary>
Motivation: Multi-user XR systems enable shared immersive experiences but suffer from unique software defects that impact user reliability and experience. Understanding these defects is necessary but currently under-researched.

Method: The authors conducted a large-scale empirical study by analyzing 2,649 real-world bug reports from developer forums, GitHub repositories, and mainstream XR app store reviews. They used qualitative methods with iterative open coding to develop a taxonomy categorizing XR bugs along three axes: symptoms, root causes, and severity.

Result: The study revealed that synchronization inconsistencies and avatar-related anomalies are the most common defects. Network/synchronization and session management flaws are the primary root causes. Over one-third of bugs have severe consequences that disrupt shared XR experiences, with additional concerns regarding privacy and health.

Conclusion: Multi-user XR systems encounter unique and severe software defects predominantly in synchronization and session management. The paper offers actionable recommendations for stakeholders and emphasizes the need for specialized testing and quality assurance methods for XR systems.

Abstract: Multi-user Extended Reality (XR) systems enable transformative shared
experiences but introduce unique software defects that compromise user
experience. Understanding software defects in multi-user XR systems is crucial
for enhancing system reliability, yet remains underexplored. To fill the gap,
this paper presents the first large-scale empirical study of multi-user XR
defects, analyzing 2,649 real-world bug reports from diverse sources, including
developer forums, GitHub repositories, and app reviews on mainstream XR app
stores. Through rigorous qualitative analysis using iterative open coding, we
develop a comprehensive taxonomy that classifies multi-user XR bugs along three
dimensions: Symptom Manifestation, Root Cause Origin, and Consequence Severity.
Our findings reveal that synchronization inconsistencies and avatar-related
anomalies are the most prevalent symptoms, while network/synchronization logic
defects and session management flaws emerge as dominant root causes.
Critically, over 34% of analyzed bugs lead to severe consequences that
fundamentally break the shared experience, including system crashes, persistent
disconnections, and complete interaction breakdowns, etc. We also identify
concerning privacy and health implications unique to multi-user XR contexts.
Based on our findings of defect analysis, we provide actionable recommendations
for developers, platform vendors, and researchers. Our results demonstrate that
multi-user XR systems face distinct challenges at the intersection of
distributed systems, real-time 3D interaction, and immersive experiences,
necessitating specialized approaches to testing, debugging, and quality
assurance.

</details>
