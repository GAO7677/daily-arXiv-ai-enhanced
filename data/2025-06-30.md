<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 8]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Can Large Language Models Help Students Prove Software Correctness? An Experimental Study with Dafny](https://arxiv.org/abs/2506.22370)
*Carolina Carreira,Álvaro Silva,Alexandre Abreu,Alexandra Mendes*

Main category: cs.SE

TL;DR: Access to ChatGPT significantly enhances students' performance on formal verification problems if they use high-quality prompts. The paper provides insights and recommendations for leveraging LLMs in computing education effectively.


<details>
  <summary>Details</summary>
Motivation: Students in computing education are increasingly using large language models (LLMs) like ChatGPT, but their effectiveness in supporting complex tasks such as deductive program verification is not well understood.

Method: A mixed-methods study was conducted with master's students in a formal methods course. Each participant tackled two Dafny verification problems—one with a custom ChatGPT interface that logged interactions and one without LLM access. Strategies and trust levels were analyzed.

Result: Students performed significantly better when using ChatGPT, but performance improvements depended on the quality of their prompts. Successful student strategies and levels of trust in LLMs were identified.

Conclusion: LLMs can support student performance in formal verification tasks, but their benefit depends on how well students engage with them. Recommendations are provided for educators to integrate LLMs into courses in ways that enhance learning instead of simply substituting student effort.

Abstract: Students in computing education increasingly use large language models (LLMs)
such as ChatGPT. Yet, the role of LLMs in supporting cognitively demanding
tasks, like deductive program verification, remains poorly understood. This
paper investigates how students interact with an LLM when solving formal
verification exercises in Dafny, a language that supports functional
correctness, by allowing programmers to write formal specifications and
automatically verifying that the implementation satisfies the specification. We
conducted a mixed-methods study with master's students enrolled in a formal
methods course. Each participant completed two verification problems, one with
access to a custom ChatGPT interface, that logged all interactions, and the
other without. We identified strategies used by successful students and
assessed the level of trust students place in LLMs. %\todo{Our findings show
that something here} Our findings show that students perform significantly
better when using ChatGPT; however, performance gains are tied to prompt
quality. We conclude with practical recommendations for integrating LLMs into
formal methods courses more effectively, including designing LLM-aware
challenges that promote learning rather than substitution.

</details>


### [2] [How (Not) To Write a Software Engineering Abstract](https://arxiv.org/abs/2506.21634)
*Lutz Prechelt,Lloyd Montgomery,Julian Frattini,Franz Zieris*

Main category: cs.SE

TL;DR: The paper finds that most software engineering abstracts—even in top venues—lack completeness and informativeness. Structured abstracts fare better than unstructured ones. The authors recommend new guidelines for writing more informative, readable abstracts, calling for required generalizing conclusions and specialized formats for certain research types.


<details>
  <summary>Details</summary>
Motivation: Abstracts are a crucial component of software engineering research articles, but many are insufficiently informative. There is a need to characterize the ideal structure of abstracts in high-quality venues and identify common deficiencies.

Method: The study used qualitative open coding to derive concepts explaining abstract properties and identified an archetypical structure for abstracts. It quantitatively analyzed the content of 362 abstracts from five high-quality venues, performed exploratory data analysis to detect recurring issues, compared real abstracts’ structures to the archetype, and inferred guidelines for more informative abstracts.

Result: Only 29% of sampled abstracts were complete (providing background, objective, method, result, and conclusion). This rate was twice as high for structured abstracts. Just 4% were deemed proper, showing good readability and no gaps in informativeness or understandability. Structured abstracts outperformed unstructured ones; artifact-centric papers need a distinct format.

Conclusion: Most abstracts, even in top venues, do not meet ideal standards—being neither complete nor proper. Structured abstracts generally perform better, yet current practices often lack required generalizing conclusions. The community should encourage better structures and conclusions in abstracts, with different formats for artifact-centric research.

Abstract: Background: Abstracts are a particularly valuable element in a software
engineering research article. However, not all abstracts are as informative as
they could be. Objective: Characterize the structure of abstracts in
high-quality software engineering venues. Observe and quantify deficiencies.
Suggest guidelines for writing informative abstracts. Methods: Use qualitative
open coding to derive concepts that explain relevant properties of abstracts.
Identify the archetypical structure of abstracts. Use quantitative content
analysis to objectively characterize abstract structure of a sample of 362
abstracts from five presumably high-quality venues. Use exploratory data
analysis to find recurring issues in abstracts. Compare the archetypical
structure to actual structures. Infer guidelines for producing informative
abstracts. Results: Only 29% of the sampled abstracts are complete, i.e.,
provide background, objective, method, result, and conclusion information. For
structured abstracts, the ratio is twice as big. Only 4% of the abstracts are
proper, i.e., they also have good readability (Flesch-Kincaid score) and have
no informativeness gaps, understandability gaps, nor highly ambiguous
sentences. Conclusions: (1) Even in top venues, a large majority of abstracts
are far from ideal. (2) Structured abstracts tend to be better than
unstructured ones. (3) Artifact-centric works need a different structured
format. (4) The community should start requiring conclusions that generalize,
which currently are often missing in abstracts.

</details>


### [3] [Experience converting a large mathematical software package written in C++ to C++20 modules](https://arxiv.org/abs/2506.21654)
*Wolfgang Bangerth*

Main category: cs.SE

TL;DR: Converting large C++ mathematical software to C++20 modules improves library compile times, but downstream impacts vary. Transition is practical but requires careful, sustained effort.


<details>
  <summary>Details</summary>
Motivation: Mathematical software packages traditionally use C++ header files to define interfaces. This approach, inherited from C, is problematic due to being clunky, unreliable, and slow. The introduction of the C++20 module system aims to address these issues, but practical strategies and outcomes for converting large, real-world mathematical software to modules remain to be explored.

Method: The author uses the deal.II finite element library (about 800,000 lines of code) as a case study. They describe methods to provide both header-based and module-based interfaces from the same codebase, detail the migration process, and evaluate the practical challenges and effects on both human and technical metrics.

Result: The conversion from header files to modules is achievable with a significant, yet manageable, effort. Compile times for the converted library decreased, but compile times for downstream projects did not show a consistent improvement.

Conclusion: Migrating large C++ mathematical software packages to the C++20 module system is feasible and beneficial for the packages themselves, primarily by reducing compile times. However, benefits for downstream projects are less clear, and a gradual, long-term transition for the broader ecosystem is recommended.

Abstract: Mathematical software has traditionally been built in the form of "packages"
that build on each other. A substantial fraction of these packages is written
in C++ and, as a consequence, the interface of a package is described in the
form of header files that downstream packages and applications can then
#include. C++ has inherited this approach towards exporting interfaces from C,
but the approach is clunky, unreliable, and slow. As a consequence, C++20 has
introduced a "module" system in which packages explicitly export declarations
and code that compilers then store in machine-readable form and that downstream
users can "import" -- a system in line with what many other programming
languages have used for decades.
  Herein, I explore how one can convert large mathematical software packages
written in C++ to this system, using the deal.II finite element library with
its around 800,000 lines of code as an example. I describe an approach that
allows providing both header-based and module-based interfaces from the same
code base, discuss the challenges one encounters, and how modules actually work
in practice in a variety of technical and human metrics. The results show that
with a non-trivial, but also not prohibitive effort, the conversion to modules
is possible, resulting in a reduction in compile time for the converted library
itself; on the other hand, for downstream projects, compile times show no clear
trend. I end with thoughts about long-term strategies for converting the entire
ecosystem of mathematical software over the coming years or decades.

</details>


### [4] [The DevSafeOps Dilemma: A Systematic Literature Review on Rapidity in Safe Autonomous Driving Development and Operation](https://arxiv.org/abs/2506.21693)
*Ali Nouri,Beatriz Cabrero-Daniel,Fredrik Törner,Christian Berger*

Main category: cs.SE

TL;DR: This paper systematically reviews literature on using DevOps in autonomous driving, highlighting both current solutions and persistent challenges, particularly around handling safety in AI-driven systems. Significant issues still need resolution to achieve truly safe DevOps in this field.


<details>
  <summary>Details</summary>
Motivation: Developing autonomous driving systems is highly complex and requires assurance of safety and reliability. Traditional development approaches struggle to keep up with continuous AI advancements and the need for rapid response to incidents. This drives interest in DevOps as a continuous development, deployment, and monitoring methodology for autonomous driving.

Method: The authors conducted a systematic literature review focused on identifying, analyzing, and synthesizing existing studies related to the use of DevOps for autonomous driving system development, especially in safety-related, AI-enabled contexts.

Result: The review provides a structured summary of current challenges and solutions associated with adopting DevOps for safety-critical, AI-enabled autonomous driving functions. It identifies several unresolved issues that hinder the full realization of safe and reliable DevOps practices in this domain.

Conclusion: While DevOps offers promise for improving autonomous driving system development, especially in terms of rapid progress and reliable operation, there remain significant open challenges concerning its safe application to AI-enabled safety-critical functions.

Abstract: Developing autonomous driving (AD) systems is challenging due to the
complexity of the systems and the need to assure their safe and reliable
operation. The widely adopted approach of DevOps seems promising to support the
continuous technological progress in AI and the demand for fast reaction to
incidents, which necessitate continuous development, deployment, and
monitoring. We present a systematic literature review meant to identify,
analyse, and synthesise a broad range of existing literature related to usage
of DevOps in autonomous driving development. Our results provide a structured
overview of challenges and solutions, arising from applying DevOps to
safety-related AI-enabled functions. Our results indicate that there are still
several open topics to be addressed to enable safe DevOps for the development
of safe AD.

</details>


### [5] [Using Generative AI in Software Design Education: An Experience Report](https://arxiv.org/abs/2506.21703)
*Victoria Jackson,Susannah Liu,Andre van der Hoek*

Main category: cs.SE

TL;DR: This paper reports on the integration of ChatGPT into an undergraduate software design class, showing it helps students with design while teaching them to critically appraise AI-generated content. Key lessons were identified for educators on effective GenAI deployment.


<details>
  <summary>Details</summary>
Motivation: There is growing use of Generative AI (GenAI) tools in software engineering, but limited research on their integration into areas beyond coding, such as software design education.

Method: An experience report was conducted in which undergraduate students were required to use ChatGPT during a team-based software design assignment. Data from ChatGPT conversation logs and students’ reflections were collected and analyzed qualitatively.

Result: Students found several benefits in using ChatGPT during their design process, but also emphasized the importance of critically evaluating AI-generated responses before using them in their work. The study identified key lessons for educators regarding the effective integration of GenAI in software design classes.

Conclusion: GenAI tools like ChatGPT can be beneficial in software design education by assisting students in design tasks and exposing them to both the strengths and limitations of generative AI. Successful classroom adoption requires guidance to ensure critical engagement with AI outputs.

Abstract: With the rapid adoption of Generative AI (GenAI) tools, software engineering
educators have grappled with how best to incorporate them into the classroom.
While some research discusses the use of GenAI in the context of learning to
code, there is little research that explores the use of GenAI in the classroom
for other areas of software development. This paper provides an experience
report on introducing GenAI into an undergraduate software design class.
Students were required to use GenAI (in the form of ChatGPT) to help complete a
team-based assignment. The data collected consisted of the ChatGPT conversation
logs and students' reflections on using ChatGPT for the assignment.
Subsequently, qualitative analysis was undertaken on the data. Students
identified numerous ways ChatGPT helped them in their design process while
recognizing the need to critique the response before incorporating it into
their design. At the same time, we identified several key lessons for educators
in how to deploy GenAI in a software design class effectively. Based on our
experience, we believe students can benefit from using GenAI in software design
education as it helps them design and learn about the strengths and weaknesses
of GenAI.

</details>


### [6] [KARMA Approach supporting Development Process Reconstruction in Model-based Systems Engineering](https://arxiv.org/abs/2506.22037)
*Jiawei Li,Zan Liang,Guoxin Wang,Jinzhi Lu,Yan Yan,Shouxuan Wu,Hao Wang*

Main category: cs.SE

TL;DR: This paper presents a novel method that uses natural language processing and metamodeling to formalize and reconstruct system development process models in response to changing requirements, enhancing efficiency as demonstrated with an aircraft maintenance system case study.


<details>
  <summary>Details</summary>
Motivation: There is a lack of effective methods to manage changes in development requirements and to reconstruct system development process models during iterative design in model-based systems engineering.

Method: The paper utilizes the KARMA language based on the GOPPRR-E metamodeling method to formalize process models uniformly. It introduces a model reconstruction framework where structured development requirements in natural language are analyzed using natural language processing, extracting structural and optimization constraints, followed by structural reorganization and algorithm optimization to generate an updated process model. A case study on the aircraft onboard maintenance system development process is presented.

Result: The method significantly enhances the design efficiency of the system development process model.

Conclusion: The proposed model reconstruction method effectively manages evolving requirements and reconstructs development process models, supporting efficient model-based systems engineering.

Abstract: Model reconstruction is a method used to drive the development of complex
system development processes in model-based systems engineering. Currently,
during the iterative design process of a system, there is a lack of an
effective method to manage changes in development requirements, such as
development cycle requirements and cost requirements, and to realize the
reconstruction of the system development process model. To address these
issues, this paper proposes a model reconstruction method to support the
development process model. Firstly, the KARMA language, based on the GOPPRR-E
metamodeling method, is utilized to uniformly formalize the process models
constructed based on different modeling languages. Secondly, a model
reconstruction framework is introduced. This framework takes a structured
development requirements based natural language as input, employs natural
language processing techniques to analyze the development requirements text,
and extracts structural and optimization constraint information. Then, after
structural reorganization and algorithm optimization, a development process
model that meets the development requirements is obtained. Finally, as a case
study, the development process of the aircraft onboard maintenance system is
reconstructed. The results demonstrate that this method can significantly
enhance the design efficiency of the development process.

</details>


### [7] [Autonomic Microservice Management via Agentic AI and MAPE-K Integration](https://arxiv.org/abs/2506.22185)
*Matteo Esposito,Alexander Bakhtin,Noman Ahmad,Mikel Robredo,Ruoyu Su,Valentina Lenarduzzi,Davide Taibi*

Main category: cs.SE

TL;DR: Microservices improve scalability but complicate management and security. The authors introduce a MAPE-K and agentic AI-based framework for automated anomaly detection and remediation, offering practical tools to boost system stability and security in distributed environments.


<details>
  <summary>Details</summary>
Motivation: Microservices, while transformative for cloud computing, introduce complex security and management issues due to their decentralized nature, making system stability difficult to maintain.

Method: The paper proposes a framework utilizing the MAPE-K architectural model and agentic AI for autonomous anomaly detection and remediation in microservices environments.

Result: The proposed framework provides customizable and industry-ready solutions for system stability, reduced downtime, and improved monitoring of various system quality attributes (including security and resilience) in microservices.

Conclusion: By applying MAPE-K and agentic AI to microservices management, the framework enables practitioners and researchers to autonomously detect and respond to anomalies, thus ensuring robust and secure cloud systems.

Abstract: While microservices are revolutionizing cloud computing by offering
unparalleled scalability and independent deployment, their decentralized nature
poses significant security and management challenges that can threaten system
stability. We propose a framework based on MAPE-K, which leverages agentic AI,
for autonomous anomaly detection and remediation to address the daunting task
of highly distributed system management. Our framework offers practical,
industry-ready solutions for maintaining robust and secure microservices.
Practitioners and researchers can customize the framework to enhance system
stability, reduce downtime, and monitor broader system quality attributes such
as system performance level, resilience, security, and anomaly management,
among others.

</details>


### [8] [What Makes ChatGPT Effective for Software Issue Resolution? An Empirical Study of Developer-ChatGPT Conversations in GitHub](https://arxiv.org/abs/2506.22390)
*Ramtin Ehsani,Sakshi Pathak,Esteban Parra,Sonia Haiduc,Preetha Chatterjee*

Main category: cs.SE

TL;DR: Analysis of 686 GitHub developer-ChatGPT conversations shows ChatGPT excels at code gen and API suggestions, but not explanations. 62% of interactions aid issue resolution; shortcomings are often due to incorrect or incomplete info. Findings can help design better LLM tools and inform developer usage strategies.


<details>
  <summary>Details</summary>
Motivation: Despite the growing use of conversational LLMs for developer support, not all interactions with models like ChatGPT are beneficial for resolving issues. This paper seeks to understand what makes some developer-LLM conversations more effective than others for practical issue resolution.

Method: The authors collected and analyzed 686 developer-ChatGPT conversations from GitHub issue threads. They categorized types of tasks, compared helpful versus unhelpful conversations, explored relevant project and issue metrics, and identified deficiencies in ineffective ChatGPT responses.

Result: 62% of ChatGPT conversations were deemed helpful for issue resolution. ChatGPT was most effective for code generation and API/tool recommendations but less useful for code explanations. Helpful conversations were generally shorter, more readable, and better aligned in language. Benefit was higher in larger, popular projects and with experienced developers, especially for simpler, well-scoped issues. Unhelpful responses often contained incorrect or incomplete information.

Conclusion: The study reveals that while ChatGPT can significantly aid in issue resolution, its effectiveness is variable. Improving ChatGPT's response accuracy and comprehensiveness, along with guiding developers on prompt design, can enhance outcomes. These insights are valuable for both LLM tool design and developer strategies in leveraging conversational AI.

Abstract: Conversational large-language models are extensively used for issue
resolution tasks. However, not all developer-LLM conversations are useful for
effective issue resolution. In this paper, we analyze 686 developer-ChatGPT
conversations shared within GitHub issue threads to identify characteristics
that make these conversations effective for issue resolution. First, we analyze
the conversations and their corresponding issues to distinguish helpful from
unhelpful conversations. We begin by categorizing the types of tasks developers
seek help with to better understand the scenarios in which ChatGPT is most
effective. Next, we examine a wide range of conversational, project, and
issue-related metrics to uncover factors associated with helpful conversations.
Finally, we identify common deficiencies in unhelpful ChatGPT responses to
highlight areas that could inform the design of more effective developer-facing
tools. We found that only 62% of the ChatGPT conversations were helpful for
successful issue resolution. ChatGPT is most effective for code generation and
tools/libraries/APIs recommendations, but struggles with code explanations.
Helpful conversations tend to be shorter, more readable, and exhibit stronger
semantic and linguistic alignment. Larger, more popular projects and more
experienced developers benefit more from ChatGPT. At the issue level, ChatGPT
performs best on simpler problems with limited developer activity and faster
resolution, typically well-scoped tasks like compilation errors. The most
common deficiencies in unhelpful ChatGPT responses include incorrect
information and lack of comprehensiveness. Our findings have wide implications
including guiding developers on effective interaction strategies for issue
resolution, informing the development of tools or frameworks to support optimal
prompt design, and providing insights on fine-tuning LLMs for issue resolution
tasks.

</details>
