<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 12]
- [cs.PL](#cs.PL) [Total: 3]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [VTS-Guided AI Interaction Workflow for Business Insights](https://arxiv.org/abs/2507.00347)
*Sun Ding,Ude Enebeli,Atilhan,Manay,Ryan Pua,Kamal Kotak*

Main category: cs.SE

TL;DR: VTS-AI uses AI and Visual Thinking Strategies to extract actionable business insights from unstructured reports faster and with richer details than current methods, while keeping human feedback in the loop. Early results are promising, and further developments will enhance its reliability and security for business analysis.


<details>
  <summary>Details</summary>
Motivation: Modern organizations struggle to rapidly extract actionable insights from dense, unstructured business reports. The current methods are labor-intensive and lack agility, especially when quick answers are required.

Method: VTS-AI integrates Visual Thinking Strategies into AI agents, enabling extraction of business insights from unstructured text, tables, and images at scale. The system operates in three tiers (micro, meso, macro), tags issues, links them to source pages, and generates action items stored in a searchable YAML file. The workflow combines automated extraction with human judgment within an IDE.

Result: In tests on an 18-page business report, VTS-AI delivered results as quickly as a one-shot ChatGPT prompt but with richer output, including page locations, verbatim excerpts, severity scores, and causal links. The system supports analyst oversight and highlights metric directions and areas needing deeper analysis.

Conclusion: VTS-AI demonstrates promise as a scalable, agile tool for extracting and organizing insights from complex business reports. Planned enhancements—such as mapping narrative tags to financial ratios and adding security layers—aim to improve auditability and readiness for production use.

Abstract: Modern firms face a flood of dense, unstructured reports. Turning these
documents into usable insights takes heavy effort and is far from agile when
quick answers are needed. VTS-AI tackles this gap. It integrates Visual
Thinking Strategies, which emphasize evidence-based observation, linking, and
thinking, into AI agents, so the agents can extract business insights from
unstructured text, tables, and images at scale. The system works in three tiers
(micro, meso, macro). It tags issues, links them to source pages, and rolls
them into clear action levers stored in a searchable YAML file. In tests on an
18-page business report, VTS-AI matched the speed of a one-shot ChatGPT prompt
yet produced richer findings: page locations, verbatim excerpts, severity
scores, and causal links. Analysts can accept or adjust these outputs in the
same IDE, keeping human judgment in the loop. Early results show VTS-AI spots
the direction of key metrics and flags where deeper number-crunching is needed.
Next steps include mapping narrative tags to financial ratios, adding
finance-tuned language models through a Model-Context Protocol, and building a
Risk & Safety Layer to stress-test models and secure data. These upgrades aim
to make VTS-AI a production-ready, audit-friendly tool for rapid business
analysis.

</details>


### [2] [An AST-guided LLM Approach for SVRF Code Synthesis](https://arxiv.org/abs/2507.00352)
*Abanoub E. Abdelmalak,Mohamed A. Elsayed,David Abercrombie,Ilhami Torunoglu*

Main category: cs.SE

TL;DR: The paper presents a new method combining AST and RAG for generating SVRF code, achieving up to 40% higher accuracy over standard methods and streamlining semiconductor design workflows.


<details>
  <summary>Details</summary>
Motivation: Traditional SVRF development is becoming ineffective due to increasingly complex semiconductor design rules with advancing manufacturing nodes, exposing an expertise gap and workflow challenges.

Method: The authors introduce a methodology that combines Abstract Syntax Tree (AST) embedding and Retrieval-Augmented Generation (RAG) for SVRF code synthesis. They also use several T5-based models and present a specialized SVRF scoring framework alongside metrics like BLEU and ROUGE-L. Structural validation is provided by AST, while RAG contributes domain-specific information to enhance code generation accuracy.

Result: Testing on a benchmark of 740 DRC rule implementations shows up to a 40% improvement in code generation accuracy with the proposed methodology compared to typical text-based fine-tuning approaches.

Conclusion: Integrating domain expertise with advanced code generation strategies (AST and RAG) significantly enhances SVRF development, facilitating rapid design iteration, reducing manual errors, and boosting overall productivity, even with limited datasets.

Abstract: Standard Verification Rule Format (SVRF) is essential for semiconductor
applications like Design Rule Check (DRC), Layout Versus Schematic (LVS), and
Optical Proximity Correction (OPC) and it faces challenges as advancing nodes
create complex design rules that renders traditional SVRF development
ineffective and highlight an expertise gap. This paper introduces a novel
methodology integrating Abstract Syntax Tree (AST) embedding and
Retrieval-Augmented Generation (RAG) for enhanced SVRF code synthesis, ensuring
semantic accuracy and error minimization through structural validation with
domain-specific insights for precise code generation.
  We evaluate different T5-based models and propose an innovative SVRF-specific
scoring framework that complements standard metrics like BLEU and ROUGE-L. In
our approach, AST provides rigorous structural validation, while RAG infuses
relevant domain knowledge, effectively enhancing the code generation workflow.
  Testing on a comprehensive benchmark of 740 DRC rule implementations, our
methodology demonstrates up to a 40\% improvement in code generation accuracy
compared to basic text-based fine-tuning process. This fusion of industry
expertise with advanced coding strategies not only optimizes SVRF development
under limited dataset constraints but also creates a more intuitive and
efficient coding environment. Consequently, users can rapidly iterate through
design cycles, reduce manual error correction, and significantly improve
overall productivity.

</details>


### [3] [iPanda: An Intelligent Protocol Testing and Debugging Agent for Conformance Testing](https://arxiv.org/abs/2507.00378)
*Xikai Sun,Fan Dang,Kebin Liu,Xin Miao,Zihao Yang,Haimo Lu,Yawen Zheng,Yunhao Liu*

Main category: cs.SE

TL;DR: iPanda leverages LLMs to fully automate protocol conformance testing, achieving much higher test-code generation success than pure LLM methods.


<details>
  <summary>Details</summary>
Motivation: Conformance testing for protocol implementations is crucial but traditionally requires significant manual effort to create and maintain numerous test cases and scripts.

Method: The paper introduces iPanda, a framework that uses Large Language Models (LLMs) to automate protocol conformance testing. It uses a keyword-based generation for test cases, retrieval-augmented generation to interpret code, and an iterative self-correction loop to refine generated scripts, concluding with automated execution and compliance verification.

Result: Experiments demonstrate that iPanda significantly improves automated test-code generation, with Pass@1 success rates 4.675–10.751 times higher than pure LLM-based methods.

Conclusion: iPanda is an effective, automated end-to-end solution for protocol conformance testing, greatly reducing manual workload and achieving superior performance over existing LLM-only techniques.

Abstract: Conformance testing is essential for ensuring that protocol implementations
comply with their specifications. However, traditional testing approaches
involve manually creating numerous test cases and scripts, making the process
labor-intensive and inefficient. Recently, Large Language Models (LLMs) have
demonstrated impressive text comprehension and code generation abilities,
providing promising opportunities for automation. In this paper, we propose
iPanda, the first end-to-end framework that leverages LLMs to automate protocol
conformance testing. Given a protocol specification document and its
implementation, iPanda first employs a keyword-based method to automatically
generate comprehensive test cases. Then, it utilizes a code-based
retrieval-augmented generation approach to effectively interpret the
implementation and produce executable test code. To further enhance code
quality, iPanda incorporates an iterative self-correction mechanism to refine
generated test scripts interactively. Finally, by executing and analyzing the
generated tests, iPanda systematically verifies compliance between
implementations and protocol specifications. Comprehensive experiments on
various protocols show that iPanda significantly outperforms pure LLM-based
approaches, improving the success rate (Pass@1) of test-code generation by
factors ranging from 4.675 times to 10.751 times.

</details>


### [4] [Recommending Variable Names for Extract Local Variable Refactorings](https://arxiv.org/abs/2507.00413)
*Taiming Wang,Hui Liu,Yuxia Zhang,Yanjie Jiang*

Main category: cs.SE

TL;DR: Automated IDE suggestions for variable names often miss the mark. VarNamer uses empirical and heuristic methods to recommend better names, outperforming state-of-the-art tools in accuracy and efficiency. It's been adopted in Eclipse and proven useful in both Java and C++ projects, streamlining the refactoring process for developers.


<details>
  <summary>Details</summary>
Motivation: Automated refactoring tools often suggest variable names that don't match developers' preferences, resulting in extra renaming work and reduced usefulness of such tools. This paper wants to improve the quality of variable name recommendations to better assist developers during extract local variable refactorings.

Method: The authors conducted a large-scale empirical study to identify important contexts for creating variable names. Based on this, they developed heuristic rules using static analysis and data mining for recommending variable names. They integrated some of these heuristics into Eclipse and evaluated the approach through empirical comparison and user studies.

Result: VarNamer, the proposed tool, increased the exact match rate of suggested names by 52.6% over Eclipse and 40.7% over IntelliJ IDEA. User studies showed that VarNamer sped up refactoring by 27.8% and reduced naming edits by 49.3%. The method also showed comparable results on C++ projects, indicating potential generalizability beyond Java.

Conclusion: VarNamer significantly outperforms existing IDEs in variable name recommendation for extract local variable refactoring, reducing developer effort and showing effectiveness across different programming languages. Some techniques have been adopted by major IDEs, and user studies confirm its practical usefulness.

Abstract: Extract local variable is one of the most popular refactorings, and most IDEs
and refactoring tools provide automated support for this refactoring. However,
we find approximately 70% of the names recommended by these IDEs are different
from what developers manually constructed, adding additional renaming burdens
to developers and providing limited assistance. In this paper, we introduce
VarNamer, an automated approach designed to recommend variable names for
extract local variable refactorings. Through a large-scale empirical study, we
identify key contexts that are useful for composing variable names. Leveraging
these insights, we developed a set of heuristic rules through program static
analysis techniques and employ data mining techniques to recommend variable
names effectively. Notably, some of our heuristic rules have been successfully
integrated into Eclipse, where they are now distributed with the latest
releases of the IDE. Evaluation demonstrates its superiority over
state-of-the-art IDEs. Specifically, VarNamer significantly increases the
chance of exact match by 52.6% compared to Eclipse and 40.7% compared to
IntelliJ IDEA. We also evaluated the proposed approach with real-world extract
local variable refactorings conducted in C++ projects, and the results suggest
that the approach can achieve comparable performance on programming languages
besides Java. It may suggest the generalizability of VarNamer. Finally, we
designed and conducted a user study and the results of the user study suggest
that our approach can speed up the refactoring by 27.8% and reduce 49.3% edits
on the recommended variable names.

</details>


### [5] [Embedded DevOps: A Survey on the Application of DevOps Practices in Embedded Software and Firmware Development](https://arxiv.org/abs/2507.00421)
*Parthiv Katapara,Anand Sharma*

Main category: cs.SE

TL;DR: DevOps is gradually being adapted for embedded systems, but faces significant challenges due to hardware and real-time constraints. This literature review organizes ongoing efforts, highlights current gaps, and suggests directions for future research.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the increasing complexity of hardware-software co-designed products, which makes traditional development techniques insufficient. DevOps practices, while well established in cloud-native environments, face unique challenges in embedded systems due to factors like hardware dependency and safety-critical requirements.

Method: The paper conducts a literature review, synthesizing 20 academic and industrial sources, categorizing efforts in tooling, testing, automation, and security related to adopting DevOps in embedded contexts.

Result: The review finds that while DevOps principles such as CI/CD and automated testing are being adapted for embedded systems, significant limitations remain, particularly in deployment workflows and observability. It categorizes current research and practice, and identifies research gaps.

Conclusion: The work consolidates fragmented information about Embedded DevOps, highlighting current limitations and providing a structured roadmap for future research, aimed at both researchers and practitioners.

Abstract: The adoption of DevOps practices in embedded systems and firmware development
is emerging as a response to the growing complexity of modern
hardware--software co-designed products. Unlike cloud-native applications,
embedded systems introduce challenges such as hardware dependency, real-time
constraints, and safety-critical requirements. This literature review
synthesizes findings from 20 academic and industrial sources to examine how
DevOps principles--particularly continuous integration, continuous delivery,
and automated testing--are adapted to embedded contexts. We categorize efforts
across tooling, testing strategies, pipeline automation, and security
practices. The review highlights current limitations in deployment workflows
and observability, proposing a roadmap for future research. This work offers
researchers and practitioners a consolidated understanding of Embedded DevOps,
bridging fragmented literature with a structured perspective.

</details>


### [6] [The Influence of HEXACO Personality Traits on the Teamwork Quality in Software Teams -- A Preliminary Research Approach](https://arxiv.org/abs/2507.00481)
*Philipp M. Zähl,Sabine Theis,Martin R. Wolf*

Main category: cs.SE

TL;DR: Personality traits, measured using the HEXACO model, significantly affect teamwork quality in software teams. Preliminary findings suggest that these human factors may be more influential than processes or technology, emphasizing the need for IT organizations to consider personality composition in team formation. Demographic factors like gender ratio and age distribution also play a role.


<details>
  <summary>Details</summary>
Motivation: While much of software engineering research concentrates on optimizing processes and technology, there is increasing awareness that human elements, especially teamwork and individual developer personalities, may be equally or more impactful. This paper is motivated by the need to understand how personality traits influence teamwork quality in software teams.

Method: The authors designed a study investigating the relationship between HEXACO personality traits and Teamwork Quality (TWQ) in software teams. A preliminary data collection was carried out with 54 participants, analyzing how individual and collective personality traits, as well as demographic variables, affect TWQ.

Result: The preliminary analysis found that specific personality traits and their group compositions significantly influenced Teamwork Quality. Demographic factors such as the proportion of women and age distribution also had measurable effects on TWQ.

Conclusion: The initial results support the utility and validity of the study design, revealing that personality traits are a significant factor in teamwork quality. The study points to possible improvements for teamwork in IT organizations and highlights directions for future research.

Abstract: Although software engineering research has focused on optimizing processes
and technology, there is a growing recognition that human factors, particularly
teamwork, also significantly impact optimization. Recent research suggests that
developer personality has a strong influence on teamwork. In fact, personality
considerations may have a greater impact on software development than processes
and tools. This paper aims to design a study that measures the impact of HEXACO
personality traits on the Teamwork Quality (TWQ) of software teams. A
preliminary data collection (n=54) was conducted for this purpose. The analysis
showed that several personality traits, as well as their composition, had a
significant impact on TWQ. Additionally, other variables, such as the
proportion of women and age distribution, also affected TWQ. The study's
initial results demonstrate the usefulness and validity of the study design.
The results also suggest several opportunities to improve teamwork in IT
organizations and avenues for further research.

</details>


### [7] [Coverage-Guided Testing for Deep Learning Models: A Comprehensive Survey](https://arxiv.org/abs/2507.00496)
*Hongjing Guo,Chuanqi Tao,Zhiqiu Huang,Weiqin Zou*

Main category: cs.SE

TL;DR: This paper reviews and categorizes the latest coverage-guided testing methods for deep learning models, highlighting trends, evaluation practices, and ongoing challenges, and proposes directions for future research to ensure model quality in safety-critical applications.


<details>
  <summary>Details</summary>
Motivation: Deep learning models are increasingly used in critical applications where errors can have serious consequences. However, ensuring the quality of these models is challenging, and existing coverage-guided testing (CGT) research is fragmented, making it hard to track progress and identify trends.

Method: The paper performs a comprehensive review of current CGT methods for deep learning models. It analyzes state-of-the-art techniques within three main areas: test coverage analysis, test input generation, and input optimization. The paper constructs taxonomies to classify these methods and studies evaluation practices such as benchmark datasets and model architectures used.

Result: The review organizes and categorizes existing CGT approaches, providing a structured understanding of methodological characteristics and application contexts. It identifies current evaluation practices and gaps, and outlines open challenges including standardization, tool support, method generalizability, and links between coverage and testing objectives.

Conclusion: The paper lays out a comprehensive roadmap for further research and practical improvements in quality assurance for deep learning models using coverage-guided testing, highlighting areas needing future work and standardization.

Abstract: As Deep Learning (DL) models are increasingly applied in safety-critical
domains, ensuring their quality has emerged as a pressing challenge in modern
software engineering. Among emerging validation paradigms, coverage-guided
testing (CGT) has gained prominence as a systematic framework for identifying
erroneous or unexpected model behaviors. Despite growing research attention,
existing CGT studies remain methodologically fragmented, limiting the
understanding of current advances and emerging trends. This work addresses that
gap through a comprehensive review of state-of-the-art CGT methods for DL
models, including test coverage analysis, coverage-guided test input
generation, and coverage-guided test input optimization. This work provides
detailed taxonomies to organize these methods based on methodological
characteristics and application scenarios. We also investigate evaluation
practices adopted in existing studies, including the use of benchmark datasets,
model architectures, and evaluation aspects. Finally, open challenges and
future directions are highlighted in terms of the correlation between
structural coverage and testing objectives, method generalizability across
tasks and models, practical deployment concerns, and the need for standardized
evaluation and tool support. This work aims to provide a roadmap for future
academic research and engineering practice in DL model quality assurance.

</details>


### [8] [A Domain-specific Language and Architecture for Detecting Process Activities from Sensor Streams in IoT](https://arxiv.org/abs/2507.00686)
*Ronny Seiger,Daniel Locher,Marco Kaufmann,Aaron F. Kurz*

Main category: cs.SE

TL;DR: The paper presents Radiant, a DSL that lets experts transform raw IoT sensor data into meaningful business process events using pattern definitions. This enables real-time monitoring and process mining in IoT systems, demonstrated in manufacturing and healthcare.


<details>
  <summary>Details</summary>
Motivation: Sensor data in IoT systems is often too detailed (fine-grained) to provide insights at the business process level. Process mining can analyze high-level processes, but bridging the gap from raw sensor data requires abstraction.

Method: The authors developed a domain-specific language (DSL) called Radiant. Radiant allows domain experts to specify patterns in sensor data that correlate with higher-level process activities. These patterns are converted into complex event processing (CEP) applications, which are then executed in a proposed software architecture to abstract and monitor events in real-time. The approach is evaluated in smart manufacturing and healthcare scenarios.

Result: Radiant successfully enables online abstraction and monitoring of business process activities from IoT sensor data. The evaluation demonstrates that activities can be detected and monitored at runtime, and the results help domain experts assess and improve the quality of detections.

Conclusion: Introducing Radiant enables domain experts to bridge the gap between low-level IoT sensor data and high-level business process insights, supporting effective process mining in IoT contexts. The method is viable in smart manufacturing and healthcare, and can inform further refinements in detection quality.

Abstract: Modern Internet of Things (IoT) systems are equipped with a plethora of
sensors providing real-time data about the current operations of their
components, which is crucial for the systems' internal control systems and
processes. However, these data are often too fine-grained to derive useful
insights into the execution of the larger processes an IoT system might be part
of. Process mining has developed advanced approaches for the analysis of
business processes that may also be used in the context of IoT. Bringing
process mining to IoT requires an event abstraction step to lift the low-level
sensor data to the business process level. In this work, we aim to empower
domain experts to perform this step using a newly developed domain-specific
language (DSL) called Radiant. Radiant supports the specification of patterns
within the sensor data that indicate the execution of higher level process
activities. These patterns are translated to complex event processing (CEP)
applications to be used for detecting activity executions at runtime. We
propose a corresponding software architecture for online event abstraction from
IoT sensor streams using the CEP applications. We evaluate these applications
to monitor activity executions using IoT sensors in smart manufacturing and
smart healthcare. The evaluation method and results inform the domain expert
about the quality of activity detections and potential for improvement.

</details>


### [9] [A Hierarchical and Evolvable Benchmark for Fine-Grained Code Instruction Following with Multi-Turn Feedback](https://arxiv.org/abs/2507.00699)
*Guoliang Duan,Mingwei Liu,Yanlin Wang,Chong Wang,Xin Peng,Zibin Zheng*

Main category: cs.SE

TL;DR: MultiCodeIF is a new, multi-dimensional benchmark for testing how well LLMs follow complex coding instructions involving layered and non-functional constraints. Results reveal large gaps in model performance, especially with multi-level or implicit constraints, but also show that structured feedback can notably boost model performance through iterative refinement. The dataset and tools are publicly released.


<details>
  <summary>Details</summary>
Motivation: While large language models excel at code generation, their ability to follow layered and complex instructions with diverse constraints—especially beyond functional correctness—remains insufficiently studied. Current benchmarks mainly focus on whether generated code works, not on whether all requirements, including subtle or non-functional ones, are properly followed. There is thus a need for a more comprehensive evaluation framework.

Method: The authors introduce MultiCodeIF, a new benchmark designed to assess instruction-following in code generation under multiple types and levels of constraints. The benchmark leverages a taxonomy organizing constraints into 9 categories and 27 types. Using an automatic pipeline called ConstraGen, they synthesize and evolve over 2,000 code tasks in 14 programming languages, supporting multi-turn evaluation with feedback-driven refinement. Six leading LLMs are evaluated on these tasks regarding their adherence to both functional and non-functional instructions.

Result: Results show that there are significant differences in how well LLMs adhere to instructions, especially under complex constraints. The best model scored 63% on constraint satisfaction, dropping steeply for tasks with hierarchical, multi-level constraints. Models perform better on explicit constraints than implicit or abstract ones. However, the ability to iteratively refine outputs via feedback significantly improves LLM performance, raising satisfaction rates up to 83.4% after several rounds.

Conclusion: MultiCodeIF sets a new standard for evaluating LLM code generation under realistic, constraint-rich instructions, identifying major gaps in current model capabilities (especially with complex or abstract requirements). It also demonstrates the importance of feedback-driven refinement for improving adherence. The benchmark and tools are publicly available for broader use.

Abstract: Large language models (LLMs) have advanced significantly in code generation,
yet their ability to follow complex programming instructions with layered and
diverse constraints remains underexplored. Existing benchmarks often prioritize
functional correctness, overlooking the nuanced requirements found in
real-world development. We introduce MultiCodeIF, a comprehensive benchmark
designed to evaluate instruction-following in code generation across multiple
dimensions: constraint type, hierarchical levels, and iterative refinement.
Built upon a structured taxonomy of 9 categories and 27 constraint types,
MultiCodeIF enables granular assessment of both functional and non-functional
instruction adherence. Using an automated pipeline, ConstraGen, we synthesize
and evolve 2,021 code tasks sourced from 14 programming languages, supporting
multi-turn evaluation through feedback-driven task variants. Empirical
evaluation of six state-of-the-art LLMs uncovers substantial performance
disparities. The top-performing model, Claude-3-7-Sonnet, achieves 63.0%
average constraint satisfaction, while smaller models like Qwen3-1.7B fall to
44.8%. Models perform well on explicit constraints, but struggle with implicit
or abstract constraints. Tasks with multiple hierarchical constraints
significantly reduce model success rates, from 54.5% in single-level to just
18.8% in multi-level scenarios. However, structured feedback enables
progressive improvement: average constraint satisfaction rises from 63.0% to
83.4% over four iterative refinement rounds. MultiCodeIF provides a scalable,
constraint-aware, and feedback-sensitive framework to benchmark LLMs under
realistic code generation scenarios, bridging the gap between synthetic
evaluations and real-world instruction complexity. The full benchmark dataset,
evaluation pipeline, and source code are available at
https://github.com/SYSUSELab/MultiCodeIF.

</details>


### [10] [Snaps: Bloated and Outdated?](https://arxiv.org/abs/2507.00786)
*Jukka Ruohonen,Qusai Ramadan*

Main category: cs.SE

TL;DR: Snap packages, while designed for cross-distribution compatibility, tend to be larger and less frequently updated than ideal, raising concerns about efficiency and freshness in software delivery.


<details>
  <summary>Details</summary>
Motivation: Snap was developed to handle software packaging challenges across diverse Linux distributions, aiming for more interoperable software delivery. However, there have been ongoing concerns and criticisms regarding the effectiveness of Snap.

Method: The paper conducts empirical analyses on currently distributed Snap packages, specifically evaluating their size (bloat) and update frequencies (timeliness).

Result: The analysis found that Snap packages are on average larger (bloated) and less frequently updated (outdated) than expected.

Conclusion: The findings highlight current weaknesses in Snap's implementation—specifically package bloat and slow update cycles, contributing empirical evidence to the ongoing debates in the software packaging community.

Abstract: Snap is an alternative software packaging system developed by Canonical and
provided by default in the Ubuntu Linux distribution. Given the heterogeneity
of various Linux distributions and their various releases, Snap allows an
interoperable delivery of software directly to users. However, concerns and
criticism have also been frequently expressed. Regarding this criticism, the
paper shows that currently distributed snap packages are indeed on average
bloated in terms of their sizes and outdated in terms updating frequencies.
With these empirical observations, this short paper contributes to the research
domain of software packaging, software packages, and package managers.

</details>


### [11] [Echoes of AI: Investigating the Downstream Effects of AI Assistants on Software Maintainability](https://arxiv.org/abs/2507.00788)
*Markus Borg,Dave Hewett,Nadim Hagatulah,Noric Couderc,Emma Söderberg,Donald Graham,Uttam Kini,Dave Farley*

Main category: cs.SE

TL;DR: Using AI assistants like GitHub Copilot can make professional developers faster without making code harder to maintain, especially for those who regularly use such tools. However, further study is needed on long-term maintainability issues like code bloat and cognitive debt.


<details>
  <summary>Details</summary>
Motivation: AI assistants like GitHub Copilot are known to improve productivity in software engineering, but their impact on code maintainability—specifically, how easily others can modify and evolve the code—has not been fully explored. This paper addresses that gap.

Method: The researchers conducted a two-phase controlled experiment involving 151 mostly professional developers. In Phase 1, participants developed new features for a Java web app, with or without AI assistance. In Phase 2, different participants attempted to evolve the previously written solutions, all without AI assistance.

Result: AI-assisted development led to a modest speedup in subsequent code evolution and slightly increased CodeHealth for the resulting codebase, particularly for habitual AI users. However, these improvements were not statistically significant overall, except the CodeHealth increase for habitual users. Notably, AI assistance provided a significant productivity boost, especially for users accustomed to AI assistants.

Conclusion: AI assistants can accelerate software development without introducing observable negative effects on code maintainability. There are potential risks, such as code bloat and cognitive debt, which future research should investigate.

Abstract: [Context] AI assistants, like GitHub Copilot and Cursor, are transforming
software engineering. While several studies highlight productivity
improvements, their impact on maintainability requires further investigation.
[Objective] This study investigates whether co-development with AI assistants
affects software maintainability, specifically how easily other developers can
evolve the resulting source code. [Method] We conducted a two-phase controlled
experiment involving 151 participants, 95% of whom were professional
developers. In Phase 1, participants added a new feature to a Java web
application, with or without AI assistance. In Phase 2, a randomized controlled
trial, new participants evolved these solutions without AI assistance.
[Results] AI-assisted development in Phase 1 led to a modest speedup in
subsequent evolution and slightly higher average CodeHealth. Although neither
difference was significant overall, the increase in CodeHealth was
statistically significant when habitual AI users completed Phase 1. For Phase
1, we also observed a significant effect that corroborates previous
productivity findings: using an AI assistant yielded a 30.7% median decrease in
task completion time. Moreover, for habitual AI users, the mean speedup was
55.9%. [Conclusions] Our study adds to the growing evidence that AI assistants
can effectively accelerate development. Moreover, we did not observe warning
signs of degraded code-level maintainability. We recommend that future research
focus on risks such as code bloat from excessive code generation and the
build-up of cognitive debt as developers invest less mental effort during
implementation.

</details>


### [12] [Out of the Day Job: Perspectives of Industry Practitioners in Co-Design and Delivery of Software Engineering Courses](https://arxiv.org/abs/2507.00803)
*Gillian Daniel,Chris Hall,Per Hammer,Alec-Angus Macdonald,Hollie Marwick-Best,Emma McKenzie,George Popa,Derek Somerville,Tim Storer*

Main category: cs.SE

TL;DR: This paper analyzes the perspectives of industry practitioners involved in co-designing and delivering software engineering courses with the University of Glasgow, revealing their motivations and offering recommendations to sustain such industry-academic partnerships.


<details>
  <summary>Details</summary>
Motivation: Although industry-academic collaborations in software engineering education are common and recognized as beneficial, there is limited research on the perspectives of industry practitioners who participate in co-design and delivery of courses. This paper seeks to understand their motivations, expectations, and experiences, as their substantial investment needs to be supported for sustainable partnerships.

Method: The study conducts a retrospective analysis among the practitioner coauthors, facilitated by academic coauthors. All coauthors have experience in co-design and delivery of software engineering courses at the University of Glasgow, but the analysis focuses on thematic discussions from the practitioners' viewpoint.

Result: The paper identifies key themes that emerged from the practitioners' discussions, outlining their experiences, motivations, and challenges in course co-design and delivery. The study culminates in practical recommendations to guide future collaborations and support the sustainability of industry-academic partnerships.

Conclusion: The perspectives of industry practitioners are under-explored but crucial for maintaining effective and sustainable collaborations in software engineering education. By capturing these viewpoints, the paper provides insights and actionable recommendations that can improve future course co-design efforts.

Abstract: Over more than two decades, The University of Glasgow has co-designed and
delivered numerous software engineering focused courses with industry partners,
covering both technical and discipline specific professional skills. Such
collaborations are not unique and many of the benefits are well recognised in
the literature. These include enhancing the real-world relevance of curricula,
developing student professional networks ahead of graduation and easing
recruitment opportunities for employers.
  However, there is relatively little scholarship on the perspectives of
industry practitioners who participate in course design and delivery. This gap
is significant, since the effort invested by practitioners is often substantial
and may require ongoing support from both the industry partner and academic
institution. Understanding the motivations, expectations and experiences of
practitioners who engage in course delivery can guide the formation of future
partnerships and ensure their long-term sustainability.
  We begin to address this gap by reporting on the outcomes of a retrospective
conducted amongst the practitioner coauthors of this paper, with the academic
coauthors acting as facilitators. All coauthors have participated in the recent
co-design and delivery of software engineering courses, but we choose to focus
explicitly on the perspectives of the practitioners. We report on the themes
that emerged from the discussions and our resulting recommendations for future
collaborations.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [13] [Estimating Correctness Without Oracles in LLM-Based Code Generation](https://arxiv.org/abs/2507.00057)
*Thomas Valentin,Ardi Madadi,Gaetano Sapia,Marcel Böhme*

Main category: cs.PL

TL;DR: The paper proposes 'incoherence' as a new way to measure code incorrectness from LLM-generated code without needing a reference solution. This method efficiently detects most incorrect programs and closely matches traditional evaluation techniques.


<details>
  <summary>Details</summary>
Motivation: Large Language Models (LLMs) are effective at generating code from natural language, but they sometimes produce code that is syntactically correct but semantically wrong ('hallucinations'). Currently, assessing code correctness requires a known correct implementation (an 'oracle'), which is often unavailable. There's a need for a way to estimate the correctness of generated code without an oracle.

Method: The authors introduce a new metric called 'incoherence' to estimate code incorrectness. This incoherence metric can be calculated efficiently and does not rely on having an oracle (a correct reference implementation). The method is validated experimentally by comparing incoherence-based evaluation with traditional oracle-based assessment.

Result: The proposed incoherence measure identifies about two-thirds of all incorrect code outputs without false positives. The incoherence-based approach shows a very high correlation with traditional oracle-based evaluation, enabling reliable code assessment even when an oracle is not available.

Conclusion: Incoherence can serve as an effective proxy for oracle-based evaluations, enabling efficient and automated identification of incorrect code generated by LLMs without access to a ground truth implementation.

Abstract: Generating code from natural language specifications is one of the most
successful applications of Large Language Models (LLMs). Yet, they hallucinate:
LLMs produce outputs that may be grammatically correct but are factually
incorrect. Without an existing, correct implementation (i.e., an oracle), can
we quantify how likely the generated program is correct?
  In this paper, we propose a measure of incorrectness, called incoherence,
that can be estimated efficiently in the absence of an oracle and provides a
lower bound on the error, i.e., the probability that the LLM-generated program
for that specification is incorrect. Our experiments demonstrate an
extraordinary effectiveness. For the average code generation task, our
incoherence-based methodology can automatically identify about two-thirds of
incorrect programs without reports of false positives. In fact, an oracle-based
evaluation of LLMs can be reliably replaced by an incoherence-based evaluation.
In particular, we find a very strong agreement between the ranking of LLMs by
the number of programs deemed correct via an oracle (pass@1) and the ranking of
LLMs by the number of programs deemed correct via our incoherence.

</details>


### [14] [Rust vs. C for Python Libraries: Evaluating Rust-Compatible Bindings Toolchains](https://arxiv.org/abs/2507.00264)
*Isabella Basso do Amaral,Renato Cordeiro Ferreira,Alfredo Goldman*

Main category: cs.PL

TL;DR: PyO3 enables high-performance Python extensions with Rust, offering better speed and easier integration than ctypes/cffi, and simplifies maintaining compatibility.


<details>
  <summary>Details</summary>
Motivation: Python is widely used and popular for its easy syntax and scientific libraries, but is hampered by a slow interpreter. Optimizing Python's performance often requires complex and challenging integration with lower-level languages, which can be cumbersome using traditional tools or third-party libraries.

Method: This paper conducts a comparative study, evaluating the performance and ease of use of PyO3 (a toolchain for binding Rust code to Python) versus the traditional Python C interface libraries like ctypes and cffi.

Result: Using Rust with the PyO3 toolchain allows developers to achieve state-of-the-art performance improvements for critical Python code sections, while avoiding compatibility headaches associated with API changes and binary-level interactions.

Conclusion: PyO3 presents a robust and user-friendly alternative for optimizing Python code using Rust, outperforming traditional tools (ctypes, cffi) in both performance and usability, and reducing maintenance and integration complexity.

Abstract: The Python programming language is best known for its syntax and scientific
libraries, but it is also notorious for its slow interpreter. Optimizing
critical sections in Python entails special knowledge of the binary
interactions between programming languages, and can be cumbersome to interface
manually, with implementers often resorting to convoluted third-party
libraries. This comparative study evaluates the performance and ease of use of
the PyO3 Python bindings toolchain for Rust against ctypes and cffi. By using
Rust tooling developed for Python, we can achieve state-of-the-art performance
with no concern for API compatibility.

</details>


### [15] [Have Object-Oriented Languages Missed a Trick with Class Function and its Subclasses?](https://arxiv.org/abs/2507.00488)
*Lloyd Allison*

Main category: cs.PL

TL;DR: Current programming languages don't fully classify functions like mathematics does. This paper explores creating a 'Function' class and subclasses for certain function types in popular OO languages, showing that better function classification is possible and beneficial.


<details>
  <summary>Details</summary>
Motivation: The paper is motivated by the observation that functions in programming languages are less systematically categorized (or 'classified') than mathematical functions. Although functional programming and recent developments in OO languages allow functions as values, there is no 'class Function' or subclasses representing particular function properties, which is seen as a missed opportunity.

Method: The paper proposes and implements various subclasses of a Function class, corresponding to functions with specific properties, in a selection of popular programming languages. This experimental approach examines how object-oriented languages could benefit from more explicit and structured classifications of functions.

Result: By introducing subclasses of Function in object-oriented programming languages, the authors demonstrate that this richer classification system is both feasible and potentially advantageous. The experiments show opportunities for improved structure and expressiveness in handling functions within existing programming environments.

Conclusion: Object-oriented programming languages could benefit from a more deliberate classification of functions, including the use of a base Function class and related subclasses describing specific function properties. Such an approach is implementable in current languages and may enrich the way programmers utilize and reason about functions.

Abstract: Compared to functions in mathematics, functions in programming languages seem
to be under classified. Functional programming languages based on the lambda
calculus famously treat functions as first-class values. Object-oriented
languages have adopted ``lambdas'', notably for call-back routines in
event-based programming. Typically a programming language has functions, a
function has a type, and some functions act on other functions and/or return
functions but there is generally a lack of (i) ``class Function'' in the OO
sense of the word class and particularly (ii) subclasses of Function for
functions having specific properties. Some such classes are presented here and
programmed in some popular programming languages as an experimental
investigation into OO languages missing this opportunity.

</details>
