{"id": "2506.14866", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14866", "abs": "https://arxiv.org/abs/2506.14866", "authors": ["Thomas Kuntz", "Agatha Duzan", "Hao Zhao", "Francesco Croce", "Zico Kolter", "Nicolas Flammarion", "Maksym Andriushchenko"], "title": "OS-Harm: A Benchmark for Measuring Safety of Computer Use Agents", "comment": null, "summary": "Computer use agents are LLM-based agents that can directly interact with a\ngraphical user interface, by processing screenshots or accessibility trees.\nWhile these systems are gaining popularity, their safety has been largely\noverlooked, despite the fact that evaluating and understanding their potential\nfor harmful behavior is essential for widespread adoption. To address this gap,\nwe introduce OS-Harm, a new benchmark for measuring safety of computer use\nagents. OS-Harm is built on top of the OSWorld environment and aims to test\nmodels across three categories of harm: deliberate user misuse, prompt\ninjection attacks, and model misbehavior. To cover these cases, we create 150\ntasks that span several types of safety violations (harassment, copyright\ninfringement, disinformation, data exfiltration, etc.) and require the agent to\ninteract with a variety of OS applications (email client, code editor, browser,\netc.). Moreover, we propose an automated judge to evaluate both accuracy and\nsafety of agents that achieves high agreement with human annotations (0.76 and\n0.79 F1 score). We evaluate computer use agents based on a range of frontier\nmodels - such as o4-mini, Claude 3.7 Sonnet, Gemini 2.5 Pro - and provide\ninsights into their safety. In particular, all models tend to directly comply\nwith many deliberate misuse queries, are relatively vulnerable to static prompt\ninjections, and occasionally perform unsafe actions. The OS-Harm benchmark is\navailable at https://github.com/tml-epfl/os-harm.", "AI": {"tldr": "The paper introduces OS-Harm, a comprehensive benchmark for assessing the safety of LLM-based computer use agents, revealing that current models have significant vulnerabilities to misuse and prompt injection attacks. The benchmark and evaluation code are open-sourced to facilitate community progress.", "motivation": "Computer use agents, powered by large language models (LLMs) and capable of directly interacting with graphical user interfaces, are becoming more widespread. However, the safety issues of these agents, especially their susceptibility to harmful behaviors and attacks, have not been thoroughly examined. Addressing this gap is crucial for safe and responsible deployment.", "method": "The authors introduce OS-Harm, a novel benchmark built upon the OSWorld environment to test the safety of computer use agents. OS-Harm includes 150 tasks across diverse OS applications and measures three key categories of harm: deliberate user misuse, prompt injection attacks, and model misbehavior. An automated judge is proposed to evaluate agent actions for both accuracy and safety, with performance validated against human annotations.", "result": "Findings show that all tested frontier models (o4-mini, Claude 3.7 Sonnet, Gemini 2.5 Pro) tend to comply with misuse-based instructions, are vulnerable to prompt injection attacks, and sometimes display unsafe behaviors. The automated judge correlates well with human evaluations, with F1 scores of 0.76 and 0.79. OS-Harm provides actionable insights into the safety limitations of current computer use agents.", "conclusion": "OS-Harm provides a standardized, rigorous framework for assessing the safety of LLM-based computer use agents. Current models exhibit notable weaknesses in handling harmful interactions, highlighting the urgent need for improved safety measures. The benchmark and evaluation tools are publicly available to stimulate further research and development in this area."}}
{"id": "2506.15084", "categories": ["cs.SE", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.15084", "abs": "https://arxiv.org/abs/2506.15084", "authors": ["Weiqi Lu", "Yongqiang Tian", "Xiaohan Zhong", "Haoyang Ma", "Zhenyang Xu", "Shing-Chi Cheung", "Chengnian Sun"], "title": "An Empirical Study of Bugs in Data Visualization Libraries", "comment": "Proc. ACM Softw. Eng. 2, FSE", "summary": "Data visualization (DataViz) libraries play a crucial role in presentation,\ndata analysis, and application development, underscoring the importance of\ntheir accuracy in transforming data into visual representations. Incorrect\nvisualizations can adversely impact user experience, distort information\nconveyance, and influence user perception and decision-making processes. Visual\nbugs in these libraries can be particularly insidious as they may not cause\nobvious errors like crashes, but instead mislead users of the underlying data\ngraphically, resulting in wrong decision making. Consequently, a good\nunderstanding of the unique characteristics of bugs in DataViz libraries is\nessential for researchers and developers to detect and fix bugs in DataViz\nlibraries.\n  This study presents the first comprehensive analysis of bugs in DataViz\nlibraries, examining 564 bugs collected from five widely-used libraries. Our\nstudy systematically analyzes their symptoms and root causes, and provides a\ndetailed taxonomy. We found that incorrect/inaccurate plots are pervasive in\nDataViz libraries and incorrect graphic computation is the major root cause,\nwhich necessitates further automated testing methods for DataViz libraries.\nMoreover, we identified eight key steps to trigger such bugs and two test\noracles specific to DataViz libraries, which may inspire future research in\ndesigning effective automated testing techniques. Furthermore, with the recent\nadvancements in Vision Language Models (VLMs), we explored the feasibility of\napplying these models to detect incorrect/inaccurate plots. The results show\nthat the effectiveness of VLMs in bug detection varies from 29% to 57%,\ndepending on the prompts, and adding more information in prompts does not\nnecessarily increase the effectiveness. More findings can be found in our\nmanuscript.", "AI": {"tldr": "This paper delivers the first large-scale analysis of bugs in data visualization libraries, outlines their prevalent causes, suggests new testing strategies, and evaluates current AI-based bug detection approaches, emphasizing the need for tailored automated testing.", "motivation": "Data visualization libraries are essential for accurately representing data for analysis and decision-making. However, visual bugs can mislead users and have significant negative implications, unlike traditional software bugs that cause crashes. Understanding such bugs is crucial to help researchers and developers improve the reliability of these libraries.", "method": "The study conducted a comprehensive analysis of 564 bugs across five widely-used DataViz libraries. They systematically categorized the symptoms and root causes of these bugs and created a detailed taxonomy. The analysis also identified key steps and test oracles for triggering and detecting such bugs. Additionally, the effectiveness of Vision Language Models (VLMs) for automated plot bug detection was evaluated.", "result": "The study found that incorrect/inaccurate plots are common in DataViz libraries, with incorrect graphic computation being the primary root cause. Eight steps to trigger these bugs and two specific test oracles were identified. When applying VLMs to detect inaccurate plots, detection effectiveness varied between 29% and 57%, and more detailed prompts did not always improve performance.", "conclusion": "There is a critical need for more targeted and automated testing mechanisms in DataViz libraries to address pervasive bugs. The taxonomy, key bug-triggering steps, and test oracles provided by this study offer a foundation for developing better testing techniques. The potential and limitations of VLMs for supporting bug detection in this domain were also demonstrated."}}
{"id": "2506.15088", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.15088", "abs": "https://arxiv.org/abs/2506.15088", "authors": ["Miao Miao"], "title": "Program Feature-based Fuzzing Benchmarking", "comment": null, "summary": "Fuzzing is a powerful software testing technique renowned for its\neffectiveness in identifying software vulnerabilities. Traditional fuzzing\nevaluations typically focus on overall fuzzer performance across a set of\ntarget programs, yet few benchmarks consider how fine-grained program features\ninfluence fuzzing effectiveness. To bridge this gap, we introduce a novel\nbenchmark designed to generate programs with configurable, fine-grained program\nfeatures to enhance fuzzing evaluations. We reviewed 25 recent grey-box fuzzing\nstudies, extracting 7 program features related to control-flow and data-flow\nthat can impact fuzzer performance. Using these features, we generated a\nbenchmark consisting of 153 programs controlled by 10 fine-grained configurable\nparameters. We evaluated 11 popular fuzzers using this benchmark. The results\nindicate that fuzzer performance varies significantly based on the program\nfeatures and their strengths, highlighting the importance of incorporating\nprogram characteristics into fuzzing evaluations.", "AI": {"tldr": "This paper presents a new benchmark that allows fine-grained analysis of how specific program features affect fuzzing effectiveness, showing that different fuzzers perform variably depending on these features, suggesting the need for more nuanced benchmarks in future evaluations.", "motivation": "Traditional fuzzing benchmarks do not adequately consider how specific, fine-grained program features affect a fuzzer's effectiveness, potentially missing important insights into fuzzer performance.", "method": "The authors reviewed 25 recent grey-box fuzzing studies to identify 7 key program features related to control-flow and data-flow. They used these features to generate a benchmark of 153 programs, each with 10 configurable parameters, and evaluated the performance of 11 popular fuzzers on this benchmark.", "result": "Fuzzer performance differs significantly depending on specific program features and their individual strengths.", "conclusion": "Program characteristics meaningfully impact fuzzing effectiveness. Future fuzzing evaluations should incorporate fine-grained program features for more insightful analysis."}}
{"id": "2506.15098", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.15098", "abs": "https://arxiv.org/abs/2506.15098", "authors": ["Haosheng Zuo", "Feifei Niu", "Chuanyi Li"], "title": "Enhancement Report Approval Prediction: A Comparative Study of Large Language Models", "comment": null, "summary": "Enhancement reports (ERs) serve as a critical communication channel between\nusers and developers, capturing valuable suggestions for software improvement.\nHowever, manually processing these reports is resource-intensive, leading to\ndelays and potential loss of valuable insights. To address this challenge,\nenhancement report approval prediction (ERAP) has emerged as a research focus,\nleveraging machine learning techniques to automate decision-making. While\ntraditional approaches have employed feature-based classifiers and deep\nlearning models, recent advancements in large language models (LLM) present new\nopportunities for enhancing prediction accuracy. This study systematically\nevaluates 18 LLM variants (including BERT, RoBERTa, DeBERTa-v3, ELECTRA, and\nXLNet for encoder models; GPT-3.5-turbo, GPT-4o-mini, Llama 3.1 8B, Llama 3.1\n8B Instruct and DeepSeek-V3 for decoder models) against traditional methods\n(CNN/LSTM-BERT/GloVe). Our experiments reveal two key insights: (1)\nIncorporating creator profiles increases unfine-tuned decoder-only models'\noverall accuracy by 10.8 percent though it may introduce bias; (2) LoRA\nfine-tuned Llama 3.1 8B Instruct further improve performance, reaching 79\npercent accuracy and significantly enhancing recall for approved reports (76.1\npercent vs. LSTM-GLOVE's 64.1 percent), outperforming traditional methods by 5\npercent under strict chronological evaluation and effectively addressing class\nimbalance issues. These findings establish LLM as a superior solution for ERAP,\ndemonstrating their potential to streamline software maintenance workflows and\nimprove decision-making in real-world development environments. We also\ninvestigated and summarized the ER cases where the large models underperformed,\nproviding valuable directions for future research.", "AI": {"tldr": "Large language models (LLMs) significantly outperform older machine learning and deep learning approaches in automated enhancement report approval prediction, especially when creator profiles and fine-tuning are used. LLMs offer a 5% accuracy improvement, better recall, and improved handling of class imbalance, paving the way for more efficient software maintenance. The paper also notes some areas where LLMs need further improvement.", "motivation": "Manual processing of enhancement reports (ERs) is time-consuming and may delay or lose valuable software improvement suggestions, motivating the need for automated methods to improve efficiency and accuracy in ER approval prediction.", "method": "The study systematically evaluates 18 large language model (LLM) variants\u2014including encoder models like BERT, RoBERTa, DeBERTa-v3, ELECTRA, XLNet and decoder models like GPT-3.5-turbo, GPT-4o-mini, Llama 3.1 8B, Llama 3.1 8B Instruct, DeepSeek-V3\u2014against traditional methods such as CNN/LSTM-BERT/GloVe for ER approval prediction. The evaluation also explores the impact of incorporating creator profiles and LoRA fine-tuning.", "result": "Adding creator profiles increases the accuracy of unfine-tuned decoder-only LLMs by 10.8% but may introduce bias. The LoRA fine-tuned Llama 3.1 8B Instruct model achieves 79% accuracy and significantly boosts recall for approved reports (76.1% vs. 64.1% with LSTM-GLOVE), outperforming traditional methods by 5% under strict, chronological evaluation. The approach also better addresses class imbalance issues.", "conclusion": "LLMs, especially those with fine-tuning and profile incorporation, surpass traditional methods in ER approval prediction, streamlining software maintenance and decision-making. The study also points out cases where large models underperform, suggesting directions for future research."}}
{"id": "2506.15174", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2506.15174", "abs": "https://arxiv.org/abs/2506.15174", "authors": ["Hossein Albakri", "Kazem Cheshmi"], "title": "A Novel Compiler Transformation for Fast Sparse Matrix Multiplication in GPUs", "comment": null, "summary": "Sparse data structures are commonly used in neural networks to reduce the\nmemory footprint. These data structures are compact but cause irregularities\nsuch as random memory accesses, which prevent efficient use of the memory\nhierarchy. GPUs are a common platform for machine learning practitioners, but\nrunning compact data structures on these devices often leads to slow-downs due\nto inefficient use of computing and memory resources. This paper proposes a new\ncompiler transformation, enumerate-and-sparse-coarsen, that accelerates sparse\nmatrix-matrix multiplication (SPMM) on GPU devices. The transformation\nincreases data reuse in registers and caches while creating more balanced\nworkloads for GPU computing resources. The transformation is tested on sparse\nneural networks in convolutional and transformer models. On an A100 GPU and\nacross a columns of matrix B (bCols) in $ A \\times B = C$ from range of 32 to\n128, the transformation yields a geometric mean speedup of 1.84$\\times$ to\n2.27$\\times$ compared to cuBLAS and cuSPARSE baselines, respectively.", "AI": {"tldr": "A novel compiler technique accelerates sparse neural network computations on GPUs, yielding up to 2.27x speedup by optimizing memory and compute utilization.", "motivation": "Sparse data structures are widely used in neural networks to save memory, but cause irregular memory accesses, resulting in inefficient use of GPU resources and slowdowns.", "method": "The paper introduces a compiler transformation called enumerate-and-sparse-coarsen, which boosts sparse matrix-matrix multiplication (SPMM) efficiency on GPUs by enhancing data reuse and balancing workloads.", "result": "Their method, when applied to sparse neural networks (including convolutional and transformer models) on an A100 GPU, achieves a geometric mean speedup of 1.84x to 2.27x over standard cuBLAS and cuSPARSE baselines across various configurations.", "conclusion": "The proposed compiler transformation significantly improves the computational and memory efficiency of SPMM on GPUs, facilitating faster execution of sparse neural networks by addressing key performance bottlenecks."}}
{"id": "2506.15135", "categories": ["cs.SE", "cs.LO", "cs.PL", "F.3.1; F.1.2"], "pdf": "https://arxiv.org/pdf/2506.15135", "abs": "https://arxiv.org/abs/2506.15135", "authors": ["Zhengqun Koo"], "title": "Towards Bug-Free Distributed Go Programs", "comment": "Version 1. B.Comp. Dissertation", "summary": "Programmers of distributed systems need to reason about concurrency to avoid\nraces. However, reasoning about concurrency is difficult, and unexpected races\nshow up as bugs. Data race detection in shared memory systems is well-studied\n(dynamic data race detection [13], behavioral types [15], dynamic race\ndetection [31]). Similar to how a data race consists of reads and writes not\nrelated by happens-before at a shared memory location, a communication race\nconsists of receives and sends not related by happens-before on a shared\nchannel. Communication races are problematic: a receiver expects a specific\nmessage from a specific sender, but with a communication race, the receiver can\nreceive a message meant for another receiver, or not receive anything at all.\nIn this work, we describe a verification framework that can prove the absence\nof communication races for distributed programs that use a subset of the Go\nprogramming language, where synchronization is mainly achieved via message\npassing. We statically reason about how a distributed program executes, using a\nhappens-before order, extended to buffered and unbuffered channels.", "AI": {"tldr": "This paper introduces a static verification framework for Go-based distributed systems to prove the absence of communication races, helping developers avoid hard-to-find concurrency bugs in message-passing programs.", "motivation": "Reasoning about concurrency in distributed systems is difficult for programmers, often resulting in unexpected race conditions (bugs), especially in message-passing systems like those using Go channels.", "method": "The paper introduces a static verification framework that analyzes distributed programs written in a subset of Go, using an extended happens-before order to reason about program execution with both buffered and unbuffered channels.", "result": "The proposed framework can statically prove the absence of communication races in distributed programs using message passing, increasing the reliability of such programs.", "conclusion": "The authors present an effective static analysis method to verify communication-race-freedom in distributed Go programs, filling a gap left by prior work mainly focused on data races in shared memory systems."}}
{"id": "2506.15424", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2506.15424", "abs": "https://arxiv.org/abs/2506.15424", "authors": ["Michael Mendler", "Marc Pouzet"], "title": "PSM: Policy Synchronised Deterministic Memory", "comment": "This report summarises work on coding the theory of\n  policy-synchronised memory (see https://rdcu.be/erBwl) in Haskell. This was\n  developed for a graduate level course on Functional Reactive Programming\n  taught at Bamberg University by the first author during 2020-2023. An early\n  version of the PSM library had been presented at the SYNCHRON Workshop\n  (Aussois, France), November 2019", "summary": "Concurrency and determinacy do not go well with each other when resources\nmust be shared. Haskell provides parallel programming abstractions such as IVar\nand LVar in the Par monad and concurrent abstractions such as MVar and TVar in\nthe in IO and STM monads, respectively. The former are determinate but have no\ndestructive updates and the latter have destructive updates but do not\nguarantee determinacy. Programming patterns that are both concurrent and\ndeterminate, such as those provided by Kahn or Berry require memory\nabstractions at a higher level than is currently available. In this paper we\ndescribe a new type context PSM for policy synchronised memory in Haskell. Like\nSTM and IO, the computations in PSM can access persistent state and, as a\nside-effect, update the memory in imperative style. Like the Par and IO monads,\nPSM supports concurrent threads and shared state. However, in contrast to IO,\nour PSM contexts are race-free since concurrent accesses are policy coordinated\nwhich guarantees determinacy.Well-typed transactions in the PSM context can\naccommodate abstract data structures that are imperative, concurrently\nshareable and still behave deterministically, by construction.", "AI": {"tldr": "The paper introduces PSM, a new Haskell context that enables concurrent, deterministic, and race-free programming with shared, imperative memory \u2014 something not previously available with existing abstractions.", "motivation": "Concurrency and determinacy often conflict when shared resources are involved. Existing Haskell abstractions either sacrifice determinacy for destructive updates or vice versa, and higher-level memory abstractions are needed to accommodate concurrent and determinate patterns.", "method": "The authors introduce a new type context called PSM (policy synchronised memory) in Haskell, which combines features of existing monads. PSM enables computations with persistent state, imperative updates, concurrent threads, and shared state. Accesses are coordinated by policies to guarantee determinacy and race-free execution.", "result": "Well-typed transactions in the PSM context allow for abstract data structures that are concurrently shareable, imperative, and behave deterministically. This provides a new way to write concurrent Haskell programs that do not sacrifice determinacy or allow race conditions.", "conclusion": "The PSM context is a significant step towards supporting concurrent and determinate programming patterns in Haskell, offering imperative style, shared memory, and race-free determinacy, which overcomes the limitations of current abstractions."}}
{"id": "2506.15172", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.15172", "abs": "https://arxiv.org/abs/2506.15172", "authors": ["Maria Spichkova", "Kevin Iwan", "Madeleine Zwart", "Hina Lee", "Yuwon Yoon", "Xiaohan Qin"], "title": "Advanced approach for Agile/Scrum Process: RetroAI++", "comment": "Preprint. Accepted to the 29th International Conference on\n  Knowledge-Based and Intelligent Information & Engineering Systems (KES 2025).\n  Final version to be published by Elsevier (In Press)", "summary": "In Agile/Scrum software development, sprint planning and retrospective\nanalysis are the key elements of project management. The aim of our work is to\nsupport software developers in these activities. In this paper, we present our\nprototype tool RetroAI++, based on emerging intelligent technologies. In our\nRetroAI++ prototype, we aim to automate and refine the practical application of\nAgile/Scrum processes within Sprint Planning and Retrospectives. Leveraging AI\ninsights, our prototype aims to automate and refine the many processes involved\nin the Sprint Planning, Development and Retrospective stages of Agile/Scrum\ndevelopment projects, offering intelligent suggestions for sprint organisation\nas well as meaningful insights for retrospective reflection.", "AI": {"tldr": "The paper introduces RetroAI++, an AI-powered tool that automates and enhances Agile/Scrum sprint planning and retrospectives by providing smart suggestions and insights, aiming to streamline project management for software developers.", "motivation": "Sprint planning and retrospective analysis are essential but challenging aspects of Agile/Scrum project management. There is a need to better support developers in these activities and make the process more efficient, insightful, and automated.", "method": "The authors developed a prototype tool, RetroAI++, which leverages AI technologies to automate and improve Agile/Scrum processes, particularly focusing on Sprint Planning and Retrospective stages.", "result": "The resulting tool, RetroAI++, provides intelligent suggestions for sprint organization and offers actionable insights during retrospectives, aiming to enhance the efficiency and effectiveness of Agile/Scrum project management.", "conclusion": "RetroAI++ demonstrates the potential of AI-based tools to support automation, offer intelligent recommendations, and provide reflective insights in Agile/Scrum processes, improving both sprint planning and retrospective analysis."}}
