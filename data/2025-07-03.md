<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 6]
- [cs.PL](#cs.PL) [Total: 2]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Is It Safe To Learn And Share? On Psychological Safety and Social Learning in (Agile) Communities of Practice](https://arxiv.org/abs/2507.01065)
*Christiaan Verwijs,Evelien Acun-Roos,Daniel Russo*

Main category: cs.SE

TL;DR: Online Agile Communities of Practice have lower psychological safety than face-to-face ones, which negatively impacts participation. Exclusionary and hostile behaviors are major threats. Differences arise by role and age, but not gender or seniority. Explicit norms and active moderation are needed for safer, more inclusive environments.


<details>
  <summary>Details</summary>
Motivation: As remote, distributed, and hybrid work environments become increasingly common in Agile Software Development (ASD), continuous and effective learning through Communities of Practice (CoPs) is more important than ever. However, psychological safety—a key enabler for effective learning—remains poorly understood in these virtual or hybrid CoP settings.

Method: The study uses a mixed-methods approach, employing surveys with 143 participants engaged in Agile CoPs. Quantitative results are complemented by a thematic analysis of participant experiences. The findings were validated through member checking with 30 participants.

Result: Psychological safety is found to be significantly lower in online interactions than in face-to-face settings. Lower psychological safety diminishes the willingness to continue contributing and increases risk-aversion. No significant effect is found for gender, seniority, or content activity, but role and age group differences are observed. Key threats to psychological safety include exclusionary behavior, negative interactions, and hostility, often amplified by tribalism and specific community dynamics.

Conclusion: Interaction modality (online versus face-to-face) has a strong impact on psychological safety in Agile CoPs—lower in online settings. Mitigation strategies include explicit norms, structured facilitation, and active moderation. The study offers actionable guidance for fostering psychological safety and inclusivity in virtual and hybrid CoPs.

Abstract: As hybrid, distributed, and asynchronous work models become more prevalent,
continuous learning in Agile Software Development (ASD) gains renewed
importance. Communities of Practice (CoPs) are increasingly adopted to support
social learning beyond formal education, often relying on virtual
communication. Psychological safety, a prerequisite for effective learning,
remains insufficiently understood in these settings. This mixed-methods study
investigates psychological safety within Agile CoPs through survey data from
143 participants. Results indicate that psychological safety is significantly
lower in online interactions compared to face-to-face settings. Moreover, low
psychological safety reduces participants' intent to continue contributing and
avoidance of interpersonal risk. No significant differences emerged based on
gender, community seniority, or content creation activity. However, differences
by role and age group suggest potential generational or role-related effects.
Thematic analysis revealed exclusionary behavior, negative interaction
patterns, and hostility as primary threats to psychological safety, often
reinforced by tribalism and specific community dynamics. Suggested
interventions include establishing explicit norms, structured facilitation, and
active moderation. The findings were validated through member checking with 30
participants. This study provides a comparative perspective on interaction
modalities and offers practical guidance for organizers seeking to cultivate
inclusive, high-impact CoPs and similarly structured virtual or hybrid work
environments.

</details>


### [2] [Bugs in the Shadows: Static Detection of Faulty Python Refactorings](https://arxiv.org/abs/2507.01103)
*Jonhnanthan Oliveira,Rohit Gheyi,Márcio Ribeiro,Alessandro Garcia*

Main category: cs.SE

TL;DR: A new static analysis detects type errors from automated Python refactoring. In evaluating refactoring tools, the method found 29 bugs, some present in major IDEs. This highlights the need to strengthen Python refactoring tools for safer automated code changes.


<details>
  <summary>Details</summary>
Motivation: Python's dynamic type system makes it difficult to perform automated refactoring safely, as it can easily introduce type errors. Since reliable and efficient refactoring is important for software evolution and developer productivity, understanding and mitigating type errors introduced during refactoring is essential.

Method: The authors propose a static analysis technique specifically designed to detect type errors that are introduced by refactoring implementations in Python. They evaluate this technique by applying Rope's refactoring tools to a set of open-source Python projects and analyze the results.

Result: The analysis discovered 29 bugs arising from four different types of refactorings out of 1,152 attempts. Some of these bugs were also found in popular IDEs like PyCharm and PyDev. Reported bugs were submitted to the respective tool developers, and several were acknowledged and accepted.

Conclusion: Current Python refactoring tools are not robust enough and can introduce type errors that compromise software reliability. There is a clear need to enhance these tools to ensure correct automated code transformations for reliable software maintenance.

Abstract: Python is a widely adopted programming language, valued for its simplicity
and flexibility. However, its dynamic type system poses significant challenges
for automated refactoring - an essential practice in software evolution aimed
at improving internal code structure without changing external behavior.
Understanding how type errors are introduced during refactoring is crucial, as
such errors can compromise software reliability and reduce developer
productivity. In this work, we propose a static analysis technique to detect
type errors introduced by refactoring implementations for Python. We evaluated
our technique on Rope refactoring implementations, applying them to open-source
Python projects. Our analysis uncovered 29 bugs across four refactoring types
from a total of 1,152 refactoring attempts. Several of these issues were also
found in widely used IDEs such as PyCharm and PyDev. All reported bugs were
submitted to the respective developers, and some of them were acknowledged and
accepted. These results highlight the need to improve the robustness of current
Python refactoring tools to ensure the correctness of automated code
transformations and support reliable software maintenance.

</details>


### [3] [Context-Aware Code Wiring Recommendation with LLM-based Agent](https://arxiv.org/abs/2507.01315)
*Taiming Wang,Yanjie Jiang,Chunhao Dong,Yuxia Zhang,Hui Liu*

Main category: cs.SE

TL;DR: WIRL is an LLM-based tool that automates context-aware variable mapping when developers copy-paste code. It outperforms existing LLMs and IDEs like IntelliJ in accuracy and recall, showing promise for smarter, more helpful code adaptation features in developer tools.


<details>
  <summary>Details</summary>
Motivation: Copy-paste-modify is a common practice among developers for incorporating external code snippets. However, a key challenge in this adaptation is 'code wiring,' which involves resolving and mapping variables from the pasted snippet to the developer's code context. Existing methods often do not leverage sufficient contextual information, leading to inaccurate or inefficient code adaptation. The motivation is to address this underexplored yet critical aspect efficiently.

Method: The authors propose WIRL, an agent based on large language models (LLMs), which frames code wiring as a Retrieval-Augmented Generation (RAG) infilling task. WIRL uses a combination of LLMs, a custom toolkit, and an orchestration module to automatically identify unresolved variables, retrieve relevant code context, and perform precise substitutions. The system mixes deterministic rule-based actions with a state-machine-guided, LLM-driven decision process to balance speed and adaptability.

Result: WIRL was evaluated on a curated dataset of real-world code adaptation cases. It achieved an exact match precision of 91.7% and recall of 90.0%. Compared to advanced LLMs, WIRL showed improvements of 22.6 and 13.7 percentage points in precision and recall, respectively. Against IntelliJ IDEA, it outperformed by 54.3 and 49.9 percentage points.

Conclusion: WIRL significantly enhances the context-awareness and accuracy of code adaptation during copy-paste-modify workflows. Its hybrid approach makes it more effective than existing LLMs and IDE solutions, particularly when dealing with complex coding contexts and unresolved variables. WIRL sets a new direction for automated, intelligent developer assistance in modern IDEs.

Abstract: Copy-paste-modify is a widespread and pragmatic practice in software
development, where developers adapt reused code snippets, sourced from
platforms such as Stack Overflow, GitHub, or LLM outputs, into their local
codebase. A critical yet underexplored aspect of this adaptation is code
wiring, which involves substituting unresolved variables in the pasted code
with suitable ones from the surrounding context. Existing solutions either rely
on heuristic rules or historical templates, often failing to effectively
utilize contextual information, despite studies showing that over half of
adaptation cases are context-dependent. In this paper, we introduce WIRL, an
LLM-based agent for code wiring framed as a Retrieval-Augmented Generation
(RAG) infilling task. WIRL combines an LLM, a customized toolkit, and an
orchestration module to identify unresolved variables, retrieve context, and
perform context-aware substitutions. To balance efficiency and autonomy, the
agent adopts a mixed strategy: deterministic rule-based steps for common
patterns, and a state-machine-guided decision process for intelligent
exploration. We evaluate WIRL on a carefully curated, high-quality dataset
consisting of real-world code adaptation scenarios. Our approach achieves an
exact match precision of 91.7% and a recall of 90.0%, outperforming advanced
LLMs by 22.6 and 13.7 percentage points in precision and recall, respectively,
and surpassing IntelliJ IDEA by 54.3 and 49.9 percentage points. These results
underscore its practical utility, particularly in contexts with complex
variable dependencies or multiple unresolved variables. We believe WIRL paves
the way for more intelligent and context-aware developer assistance in modern
IDEs.

</details>


### [4] [Combining Type Inference and Automated Unit Test Generation for Python](https://arxiv.org/abs/2507.01477)
*Lukas Krodinger,Stephan Lukasczyk,Gordon Fraser*

Main category: cs.SE

TL;DR: This paper proposes type tracing for Python unit test generation, dynamically inferring types during test execution, resulting in greatly improved code coverage and test effectiveness.


<details>
  <summary>Details</summary>
Motivation: Automated test generation for dynamically-typed languages like Python is challenging due to missing type information, hindering effective test input selection.

Method: Introduce 'type tracing,' which gathers and refines type information during repeated test executions within the Pynguin framework. Type tracing infers parameter types, records return types, and leverages this knowledge to guide test generation.

Result: The proposed method achieves up to 90.0% more branch coverage and better mutation scores. It also infers types with quality similar to state-of-the-art type-inference tools.

Conclusion: Type tracing significantly enhances automated unit test generation for Python by inferring and refining type information at runtime, leading to substantial coverage and quality improvements.

Abstract: Automated unit test generation is an established research field that has so
far focused on statically-typed programming languages. The lack of type
information in dynamically-typed programming languages, such as Python,
inhibits test generators, which heavily rely on information about parameter and
return types of functions to select suitable arguments when constructing test
cases. Since automated test generators inherently rely on frequent execution of
candidate tests, we make use of these frequent executions to address this
problem by introducing type tracing, which extracts type-related information
during execution and gradually refines the available type information. We
implement type tracing as an extension of the Pynguin test-generation framework
for Python, allowing it (i) to infer parameter types by observing how
parameters are used during runtime, (ii) to record the types of values that
function calls return, and (iii) to use this type information to increase code
coverage. The approach leads to up to 90.0% more branch coverage, improved
mutation scores, and to type information of similar quality to that produced by
other state-of-the-art type-inference tools.

</details>


### [5] [DaiFu: In-Situ Crash Recovery for Deep Learning Systems](https://arxiv.org/abs/2507.01628)
*Zilong He,Pengfei Chen,Hongyu Zhang,Xiaoyun Li,Guangba Yu,Hongyang Chen,Zibin Zheng*

Main category: cs.SE

TL;DR: DaiFu is a new, lightweight recovery framework for deep learning systems, enabling fast in-situ crash recovery with minimal overhead. It is up to 1372x faster than existing methods and works well across various crash types.


<details>
  <summary>Details</summary>
Motivation: Deep learning systems are widely used but frequently suffer from crashes due to complex software stacks, leading to significant resource waste and decreased developer productivity. Existing crash recovery solutions like checkpoint-retry are too slow and heavyweight for common programming or runtime errors, highlighting the need for faster, more efficient recovery methods.

Method: The authors introduce DaiFu, an in-situ recovery framework for DL systems. DaiFu uses lightweight code transformation to enable the DL system to catch crashes on the spot and supports dynamic, immediate updates to the running context (such as code, configurations, and data) to facilitate agile crash recovery.

Result: DaiFu significantly speeds up the recovery process after a crash: evaluation shows a 1372x improvement in restore time versus state-of-the-art solutions, while adding negligible performance overhead (less than 0.40%). Its effectiveness is demonstrated through a benchmark covering 7 different crash scenarios.

Conclusion: DaiFu offers a practical, lightweight, and highly effective solution for crash recovery in deep learning systems, greatly reducing downtime and minimizing performance impact. Its framework is proven effective across diverse crash cases.

Abstract: Deep learning (DL) systems have been widely adopted in many areas, and are
becoming even more popular with the emergence of large language models.
However, due to the complex software stacks involved in their development and
execution, crashes are unavoidable and common. Crashes severely waste computing
resources and hinder development productivity, so efficient crash recovery is
crucial. Existing solutions, such as checkpoint-retry, are too heavyweight for
fast recovery from crashes caused by minor programming errors or transient
runtime errors. Therefore, we present DaiFu, an in-situ recovery framework for
DL systems. Through a lightweight code transformation to a given DL system,
DaiFu augments it to intercept crashes in situ and enables dynamic and instant
updates to its program running context (e.g., code, configurations, and other
data) for agile crash recovery. Our evaluation shows that DaiFu helps reduce
the restore time for crash recovery, achieving a 1372x speedup compared with
state-of-the-art solutions. Meanwhile, the overhead of DaiFu is negligible
(under 0.40%). We also construct a benchmark spanning 7 distinct crash
scenarios in DL systems, and show the effectiveness of DaiFu in diverse
situations.

</details>


### [6] [APRMCTS: Improving LLM-based Automated Program Repair with Iterative Tree Search](https://arxiv.org/abs/2507.01827)
*Haichuan Hu,Congqing He,Hao Zhang,Xiaochen Xie,Quanjun Zhang*

Main category: cs.SE

TL;DR: This paper presents APRMCTS, which combines LLMs and Monte Carlo Tree Search to significantly improve automated program repair. It outperforms state-of-the-art methods on standard benchmarks, fixes more bugs with less computation and cost, and particularly shines on complex bug fixes.


<details>
  <summary>Details</summary>
Motivation: Automated Program Repair (APR) is essential for software maintenance, but recent LLM-based APR techniques face issues like local optima (limited patch effectiveness) and inefficiency (redundant exploration). There is a need for a more effective and efficient patch search approach.

Method: This paper introduces APRMCTS, a novel APR method that combines Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS). APRMCTS performs an iterative global evaluation of candidate patches and refines the most promising ones using MCTS, rather than relying on trial-and-error.

Result: Experiments on 835 bugs from the Defects4J benchmark show that APRMCTS, when used with GPT-3.5, fixes 201 bugs, beating all existing baselines. It also improves bug-fixing numbers for several prominent LLMs by 27-37 bugs each and is effective even with much smaller patch sizes (16 and 32 versus 500-10,000 in prior work) while cutting time and cost significantly (to less than 20% and 50% of previous methods, respectively).

Conclusion: APRMCCTS achieves state-of-the-art APR performance with increased effectiveness and efficiency. Its global-search approach overcomes local optima and redundant searches, making it especially strong for fixing complex bugs, with substantially lower computational and monetary costs than previous LLM-based APR techniques.

Abstract: Automated Program Repair (APR) attempts to fix software bugs without human
intervention, which plays a crucial role in software development and
maintenance. Recently, with the advances in Large Language Models (LLMs), a
rapidly increasing number of APR techniques have been proposed with remarkable
performance. However, existing LLM-based APR techniques typically adopt
trial-and-error strategies, which suffer from two major drawbacks: (1)
inherently limited patch effectiveness due to local exploration, and (2) low
search efficiency due to redundant exploration. In this paper, we propose
APRMCTS, which uses iterative tree search to improve LLM-based APR. APRMCTS
incorporates Monte Carlo Tree Search (MCTS) into patch searching by performing
a global evaluation of the explored patches and selecting the most promising
one for subsequent refinement and generation. APRMCTS effectively resolves the
problems of falling into local optima and thus helps improve the efficiency of
patch searching. Our experiments on 835 bugs from Defects4J demonstrate that,
when integrated with GPT-3.5, APRMCTS can fix a total of 201 bugs, which
outperforms all state-of-the-art baselines. Besides, APRMCTS helps GPT-4o-mini,
GPT-3.5, Yi-Coder-9B, and Qwen2.5-Coder-7B to fix 30, 27, 37, and 28 more bugs,
respectively. More importantly, APRMCTS boasts a significant performance
advantage while employing small patch size (16 and 32), notably fewer than the
500 and 10,000 patches adopted in previous studies. In terms of cost, compared
to existing state-of-the-art LLM-based APR methods, APRMCTS has time and
monetary costs of less than 20% and 50%, respectively. Our extensive study
demonstrates that APRMCTS exhibits good effectiveness and efficiency, with
particular advantages in addressing complex bugs.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [7] [Advanced LPeg techniques: A dual case study approach](https://arxiv.org/abs/2507.01272)
*Zixuan Zhu*

Main category: cs.PL

TL;DR: Through careful grammar design and innovative optimization strategies, this paper demonstrates major performance improvements for LPeg-based parsers in Lua, achieving state-of-the-art results for both JSON parsing and glob pattern conversion, all without requiring any changes to the LPeg library.


<details>
  <summary>Details</summary>
Motivation: LPeg (Lua Parsing Expression Grammars) is a widely used pattern-matching and parsing library, but its performance can be limited by the way grammars are constructed. There is a need for practical, effective optimization techniques to boost the speed and efficiency of LPeg-based parsers without altering the library itself.

Method: The authors present two complementary case studies to develop and evaluate their optimization strategies. They design and optimize a high-performance JSON parser and a Glob-to-LPeg pattern converter. Optimization involves techniques like substitution capture, table construction optimization, segment-boundary separation, Cox's flattened search strategy, and optimized braced condition handling. They then comprehensively benchmark these tools against existing solutions.

Result: The optimized JSON parser achieves speeds up to 125 MB/s, outperforming dkjson and showing competitive performance against rxi_json in most cases. The Glob-to-LPeg converter delivers 14–92% better performance than Bun.Glob and is 3–14 times faster than Minimatch across a variety of scenarios.

Conclusion: Strategic grammar construction and optimization techniques can significantly improve the performance of LPeg-based parsers. The paper's proposed methods enable remarkable speed and efficiency gains without any need to change the LPeg library itself, offering substantial practical value to the text processing and Lua programming communities.

Abstract: This paper presents advanced optimization techniques for Lua Parsing
Expression Grammars (LPeg) through two complementary case studies: a
high-performance JSON parser and a sophisticated Glob-to-LPeg pattern
converter. We demonstrate how strategic grammar construction can dramatically
improve parsing performance without modifying the underlying LPeg library. For
the JSON parser, we implement substitution capture and table construction
optimization to reduce memory allocation overhead and improve object
processing. For the Glob converter, we introduce segment-boundary separation,
implement Cox's flattened search strategy, and develop optimized braced
condition handling to prevent exponential backtracking. Comprehensive
benchmarks demonstrate that our JSON parser achieves processing speeds up to
125 MB/s on complex documents, consistently outperforming dkjson and showing
competitive results against rxi_json across most test cases. Our Glob-to-LPeg
converter exhibits 14-92% better performance than Bun.Glob and runs 3-14 times
faster than Minimatch across diverse pattern matching scenarios. This research
provides practical optimization techniques for LPeg-based parsers, contributing
valuable strategies to the text processing ecosystem.

</details>


### [8] [Globality and Regions](https://arxiv.org/abs/2507.01664)
*Hector Gramaglia*

Main category: cs.PL

TL;DR: This paper shows that global variables in a region-based language can be understood as arising from the unification of abstraction and region abstraction, offering a clear theoretical basis for integrating imperative features into functional languages with strong memory safety.


<details>
  <summary>Details</summary>
Motivation: The motivation is to precisely characterize global variables in a region-based language, and to clarify how imperative operations can be conceptually integrated into a functional language while ensuring memory safety.

Method: The paper builds on prior work introducing a 'global' language and demonstrates, via theoretical analysis, that global variables as defined in the global language originate from the unification of abstraction and region abstraction in the Tofte and Talping's region language.

Result: The main result is a demonstrated linkage: global variables in the global language stem from the merging of abstraction and region abstraction in the region-based language framework.

Conclusion: The paper concludes that the unification of abstraction and region abstraction in a region-based language provides a clear and theoretically sound foundation for global variables and their memory safety guarantees, connecting imperative and functional paradigms.

Abstract: We obtain a characterization of global variables by unifying abstraction with
region abstraction in a region-based language. More precisely, in a previous
work a language called global was presented, whose virtue is to provide a
conceptually clear way of introducing imperative operations in a functional
language. Memory safety is provided by the concept of linear protection, which
connects the global system to a linear one. In this paper we show that the
concept of global variable provided by the global language arises from the
Tofte and Talping's region language through the unification of abstraction and
region abstraction.

</details>
