{"id": "2506.20754", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.20754", "abs": "https://arxiv.org/abs/2506.20754", "authors": ["Marina Ara\u00fajo", "J\u00falia Ara\u00fajo", "Romeu Oliveira", "Lucas Romao", "Marcos Kalinowski"], "title": "Domain Knowledge in Requirements Engineering: A Systematic Mapping Study", "comment": "Accepted for publication at the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA) 2025", "summary": "[Context] Domain knowledge is recognized as a key component for the success\nof Requirements Engineering (RE), as it provides the conceptual support needed\nto understand the system context, ensure alignment with stakeholder needs, and\nreduce ambiguity in requirements specification. Despite its relevance, the\nscientific literature still lacks a systematic consolidation of how domain\nknowledge can be effectively used and operationalized in RE. [Goal] This paper\naddresses this gap by offering a comprehensive overview of existing\ncontributions, including methods, techniques, and tools to incorporate domain\nknowledge into RE practices. [Method] We conducted a systematic mapping study\nusing a hybrid search strategy that combines database searches with iterative\nbackward and forward snowballing. [Results] In total, we found 75 papers that\nmet our inclusion criteria. The analysis highlights the main types of\nrequirements addressed, the most frequently considered quality attributes, and\nrecurring challenges in the formalization, acquisition, and long-term\nmaintenance of domain knowledge. The results provide support for researchers\nand practitioners in identifying established approaches and unresolved issues.\nThe study also outlines promising directions for future research, emphasizing\nthe development of scalable, automated, and sustainable solutions to integrate\ndomain knowledge into RE processes. [Conclusion] The study contributes by\nproviding a comprehensive overview that helps to build a conceptual and\nmethodological foundation for knowledge-driven requirements engineering.", "AI": {"tldr": "This paper systematically reviews how domain knowledge is incorporated into Requirements Engineering, mapping existing methods, challenges, and future needs, thus providing a conceptual and methodological foundation for the field.", "motivation": "Domain knowledge is essential for successful Requirements Engineering (RE), offering support for understanding system context and aligning with stakeholder needs. However, literature lacks a systematic overview of how domain knowledge is used and operationalized in RE.", "method": "A systematic mapping study was performed using a hybrid search strategy that combined database searches and iterative backward and forward snowballing.", "result": "The study identified 75 relevant papers. The analysis categorizes types of requirements, key quality attributes, and recurring challenges in acquiring, formalizing, and maintaining domain knowledge. It supports identifying established methods and highlights unresolved issues and future research directions, such as scalable and automated integration of domain knowledge in RE.", "conclusion": "The study offers a comprehensive overview of domain knowledge usage in RE, helping to establish a solid foundation for knowledge-driven approaches to requirements engineering."}}
{"id": "2506.20759", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20759", "abs": "https://arxiv.org/abs/2506.20759", "authors": ["Lucas Romao", "Hugo Villamizar", "Romeu Oliveira", "Silvio Alonso", "Marcos Kalinowski"], "title": "Agile Management for Machine Learning: A Systematic Mapping Study", "comment": "Accepted for publication at the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA) 2025", "summary": "[Context] Machine learning (ML)-enabled systems are present in our society,\ndriving significant digital transformations. The dynamic nature of ML\ndevelopment, characterized by experimental cycles and rapid changes in data,\nposes challenges to traditional project management. Agile methods, with their\nflexibility and incremental delivery, seem well-suited to address this\ndynamism. However, it is unclear how to effectively apply these methods in the\ncontext of ML-enabled systems, where challenges require tailored approaches.\n[Goal] Our goal is to outline the state of the art in agile management for\nML-enabled systems. [Method] We conducted a systematic mapping study using a\nhybrid search strategy that combines database searches with backward and\nforward snowballing iterations. [Results] Our study identified 27 papers\npublished between 2008 and 2024. From these, we identified eight frameworks and\ncategorized recommendations and practices into eight key themes, such as\nIteration Flexibility, Innovative ML-specific Artifacts, and the Minimal Viable\nModel. The main challenge identified across studies was accurate effort\nestimation for ML-related tasks. [Conclusion] This study contributes by mapping\nthe state of the art and identifying open gaps in the field. While relevant\nwork exists, more robust empirical evaluation is still needed to validate these\ncontributions.", "AI": {"tldr": "A systematic review found that while agile methods show promise for managing ML-enabled systems, current approaches face challenges like effort estimation. Existing frameworks and practices are mapped, but more empirical validation is necessary.", "motivation": "The dynamic and experimental nature of machine learning (ML) development challenges traditional project management approaches. With ML's rapid changes in data and iterative cycles, there is a need to evaluate whether agile methods can be effectively tailored for managing ML-enabled systems.", "method": "A systematic mapping study was conducted, using a hybrid search strategy that included database searches and backward and forward snowballing. This resulted in the identification and analysis of 27 relevant papers published between 2008 and 2024.", "result": "The study identified eight frameworks for agile management of ML-enabled systems and grouped recommendations into eight themes, including Iteration Flexibility and Minimal Viable Model. Accurate effort estimation for ML tasks emerged as a major challenge across the literature.", "conclusion": "The paper maps the current state of research in agile management for ML-enabled systems and highlights existing accomplishments along with research gaps. There is a need for more empirical evaluation of agile approaches tailored to ML development."}}
{"id": "2506.20851", "categories": ["cs.SE", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2506.20851", "abs": "https://arxiv.org/abs/2506.20851", "authors": ["Srikar Reddy Gadusu", "Larry Callahan", "Samir Lababidi", "Arunasri Nishtala", "Sophia Healey", "Hande McGinty"], "title": "Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach", "comment": null, "summary": "As data and knowledge expand rapidly, adopting systematic methodologies for\nontology generation has become crucial. With the daily increases in data\nvolumes and frequent content changes, the demand for databases to store and\nretrieve information for the creation of knowledge graphs has become\nincreasingly urgent. The previously established Knowledge Acquisition and\nRepresentation Methodology (KNARM) outlines a systematic approach to address\nthese challenges and create knowledge graphs. However, following this\nmethodology highlights the existing challenge of seamlessly integrating Neo4j\ndatabases with the Web Ontology Language (OWL). Previous attempts to integrate\ndata from Neo4j into an ontology have been discussed, but these approaches\noften require an understanding of description logics (DL) syntax, which may not\nbe familiar to many users. Thus, a more accessible method is necessary to\nbridge this gap. This paper presents a user-friendly approach that utilizes\nPython and its rdflib library to support ontology development. We showcase our\nnovel approach through a Neo4j database we created by integrating data from the\nFood and Drug Administration (FDA) Adverse Event Reporting System (FAERS)\ndatabase. Using this dataset, we developed a Python script that automatically\ngenerates the required classes and their axioms, facilitating a smoother\nintegration process. This approach offers a practical solution to the\nchallenges of ontology generation in the context of rapidly growing adverse\ndrug event datasets, supporting improved drug safety monitoring and public\nhealth decision-making.", "AI": {"tldr": "The paper proposes an easy-to-use Python-based solution for automatic ontology generation from Neo4j databases, demonstrated with a drug safety dataset, bridging technical gaps and enabling better data-driven public health outcomes.", "motivation": "The motivation of the paper is to address the growing challenges of ontology generation as data volumes increase and content changes frequently. There is a specific need for practical tools to facilitate knowledge graph creation and integration of databases such as Neo4j with ontologies, especially for users unfamiliar with complex description logics syntax.", "method": "The paper introduces a user-friendly approach utilizing Python and the rdflib library. The method automates the generation of ontology classes and their axioms from a Neo4j database, demonstrated using FDA Adverse Event Reporting System (FAERS) data to create a knowledge graph.", "result": "The result is a practical, automated solution that simplifies ontology generation from Neo4j databases, reducing the technical barrier and facilitating smoother data integration. The system effectively generates ontological constructs needed for knowledge graphs, as shown via the FAERS dataset example.", "conclusion": "The presented approach offers a practical and accessible means to automate ontology generation and knowledge graph integration from Neo4j databases. This supports more efficient drug safety monitoring and enhances public health decision-making."}}
{"id": "2506.20869", "categories": ["cs.SE", "cs.AI", "cs.IR", "D.2.11; I.2.6; H.3.3"], "pdf": "https://arxiv.org/pdf/2506.20869", "abs": "https://arxiv.org/abs/2506.20869", "authors": ["Md Toufique Hasan", "Muhammad Waseem", "Kai-Kristian Kemell", "Ayman Asad Khan", "Mika Saari", "Pekka Abrahamsson"], "title": "Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation", "comment": "Accepted as a full paper to the 51st Euromicro Conference on Software\n  Engineering and Advanced Applications (SEAA 2025). 9 pages, 4 figures. This\n  is the preprint version and not the final camera ready version", "summary": "Retrieval-Augmented Generation (RAG) systems are emerging as a key approach\nfor grounding Large Language Models (LLMs) in external knowledge, addressing\nlimitations in factual accuracy and contextual relevance. However, there is a\nlack of empirical studies that report on the development of RAG-based\nimplementations grounded in real-world use cases, evaluated through general\nuser involvement, and accompanied by systematic documentation of lessons\nlearned. This paper presents five domain-specific RAG applications developed\nfor real-world scenarios across governance, cybersecurity, agriculture,\nindustrial research, and medical diagnostics. Each system incorporates\nmultilingual OCR, semantic retrieval via vector embeddings, and domain-adapted\nLLMs, deployed through local servers or cloud APIs to meet distinct user needs.\nA web-based evaluation involving a total of 100 participants assessed the\nsystems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii)\nTransparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of\nRecommendation. Based on user feedback and our development experience, we\ndocumented twelve key lessons learned, highlighting technical, operational, and\nethical challenges affecting the reliability and usability of RAG systems in\npractice.", "AI": {"tldr": "This paper empirically evaluates five real-world RAG systems in diverse domains, using participant feedback to document practical lessons and challenges, providing actionable insights for future RAG deployment and research.", "motivation": "The motivation behind this paper is to address the limited empirical evidence and practical guidance available on developing and deploying Retrieval-Augmented Generation (RAG) systems in real-world scenarios, specifically focusing on factual accuracy, contextual relevance, and user experience.", "method": "The authors developed five domain-specific RAG applications spanning governance, cybersecurity, agriculture, industrial research, and medical diagnostics. These systems utilized multilingual OCR, vector-based semantic retrieval, and domain-adapted LLMs. Systems were deployed through local servers or cloud APIs, evaluated via a web-based study with 100 participants assessing six key user experience dimensions.", "result": "The evaluation provided user-driven insights, identifying strengths and limitations of RAG deployments in practical contexts. User feedback and development experiences culminated in the documentation of twelve key lessons addressing technical, operational, and ethical challenges to reliability and usability.", "conclusion": "The study demonstrates the benefits and challenges of real-world RAG deployment, offering empirically-grounded lessons crucial for practitioners and researchers aiming to implement RAG systems across various domains."}}
{"id": "2506.20883", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20883", "abs": "https://arxiv.org/abs/2506.20883", "authors": ["Kyanna Dagenais", "Istvan David"], "title": "Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance", "comment": "Accepted for ACM/IEEE MODELS'25", "summary": "Model-driven engineering problems often require complex model transformations\n(MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of\nsuch problems include model synchronization, automated model repair, and design\nspace exploration. Manually developing complex MTs is an error-prone and often\ninfeasible process. Reinforcement learning (RL) is an apt way to alleviate\nthese issues. In RL, an autonomous agent explores the state space through trial\nand error to identify beneficial sequences of actions, such as MTs. However, RL\nmethods exhibit performance issues in complex problems. In these situations,\nhuman guidance can be of high utility. In this paper, we present an approach\nand technical framework for developing complex MT sequences through RL, guided\nby potentially uncertain human advice. Our framework allows user-defined MTs to\nbe mapped onto RL primitives, and executes them as RL programs to find optimal\nMT sequences. Our evaluation shows that human guidance, even if uncertain,\nsubstantially improves RL performance, and results in more efficient\ndevelopment of complex MTs. Through a trade-off between the certainty and\ntimeliness of human advice, our method takes a step towards RL-driven\nhuman-in-the-loop engineering methods.", "AI": {"tldr": "Combining reinforcement learning and human guidance helps automate and improve the efficiency of creating complex sequences of model transformations, with human input (even if uncertain) making RL tools more effective and practical in engineering tasks.", "motivation": "Developing complex model transformations (MTs) in model-driven engineering is often manual, error-prone, and sometimes infeasible. Reinforcement learning (RL) can automate this process but struggles with performance on complex problems, highlighting the need for improved methods.", "method": "The paper introduces a framework that maps user-defined model transformations to RL primitives and executes them as RL programs. It incorporates potentially uncertain human advice to guide the RL agent, improving its efficiency in finding optimal MT sequences.", "result": "The evaluation demonstrates that integrating human guidance\u2014even if it's uncertain\u2014significantly boosts RL performance, enabling more efficient and effective development of complex MTs.", "conclusion": "The proposed human-in-the-loop RL framework effectively enhances the development process of complex model transformations by leveraging both RL capabilities and human input, balancing the reliability and promptness of human advice for optimal outcomes."}}
{"id": "2506.21014", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.21014", "abs": "https://arxiv.org/abs/2506.21014", "authors": ["Shaojian Qiu", "Mengyang Huang", "Jiahao Cheng"], "title": "Boosting Vulnerability Detection with Inter-function Multilateral Association Insights", "comment": null, "summary": "Vulnerability detection is a crucial yet challenging technique for ensuring\nthe security of software systems. Currently, most deep learning-based\nvulnerability detection methods focus on stand-alone functions, neglecting the\ncomplex inter-function interrelations, particularly the multilateral\nassociations. This oversight can fail to detect vulnerabilities in these\ninterrelations. To address this gap, we present an Inter-Function Multilateral\nAssociation analysis framework for Vulnerability Detection (IFMA-VD). The\ncornerstone of the IFMA-VD lies in constructing a code behavior hypergraph and\nutilizing hyperedge convolution to extract multilateral association features.\nSpecifically, we first parse functions into a code property graph to generate\nintra-function features. Following this, we construct a code behavior\nhypergraph by segmenting the program dependency graph to isolate and encode\nbehavioral features into hyperedges. Finally, we utilize a hypergraph network\nto capture the multilateral association knowledge for augmenting vulnerability\ndetection. We evaluate IFMA-VD on three widely used vulnerability datasets and\ndemonstrate improvements in F-measure and Recall compared to baseline methods.\nAdditionally, we illustrate that multilateral association features can boost\ncode feature representation and validate the effectiveness of IFMA-VD on\nreal-world datasets.", "AI": {"tldr": "This paper introduces IFMA-VD, a new framework that models complex relationships between software functions using hypergraphs to improve vulnerability detection, achieving better performance than previous methods on multiple datasets.", "motivation": "Most existing deep learning-based vulnerability detection methods focus only on individual functions and ignore complex relationships between functions, especially multilateral associations. This limited perspective can cause such methods to miss vulnerabilities that arise from these interactions.", "method": "The authors propose IFMA-VD, a framework that constructs a code behavior hypergraph and applies hyperedge convolution to extract features representing multilateral associations among functions. The process includes parsing functions into code property graphs to create intra-function features, building a code behavior hypergraph from segmented program dependency graphs, and then capturing the association knowledge using a hypergraph network.", "result": "Experimental evaluation on three popular vulnerability datasets shows that IFMA-VD outperforms baseline methods in F-measure and Recall. The addition of multilateral association features improves code feature representation, and the framework is validated to be effective on real-world datasets.", "conclusion": "IFMA-VD addresses the limitations of prior methods by modeling complex inter-function associations, resulting in better vulnerability detection performance. The framework's effectiveness is demonstrated through improved results on standard datasets and real-world scenarios."}}
{"id": "2506.21138", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21138", "abs": "https://arxiv.org/abs/2506.21138", "authors": ["Abdelkarim El-Hajjami", "Camille Salinesi"], "title": "How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE", "comment": null, "summary": "The shortage of publicly available, labeled requirements datasets remains a\nmajor barrier to advancing Artificial Intelligence for Requirements Engineering\n(AI4RE). While Large Language Models offer promising capabilities for synthetic\ndata generation, systematic approaches to control and optimize the quality of\ngenerated requirements remain underexplored. This paper presents Synthline v1,\nan enhanced Product Line approach for generating synthetic requirements data\nthat extends our earlier v0 version with advanced generation strategies and\ncuration techniques. We investigate four research questions assessing how\nprompting strategies, automated prompt optimization, and post-generation\ncuration affect data quality across four classification tasks: defect\ndetection, functional vs. non-functional, quality vs. non-quality, and security\nvs. non-security. Our evaluation shows that multi-sample prompting\nsignificantly boosts both utility and diversity over single-sample generation,\nwith F1-score gains from 6 to 44 points. The use of PACE (Prompt Actor-Critic\nEditing) for automated prompt optimization yields task-dependent results,\ngreatly improving functional classification (+32.5 points) but reducing\nperformance on others. Interestingly, similarity-based curation improves\ndiversity but often harms classification performance, indicating that some\nredundancy may help ML models. Most importantly, our results show that\nsynthetic requirements can match or outperform human-authored ones for specific\ntasks, with synthetic data surpassing human data for security (+7.8 points) and\ndefect classification (+15.4 points). These findings offer practical insights\nfor AI4RE and chart a viable path to mitigating dataset scarcity through\nsystematic synthetic generation.", "AI": {"tldr": "Synthline v1 offers an advanced, systematic approach to generating synthetic requirements data using LLMs. Through careful prompting, automated optimization, and curation, the method not only produces diverse, high-quality datasets but in some cases surpasses human-authored data, supporting the advancement of AI in requirements engineering despite dataset shortages.", "motivation": "The main motivation is the scarcity of labeled requirements datasets, which hinders progress in applying Artificial Intelligence to Requirements Engineering (AI4RE). There is a specific need for systematic methods to generate high-quality synthetic requirements data using Large Language Models (LLMs).", "method": "The authors introduce Synthline v1, an improved Product Line approach for generating synthetic requirements datasets. They incorporate advanced generation strategies, automated prompt optimization (using PACE), and post-generation curation. Four research questions are studied across four classification tasks to evaluate how these methods affect data quality.", "result": "Results demonstrate that multi-sample prompting increases both utility and diversity, with F1-score improvements of 6 to 44 points compared to single-sample generation. Automated prompt optimization via PACE shows task-dependent effects, significantly aiding functional classification but sometimes reducing performance in other tasks. Similarity-based curation enhances diversity but can hurt classification performance. Critically, synthetic data can equal or surpass human-authored data for several tasks, particularly security (+7.8 points) and defect classification (+15.4 points).", "conclusion": "Systematic methods for LLM-based synthetic requirements data generation are effective and can produce data of equal or greater quality than human-generated equivalents in some tasks. These techniques can help address the data scarcity problem in AI4RE."}}
{"id": "2506.21211", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21211", "abs": "https://arxiv.org/abs/2506.21211", "authors": ["Quanming Liu", "Xupeng Bu", "Zhichao Yan", "Ru Li"], "title": "$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models", "comment": null, "summary": "Automatic Program Repair (APR) is a core technology in software development\nand maintenance, with aims to enable automated defect repair with minimal human\nintervention. In recent years, the substantial advancements in Large Language\nModels (LLMs) and the Chain-of-Thought (CoT) techniques have significantly\nenhanced the reasoning capabilities of these models. However, due to the\ncomplex logic and multi-step reasoning ability needed, the application of CoT\ntechniques in the APR domain remains insufficient. This study systematically\nevaluates the performance of several common CoT techniques in APR tasks and\nproposes an innovative framework $T^3$, which integrates the powerful reasoning\ncapabilities of LLMs with tree search, effectively improving the precision of\ngenerating candidate repair solutions. Furthermore, $T^3$ provides valuable\nguidance for optimizing sample selection and repair strategies in APR tasks,\nestablishing a robust framework for achieving efficient automated debugging.", "AI": {"tldr": "This paper presents T^3, a framework that merges large language models' reasoning with tree search to improve automatic program repair, resulting in more precise and efficient bug fixes with minimal human intervention.", "motivation": "Automatic Program Repair (APR) aims to fix software defects with minimal human input, but the application of advanced reasoning techniques, such as Chain-of-Thought (CoT) from large language models (LLMs), has been limited in APR due to the complex logic and multi-step reasoning required.", "method": "The paper systematically evaluates several common Chain-of-Thought (CoT) techniques in APR tasks and introduces a novel framework called T^3. T^3 combines LLMs' reasoning abilities with a tree search approach to enhance the precision of generating candidate repair solutions.", "result": "The proposed T^3 framework significantly improves the quality of candidate repairs in APR and offers effective guidance for both sample selection and repair strategy formulation, leading to more efficient automated debugging.", "conclusion": "Integrating LLM-based reasoning and tree search within the T^3 framework provides a robust and effective solution for automatic program repair, addressing previous limitations in applying CoT to APR and paving the way for better automated defect fixing strategies."}}
{"id": "2506.21266", "categories": ["cs.SE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.21266", "abs": "https://arxiv.org/abs/2506.21266", "authors": ["Daniil Karol", "Elizaveta Artser", "Ilya Vlasov", "Yaroslav Golubev", "Hieke Keuning", "Anastasiia Birillo"], "title": "KOALA: a Configurable Tool for Collecting IDE Data When Solving Programming Tasks", "comment": "Accepted to CompEd'25, 7 pages, 4 figures", "summary": "Collecting data of students solving programming tasks is incredibly valuable\nfor researchers and educators. It allows verifying that the students correctly\napply the features and concepts they are taught, or finding students'\nmisconceptions. However, existing data collection tools have limitations, e.g.,\nno control over the granularity of the collected code, not collecting the\nspecific events of the programming environment used, and overall being hard to\nconfigure.\n  To overcome these limitations, we propose KOALA, a convenient and highly\nconfigurable tool for collecting code snapshots and feature usage from students\nsolving programming tasks in JetBrains IDEs. The plugin can be installed in\nIDEs and configured to provide the students with the necessary tasks, enable or\ndisable certain IDE features like code completion, and run surveys. During\nproblem solving, the plugin collects code snapshots at the configured\ngranularity, all IDE actions like running and debugging, as well as some data\nnot collected in prior works, like employed hotkeys and switching focus between\nfiles. The collected data is sent to the server that comes with the tool, where\nit is stored and can be converted to the standardized ProgSnap2 format. To\nshowcase the tool, we collected data from 28 students solving tasks in two\ncourses within the IDE, highlighting some insights from this data.", "AI": {"tldr": "KOALA is a flexible data collection plugin for JetBrains IDEs, enabling educators and researchers to capture detailed, configurable programming activity data from students, overcoming the limitations of previous tools. Initial deployment showed it can reveal new insights into student learning behaviors.", "motivation": "Existing tools for collecting data on students solving programming tasks have notable limitations, such as lack of control over data granularity, incomplete event capture, and complex configuration. There is a need for a more flexible and comprehensive tool for researchers and educators to better analyze and support student learning in programming environments.", "method": "The authors developed KOALA, a configurable plugin for JetBrains IDEs, which collects code snapshots and monitors a variety of IDE interactions during students' problem solving. KOALA can be set up to control task distribution, enable/disable IDE features, conduct surveys, and capture data at customizable granularities. The collected data is sent to a server and can be converted into a standardized format (ProgSnap2) for further analysis.", "result": "The tool was deployed in two courses, collecting data from 28 students. The data included detailed records of code snapshots, IDE actions, and user behavior not typically captured by previous tools, such as hotkey usage and file-switching frequency. Initial analysis highlighted new insights into student learning and behavior within programming tasks.", "conclusion": "KOALA offers a significant advancement in data collection for programming education research, providing richer and more configurable datasets than previous tools. Its deployment demonstrated both the feasibility and the value of capturing a broader spectrum of student activity in educational programming environments."}}
{"id": "2506.21297", "categories": ["cs.SE", "cs.DC", "D.2.11; D.2.13; D.2.7"], "pdf": "https://arxiv.org/pdf/2506.21297", "abs": "https://arxiv.org/abs/2506.21297", "authors": ["Ricardo Hideki Hangai Kojo", "Luiz Fernando Corte Real", "Renato Cordeiro Ferreira", "Thatiane de Oliveira Rosa", "Alfredo Goldman"], "title": "Exploring Micro Frontends: A Case Study Application in E-Commerce", "comment": "11 pages, 2 figures (2 diagrams), submitted to the workshop AMP 2025", "summary": "In the micro frontends architectural style, the frontend is divided into\nsmaller components, which can range from a simple button to an entire page. The\ngoal is to improve scalability, resilience, and team independence, albeit at\nthe cost of increased complexity and infrastructure demands. This paper seeks\nto understand when it is worth adopting micro frontends, particularly in the\ncontext of industry. To achieve this, we conducted an investigation into the\nstate of the art of micro frontends, based on both academic and gray\nliterature. We then implemented this architectural style in a marketplace for\nhandcrafted products, which already used microservices. Finally, we evaluated\nthe implementation through a semi-open questionnaire with the developers. At\nthe studied marketplace company, the need for architectural change arose due to\nthe tight coupling between their main system (a Java monolith) and a dedicated\nfrontend system. Additionally, there were deprecated technologies and poor\ndeveloper experience. To address these issues, the micro frontends architecture\nwas adopted, along with the API Gateway and Backend for Frontend patterns, and\ntechnologies such as Svelte and Fastify. Although the adoption of Micro\nFrontends was successful, it was not strictly necessary to meet the company's\nneeds. According to the analysis of the mixed questionnaire responses, other\nalternatives, such as a monolithic frontend, could have achieved comparable\nresults. What made adopting micro frontends the most convenient choice in the\ncompany's context was the monolith strangulation and microservices adoption,\nwhich facilitated implementation through infrastructure reuse and knowledge\nsharing between teams.", "AI": {"tldr": "Adopting micro frontends in a marketplace improved scalability and developer experience, but was not strictly necessary\u2014other solutions could work as well. The migration made sense mainly because the company was already breaking up a monolith and using microservices, enabling easier implementation and team collaboration.", "motivation": "The motivation for this paper is to evaluate when adopting micro frontends is worthwhile, particularly in industrial contexts where challenges such as tight system coupling, deprecated technologies, and poor developer experience are present.", "method": "The authors conducted a review of both academic and gray literature on micro frontends, implemented the micro frontend architecture in a real-world handcrafted products marketplace (which already used microservices), and then evaluated the implementation via a semi-open questionnaire with developers.", "result": "The findings revealed that, although the adoption of micro frontends was successful, it was not strictly necessary to meet the organization's goals. Other approaches, like a monolithic frontend, could have also fulfilled the needs. The decision to adopt micro frontends was primarily influenced by ongoing monolith strangulation, existing microservices, and the benefits of infrastructure and knowledge reuse.", "conclusion": "Micro frontends can be a convenient choice in environments already moving towards microservices and monolith decomposition, but they introduce additional complexity and may not always be required for achieving organizational goals. Alternatives should be carefully considered based on context."}}
{"id": "2506.21300", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.21300", "abs": "https://arxiv.org/abs/2506.21300", "authors": ["Yannis Bertrand", "Christian Imenkamp", "Lukas Malburg", "Matthias Ehrendorfer", "Marco Franceschetti", "Joscha Gr\u00fcger", "Francesco Leotta", "J\u00fcrgen Mangler", "Ronny Seiger", "Agnes Koschmider", "Stefanie Rinderle-Ma", "Barbara Weber", "Estefania Serral"], "title": "An object-centric core metamodel for IoT-enhanced event logs", "comment": null, "summary": "Advances in Internet-of-Things (IoT) technologies have prompted the\nintegration of IoT devices with business processes (BPs) in many organizations\nacross various sectors, such as manufacturing, healthcare and smart spaces. The\nproliferation of IoT devices leads to the generation of large amounts of IoT\ndata providing a window on the physical context of BPs, which facilitates the\ndiscovery of new insights about BPs using process mining (PM) techniques.\nHowever, to achieve these benefits, IoT data need to be combined with\ntraditional process (event) data, which is challenging due to the very\ndifferent characteristics of IoT and process data, for instance in terms of\ngranularity levels. Recently, several data models were proposed to integrate\nIoT data with process data, each focusing on different aspects of data\nintegration based on different assumptions and requirements. This fragmentation\nhampers data exchange and collaboration in the field of PM, e.g., making it\ntedious for researchers to share data. In this paper, we present a core model\nsynthesizing the most important features of existing data models. As the core\nmodel is based on common requirements, it greatly facilitates data sharing and\ncollaboration in the field. A prototypical Python implementation is used to\nevaluate the model against various use cases and demonstrate that it satisfies\nthese common requirements.", "AI": {"tldr": "A new core data model is introduced to bridge IoT and process event data, overcoming existing fragmentation and enabling easier data sharing and collaboration in process mining. A Python prototype shows the model works across different use cases.", "motivation": "The integration of IoT devices into business processes generates vast amounts of diverse data, revealing new insights through process mining. However, merging IoT data with traditional event data is challenging due to different data characteristics and fragmented data models, which hinders data sharing and collaboration.", "method": "The authors propose a core data model that synthesizes key features from existing models, driven by shared requirements. They implement a Python prototype to validate the model against multiple use cases, checking whether it meets these requirements.", "result": "The proposed core model successfully addresses the challenge of integrating IoT and process data, facilitating data sharing and collaboration. The Python prototype demonstrates the model's applicability and effectiveness across various scenarios.", "conclusion": "The paper provides a unified, requirement-driven data model that streamlines the integration of IoT and process data for process mining, promoting easier data exchange and increasing collaborative potential in the field."}}
