{"id": "2506.20754", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.20754", "abs": "https://arxiv.org/abs/2506.20754", "authors": ["Marina Ara\u00fajo", "J\u00falia Ara\u00fajo", "Romeu Oliveira", "Lucas Romao", "Marcos Kalinowski"], "title": "Domain Knowledge in Requirements Engineering: A Systematic Mapping Study", "comment": "Accepted for publication at the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA) 2025", "summary": "[Context] Domain knowledge is recognized as a key component for the success\nof Requirements Engineering (RE), as it provides the conceptual support needed\nto understand the system context, ensure alignment with stakeholder needs, and\nreduce ambiguity in requirements specification. Despite its relevance, the\nscientific literature still lacks a systematic consolidation of how domain\nknowledge can be effectively used and operationalized in RE. [Goal] This paper\naddresses this gap by offering a comprehensive overview of existing\ncontributions, including methods, techniques, and tools to incorporate domain\nknowledge into RE practices. [Method] We conducted a systematic mapping study\nusing a hybrid search strategy that combines database searches with iterative\nbackward and forward snowballing. [Results] In total, we found 75 papers that\nmet our inclusion criteria. The analysis highlights the main types of\nrequirements addressed, the most frequently considered quality attributes, and\nrecurring challenges in the formalization, acquisition, and long-term\nmaintenance of domain knowledge. The results provide support for researchers\nand practitioners in identifying established approaches and unresolved issues.\nThe study also outlines promising directions for future research, emphasizing\nthe development of scalable, automated, and sustainable solutions to integrate\ndomain knowledge into RE processes. [Conclusion] The study contributes by\nproviding a comprehensive overview that helps to build a conceptual and\nmethodological foundation for knowledge-driven requirements engineering.", "AI": {"tldr": "This paper systematically reviews how domain knowledge is incorporated in Requirements Engineering, analyzes 75 relevant studies, summarizes challenges and best practices, and provides guidance for future research.", "motivation": "Domain knowledge is crucial in Requirements Engineering (RE) for understanding system context and stakeholder needs, yet there is no systematic overview of how it is effectively utilized within RE.", "method": "The paper uses a systematic mapping study with a hybrid search strategy, combining database searches and iterative backward/forward snowballing to identify relevant literature.", "result": "75 relevant papers were identified. The analysis reveals key requirement types, frequently considered quality attributes, and common challenges related to domain knowledge, such as its formalization, acquisition, and maintenance. The study supports researchers and practitioners, and points to the need for scalable and automated solutions.", "conclusion": "The paper offers a comprehensive overview that lays a conceptual and methodological foundation for knowledge-driven requirements engineering, identifying established methods and unresolved issues."}}
{"id": "2506.20759", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20759", "abs": "https://arxiv.org/abs/2506.20759", "authors": ["Lucas Romao", "Hugo Villamizar", "Romeu Oliveira", "Silvio Alonso", "Marcos Kalinowski"], "title": "Agile Management for Machine Learning: A Systematic Mapping Study", "comment": "Accepted for publication at the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA) 2025", "summary": "[Context] Machine learning (ML)-enabled systems are present in our society,\ndriving significant digital transformations. The dynamic nature of ML\ndevelopment, characterized by experimental cycles and rapid changes in data,\nposes challenges to traditional project management. Agile methods, with their\nflexibility and incremental delivery, seem well-suited to address this\ndynamism. However, it is unclear how to effectively apply these methods in the\ncontext of ML-enabled systems, where challenges require tailored approaches.\n[Goal] Our goal is to outline the state of the art in agile management for\nML-enabled systems. [Method] We conducted a systematic mapping study using a\nhybrid search strategy that combines database searches with backward and\nforward snowballing iterations. [Results] Our study identified 27 papers\npublished between 2008 and 2024. From these, we identified eight frameworks and\ncategorized recommendations and practices into eight key themes, such as\nIteration Flexibility, Innovative ML-specific Artifacts, and the Minimal Viable\nModel. The main challenge identified across studies was accurate effort\nestimation for ML-related tasks. [Conclusion] This study contributes by mapping\nthe state of the art and identifying open gaps in the field. While relevant\nwork exists, more robust empirical evaluation is still needed to validate these\ncontributions.", "AI": {"tldr": "Agile methods show promise for managing ML-enabled systems, but current literature reveals gaps and challenges, especially in effort estimation. More empirical studies are needed for validation.", "motivation": "Machine learning-enabled systems are increasingly prevalent and require project management strategies that can handle rapid changes and experimental cycles. Traditional project management approaches struggle with the unique characteristics of ML development, while agile methods appear promising but lack clear tailoring for ML contexts. This gap motivates analysis of current agile approaches for ML systems.", "method": "The authors performed a systematic mapping study, combining database searches with backward and forward snowballing techniques, to gather and analyze relevant literature on agile methods in ML-enabled system development.", "result": "The study reviewed 27 papers published between 2008 and 2024, identifying eight frameworks and categorizing recommendations into eight key themes, such as Iteration Flexibility and Minimal Viable Model. Accurate effort estimation for ML tasks emerged as the principal challenge.", "conclusion": "The study maps the current state of agile project management for ML-enabled systems and highlights open research gaps. Although progress has been made, further strong empirical evaluation is needed to solidify these agile approaches."}}
{"id": "2506.20851", "categories": ["cs.SE", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2506.20851", "abs": "https://arxiv.org/abs/2506.20851", "authors": ["Srikar Reddy Gadusu", "Larry Callahan", "Samir Lababidi", "Arunasri Nishtala", "Sophia Healey", "Hande McGinty"], "title": "Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach", "comment": null, "summary": "As data and knowledge expand rapidly, adopting systematic methodologies for\nontology generation has become crucial. With the daily increases in data\nvolumes and frequent content changes, the demand for databases to store and\nretrieve information for the creation of knowledge graphs has become\nincreasingly urgent. The previously established Knowledge Acquisition and\nRepresentation Methodology (KNARM) outlines a systematic approach to address\nthese challenges and create knowledge graphs. However, following this\nmethodology highlights the existing challenge of seamlessly integrating Neo4j\ndatabases with the Web Ontology Language (OWL). Previous attempts to integrate\ndata from Neo4j into an ontology have been discussed, but these approaches\noften require an understanding of description logics (DL) syntax, which may not\nbe familiar to many users. Thus, a more accessible method is necessary to\nbridge this gap. This paper presents a user-friendly approach that utilizes\nPython and its rdflib library to support ontology development. We showcase our\nnovel approach through a Neo4j database we created by integrating data from the\nFood and Drug Administration (FDA) Adverse Event Reporting System (FAERS)\ndatabase. Using this dataset, we developed a Python script that automatically\ngenerates the required classes and their axioms, facilitating a smoother\nintegration process. This approach offers a practical solution to the\nchallenges of ontology generation in the context of rapidly growing adverse\ndrug event datasets, supporting improved drug safety monitoring and public\nhealth decision-making.", "AI": {"tldr": "The paper introduces an accessible, Python-based method to automatically generate OWL ontologies from Neo4j databases, showcased with FDA adverse drug event data, significantly simplifying the process for users and supporting better drug safety analysis.", "motivation": "Due to the rapid expansion of data and knowledge, and frequent content changes, the need for scalable, systematic, and user-friendly methodologies for ontology and knowledge graph generation has become critical, especially for integrating graph databases like Neo4j with ontologies such as OWL.", "method": "The paper presents a Python-based approach utilizing the rdflib library to automatically generate ontology classes and their axioms from a Neo4j database. This is demonstrated using data integrated from the FDA Adverse Event Reporting System (FAERS).", "result": "The authors developed a Python script that automates the generation of ontology components from Neo4j data, streamlining the process for users unfamiliar with description logics (DL) syntax. The approach effectively supports the creation of knowledge graphs for rapidly growing pharmaceutical datasets.", "conclusion": "This user-friendly Python/rdflib method bridges the gap between Neo4j databases and OWL ontologies, providing a practical, accessible solution for ontology generation, particularly beneficial for drug safety monitoring and public health."}}
{"id": "2506.20869", "categories": ["cs.SE", "cs.AI", "cs.IR", "D.2.11; I.2.6; H.3.3"], "pdf": "https://arxiv.org/pdf/2506.20869", "abs": "https://arxiv.org/abs/2506.20869", "authors": ["Md Toufique Hasan", "Muhammad Waseem", "Kai-Kristian Kemell", "Ayman Asad Khan", "Mika Saari", "Pekka Abrahamsson"], "title": "Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation", "comment": "Accepted as a full paper to the 51st Euromicro Conference on Software\n  Engineering and Advanced Applications (SEAA 2025). 9 pages, 4 figures. This\n  is the preprint version and not the final camera ready version", "summary": "Retrieval-Augmented Generation (RAG) systems are emerging as a key approach\nfor grounding Large Language Models (LLMs) in external knowledge, addressing\nlimitations in factual accuracy and contextual relevance. However, there is a\nlack of empirical studies that report on the development of RAG-based\nimplementations grounded in real-world use cases, evaluated through general\nuser involvement, and accompanied by systematic documentation of lessons\nlearned. This paper presents five domain-specific RAG applications developed\nfor real-world scenarios across governance, cybersecurity, agriculture,\nindustrial research, and medical diagnostics. Each system incorporates\nmultilingual OCR, semantic retrieval via vector embeddings, and domain-adapted\nLLMs, deployed through local servers or cloud APIs to meet distinct user needs.\nA web-based evaluation involving a total of 100 participants assessed the\nsystems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii)\nTransparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of\nRecommendation. Based on user feedback and our development experience, we\ndocumented twelve key lessons learned, highlighting technical, operational, and\nethical challenges affecting the reliability and usability of RAG systems in\npractice.", "AI": {"tldr": "This paper develops and evaluates five real-world RAG systems across diverse domains, tests them with 100 users, and presents 12 lessons learned about technical, operational, and ethical issues in practice.", "motivation": "There is a lack of empirical studies on real-world RAG (Retrieval-Augmented Generation) implementations that include user involvement and systematic documentation. The motivation is to bridge this gap by developing and evaluating RAG systems in practical scenarios.", "method": "The authors developed five domain-specific RAG applications in governance, cybersecurity, agriculture, industrial research, and medical diagnostics. These systems used multilingual OCR, semantic retrieval with vector embeddings, and domain-adapted LLMs, and were deployed via local servers or cloud APIs. They conducted a web-based evaluation with 100 participants, assessing six dimensions of user experience. Additionally, they documented twelve key lessons learned from both feedback and development experience.", "result": "The paper presented the development and evaluation results of five RAG-based systems used in real-world domains. Feedback from 100 participants provided evaluations across ease of use, relevance, transparency, responsiveness, accuracy, and likelihood of recommendation. Twelve key lessons were documented regarding technical, operational, and ethical challenges.", "conclusion": "Real-world deployment and systematic evaluation of RAG systems reveal significant insights into their reliability and usability, emphasizing the importance of addressing technical, operational, and ethical challenges in practical applications."}}
{"id": "2506.20883", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20883", "abs": "https://arxiv.org/abs/2506.20883", "authors": ["Kyanna Dagenais", "Istvan David"], "title": "Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance", "comment": "Accepted for ACM/IEEE MODELS'25", "summary": "Model-driven engineering problems often require complex model transformations\n(MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of\nsuch problems include model synchronization, automated model repair, and design\nspace exploration. Manually developing complex MTs is an error-prone and often\ninfeasible process. Reinforcement learning (RL) is an apt way to alleviate\nthese issues. In RL, an autonomous agent explores the state space through trial\nand error to identify beneficial sequences of actions, such as MTs. However, RL\nmethods exhibit performance issues in complex problems. In these situations,\nhuman guidance can be of high utility. In this paper, we present an approach\nand technical framework for developing complex MT sequences through RL, guided\nby potentially uncertain human advice. Our framework allows user-defined MTs to\nbe mapped onto RL primitives, and executes them as RL programs to find optimal\nMT sequences. Our evaluation shows that human guidance, even if uncertain,\nsubstantially improves RL performance, and results in more efficient\ndevelopment of complex MTs. Through a trade-off between the certainty and\ntimeliness of human advice, our method takes a step towards RL-driven\nhuman-in-the-loop engineering methods.", "AI": {"tldr": "The paper presents a framework that uses reinforcement learning, enhanced by human advice (even if uncertain), to automate and improve the creation of complex model transformation sequences in model-driven engineering. Human-in-the-loop guidance significantly boosts RL efficiency and effectiveness, moving model engineering closer to robust semi-automated solutions.", "motivation": "Model-driven engineering often requires chaining together complex sequences of model transformations (MTs). Manually designing such sequences is difficult and error-prone. Reinforcement learning (RL) could automate this process but struggles with performance on complex problems. The authors propose that involving uncertain but timely human advice can help overcome these performance issues in RL-driven MT development.", "method": "The authors introduce a technical framework that integrates user-defined MTs with RL primitives, allowing these transformations to be executed as RL programs. Their approach enables the RL agent to be guided by human advice, even if the advice is uncertain. The framework evaluates the impact of such human guidance on the RL-driven development of MT sequences.", "result": "The evaluation demonstrates that incorporating human guidance, even with uncertainty, significantly boosts RL performance. The approach enables more efficient and effective development of complex MTs compared to using RL alone.", "conclusion": "The combination of RL and human-in-the-loop advice enhances the automation and quality of developing complex model transformation sequences in model-driven engineering. The method paves the way for RL-driven human-in-the-loop engineering processes by balancing the certainty and timeliness of human input."}}
{"id": "2506.21014", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.21014", "abs": "https://arxiv.org/abs/2506.21014", "authors": ["Shaojian Qiu", "Mengyang Huang", "Jiahao Cheng"], "title": "Boosting Vulnerability Detection with Inter-function Multilateral Association Insights", "comment": null, "summary": "Vulnerability detection is a crucial yet challenging technique for ensuring\nthe security of software systems. Currently, most deep learning-based\nvulnerability detection methods focus on stand-alone functions, neglecting the\ncomplex inter-function interrelations, particularly the multilateral\nassociations. This oversight can fail to detect vulnerabilities in these\ninterrelations. To address this gap, we present an Inter-Function Multilateral\nAssociation analysis framework for Vulnerability Detection (IFMA-VD). The\ncornerstone of the IFMA-VD lies in constructing a code behavior hypergraph and\nutilizing hyperedge convolution to extract multilateral association features.\nSpecifically, we first parse functions into a code property graph to generate\nintra-function features. Following this, we construct a code behavior\nhypergraph by segmenting the program dependency graph to isolate and encode\nbehavioral features into hyperedges. Finally, we utilize a hypergraph network\nto capture the multilateral association knowledge for augmenting vulnerability\ndetection. We evaluate IFMA-VD on three widely used vulnerability datasets and\ndemonstrate improvements in F-measure and Recall compared to baseline methods.\nAdditionally, we illustrate that multilateral association features can boost\ncode feature representation and validate the effectiveness of IFMA-VD on\nreal-world datasets.", "AI": {"tldr": "This paper introduces IFMA-VD, a framework that models complex inter-function relationships with hypergraphs to enhance vulnerability detection, showing better performance over existing methods on multiple datasets.", "motivation": "Most existing vulnerability detection methods using deep learning focus only on individual functions and ignore the complex relationships, especially multilateral associations, between different functions. This omission can lead to missed vulnerabilities that occur due to these interrelations.", "method": "The authors propose a framework called IFMA-VD that constructs a code behavior hypergraph and uses hyperedge convolution to extract multilateral association features. The process involves parsing functions into a code property graph for intra-function features, building a code behavior hypergraph from a program dependency graph, and applying a hypergraph network to capture multilateral association knowledge for improved vulnerability detection.", "result": "IFMA-VD was evaluated on three widely used vulnerability datasets and outperformed baseline methods in terms of F-measure and Recall. The study also shows that incorporating multilateral association features strengthens code feature representation and that IFMA-VD is effective on real-world datasets.", "conclusion": "Considering multilateral inter-function associations via hypergraph modeling and hyperedge convolutions enhances deep learning-based vulnerability detection methods in their ability to find vulnerabilities, as demonstrated by improved performance metrics and validations on real-world data."}}
{"id": "2506.21138", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21138", "abs": "https://arxiv.org/abs/2506.21138", "authors": ["Abdelkarim El-Hajjami", "Camille Salinesi"], "title": "How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE", "comment": null, "summary": "The shortage of publicly available, labeled requirements datasets remains a\nmajor barrier to advancing Artificial Intelligence for Requirements Engineering\n(AI4RE). While Large Language Models offer promising capabilities for synthetic\ndata generation, systematic approaches to control and optimize the quality of\ngenerated requirements remain underexplored. This paper presents Synthline v1,\nan enhanced Product Line approach for generating synthetic requirements data\nthat extends our earlier v0 version with advanced generation strategies and\ncuration techniques. We investigate four research questions assessing how\nprompting strategies, automated prompt optimization, and post-generation\ncuration affect data quality across four classification tasks: defect\ndetection, functional vs. non-functional, quality vs. non-quality, and security\nvs. non-security. Our evaluation shows that multi-sample prompting\nsignificantly boosts both utility and diversity over single-sample generation,\nwith F1-score gains from 6 to 44 points. The use of PACE (Prompt Actor-Critic\nEditing) for automated prompt optimization yields task-dependent results,\ngreatly improving functional classification (+32.5 points) but reducing\nperformance on others. Interestingly, similarity-based curation improves\ndiversity but often harms classification performance, indicating that some\nredundancy may help ML models. Most importantly, our results show that\nsynthetic requirements can match or outperform human-authored ones for specific\ntasks, with synthetic data surpassing human data for security (+7.8 points) and\ndefect classification (+15.4 points). These findings offer practical insights\nfor AI4RE and chart a viable path to mitigating dataset scarcity through\nsystematic synthetic generation.", "AI": {"tldr": "The paper introduces Synthline v1, an improved approach to generating synthetic requirements datasets. By comparing various generation and curation techniques, the authors show that synthetic data, when carefully crafted, can rival or outperform human-written requirements in select AI tasks\u2014helping solve dataset scarcity in the field.", "motivation": "There is a lack of large, publicly available annotated datasets for requirements engineering, which holds back progress in applying AI to this field. Synthetic data generation via Large Language Models (LLMs) is a promising direction, but methods for controlling and optimizing the quality of generated requirements data have not been fully investigated.", "method": "The authors present Synthline v1, a product line-based approach to generate synthetic requirements datasets. They extend their previous work with advanced prompt generation strategies and curation methods. Four experiments are conducted to analyze how prompting techniques, automated prompt optimization (PACE), and post-generation curation affect data quality across four requirements engineering classification tasks.", "result": "Multi-sample prompting increases both the usefulness and variety of generated data compared to single-sample approaches, leading to F1-score improvements from 6 to 44 points. Automated prompt optimization (PACE) shows significant gains for some tasks but decreased results for others. Similarity-based data curation improves diversity but can negatively impact model performance, suggesting some redundancy supports machine learning. Notably, synthetic requirements can match or even surpass the performance of human-authored datasets in tasks like security and defect classification.", "conclusion": "Systematic synthetic generation of requirements datasets, using advanced LLM prompting and curation, is effective and can potentially overcome the shortage of high-quality data for AI4RE. Synthetic data can, in some cases, outperform real human-authored data, indicating its viability for future research and applications."}}
{"id": "2506.21211", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21211", "abs": "https://arxiv.org/abs/2506.21211", "authors": ["Quanming Liu", "Xupeng Bu", "Zhichao Yan", "Ru Li"], "title": "$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models", "comment": null, "summary": "Automatic Program Repair (APR) is a core technology in software development\nand maintenance, with aims to enable automated defect repair with minimal human\nintervention. In recent years, the substantial advancements in Large Language\nModels (LLMs) and the Chain-of-Thought (CoT) techniques have significantly\nenhanced the reasoning capabilities of these models. However, due to the\ncomplex logic and multi-step reasoning ability needed, the application of CoT\ntechniques in the APR domain remains insufficient. This study systematically\nevaluates the performance of several common CoT techniques in APR tasks and\nproposes an innovative framework $T^3$, which integrates the powerful reasoning\ncapabilities of LLMs with tree search, effectively improving the precision of\ngenerating candidate repair solutions. Furthermore, $T^3$ provides valuable\nguidance for optimizing sample selection and repair strategies in APR tasks,\nestablishing a robust framework for achieving efficient automated debugging.", "AI": {"tldr": "The paper evaluates how well reasoning-based AI models work for automated program repair and proposes a new, more effective framework ($T^3$) that improves repair accuracy and efficiency by integrating reasoning and tree search strategies.", "motivation": "Automatic Program Repair (APR) is critical in software engineering for reducing manual debugging effort. While Large Language Models (LLMs) and Chain-of-Thought (CoT) techniques have improved automated reasoning, their applications to APR tasks\u2014requiring complex, multi-step logic\u2014are underexplored.", "method": "The paper systematically evaluates existing CoT techniques on APR tasks. It introduces a novel framework, $T^3$, which combines LLMs\u2019 reasoning abilities with tree search methods to enhance the accuracy of candidate repairs. $T^3$ also aids in optimizing sample selection and repair tactics.", "result": "The $T^3$ framework leads to more precise generation of repair candidates and offers structured guidance on sample selection and repair strategies, improving the overall efficiency and robustness of automated debugging.", "conclusion": "Integrating advanced reasoning techniques from LLMs and tree search in the $T^3$ framework marks a significant step forward for APR, showing performance improvements and providing a strong foundation for future automated debugging solutions."}}
{"id": "2506.21266", "categories": ["cs.SE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.21266", "abs": "https://arxiv.org/abs/2506.21266", "authors": ["Daniil Karol", "Elizaveta Artser", "Ilya Vlasov", "Yaroslav Golubev", "Hieke Keuning", "Anastasiia Birillo"], "title": "KOALA: a Configurable Tool for Collecting IDE Data When Solving Programming Tasks", "comment": "Accepted to CompEd'25, 7 pages, 4 figures", "summary": "Collecting data of students solving programming tasks is incredibly valuable\nfor researchers and educators. It allows verifying that the students correctly\napply the features and concepts they are taught, or finding students'\nmisconceptions. However, existing data collection tools have limitations, e.g.,\nno control over the granularity of the collected code, not collecting the\nspecific events of the programming environment used, and overall being hard to\nconfigure.\n  To overcome these limitations, we propose KOALA, a convenient and highly\nconfigurable tool for collecting code snapshots and feature usage from students\nsolving programming tasks in JetBrains IDEs. The plugin can be installed in\nIDEs and configured to provide the students with the necessary tasks, enable or\ndisable certain IDE features like code completion, and run surveys. During\nproblem solving, the plugin collects code snapshots at the configured\ngranularity, all IDE actions like running and debugging, as well as some data\nnot collected in prior works, like employed hotkeys and switching focus between\nfiles. The collected data is sent to the server that comes with the tool, where\nit is stored and can be converted to the standardized ProgSnap2 format. To\nshowcase the tool, we collected data from 28 students solving tasks in two\ncourses within the IDE, highlighting some insights from this data.", "AI": {"tldr": "KOALA is a new, configurable plugin for JetBrains IDEs that collects detailed data (code snapshots, IDE actions, feature usage) from students' programming activities, addresses key limitations of previous tools, and provides researchers richer insights into student learning.", "motivation": "Current tools for collecting student programming data have significant limitations: they lack fine-grained control over what is recorded, miss key events within the programming environment, and are generally difficult to configure. This hinders educators and researchers in fully understanding student activity and learning processes.", "method": "The authors introduce KOALA, a configurable data collection plugin for JetBrains IDEs. KOALA can control the granularity of collected code snapshots, logs IDE actions (such as running/debugging), feature usage (like code completion and hotkeys), and even tracks file focus changes. It can distribute programming tasks, control IDE features, and run surveys. Data is stored on a server and can be exported to the standardized ProgSnap2 format.", "result": "The KOALA tool was successfully deployed to collect data from 28 students in two programming courses. The data included code snapshots, IDE actions, and additional usage metrics not typically gathered by previous tools, providing valuable new insights into student programming behaviors.", "conclusion": "KOALA fills gaps left by previous data collection tools, offering educators and researchers a powerful, flexible way to study how students interact with programming environments. The extra dimensions of data provide new opportunities for analyzing student learning and behavior."}}
{"id": "2506.21297", "categories": ["cs.SE", "cs.DC", "D.2.11; D.2.13; D.2.7"], "pdf": "https://arxiv.org/pdf/2506.21297", "abs": "https://arxiv.org/abs/2506.21297", "authors": ["Ricardo Hideki Hangai Kojo", "Luiz Fernando Corte Real", "Renato Cordeiro Ferreira", "Thatiane de Oliveira Rosa", "Alfredo Goldman"], "title": "Exploring Micro Frontends: A Case Study Application in E-Commerce", "comment": "11 pages, 2 figures (2 diagrams), submitted to the workshop AMP 2025", "summary": "In the micro frontends architectural style, the frontend is divided into\nsmaller components, which can range from a simple button to an entire page. The\ngoal is to improve scalability, resilience, and team independence, albeit at\nthe cost of increased complexity and infrastructure demands. This paper seeks\nto understand when it is worth adopting micro frontends, particularly in the\ncontext of industry. To achieve this, we conducted an investigation into the\nstate of the art of micro frontends, based on both academic and gray\nliterature. We then implemented this architectural style in a marketplace for\nhandcrafted products, which already used microservices. Finally, we evaluated\nthe implementation through a semi-open questionnaire with the developers. At\nthe studied marketplace company, the need for architectural change arose due to\nthe tight coupling between their main system (a Java monolith) and a dedicated\nfrontend system. Additionally, there were deprecated technologies and poor\ndeveloper experience. To address these issues, the micro frontends architecture\nwas adopted, along with the API Gateway and Backend for Frontend patterns, and\ntechnologies such as Svelte and Fastify. Although the adoption of Micro\nFrontends was successful, it was not strictly necessary to meet the company's\nneeds. According to the analysis of the mixed questionnaire responses, other\nalternatives, such as a monolithic frontend, could have achieved comparable\nresults. What made adopting micro frontends the most convenient choice in the\ncompany's context was the monolith strangulation and microservices adoption,\nwhich facilitated implementation through infrastructure reuse and knowledge\nsharing between teams.", "AI": {"tldr": "Micro frontends were successfully implemented to modernize a marketplace's frontend, but similar results could've been achieved with simpler solutions. The main justification was alignment with existing microservices and organizational context, not intrinsic technical necessity.", "motivation": "The paper aims to understand when adopting the micro frontends architectural style is beneficial, especially within industry settings. The motivation stems from challenges such as system tight coupling, deprecated technologies, and suboptimal developer experiences in an existing marketplace company.", "method": "The authors undertook a literature review of both academic and gray sources, implemented micro frontends in an existing microservices-based marketplace, and evaluated the outcome via a semi-open questionnaire given to developers.", "result": "The implementation of micro frontends was successful but found not to be strictly necessary; similar outcomes might have been achieved with a monolithic frontend. The choice was ultimately driven by the context: the ongoing shift away from a monolithic architecture (monolith strangulation) and the reuse of microservices infrastructure and team expertise.", "conclusion": "While micro frontends added complexity, their adoption was most appropriate due to infrastructure and organizational context, though not strictly required for the business needs. Other architectures could potentially have sufficed."}}
{"id": "2506.21300", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.21300", "abs": "https://arxiv.org/abs/2506.21300", "authors": ["Yannis Bertrand", "Christian Imenkamp", "Lukas Malburg", "Matthias Ehrendorfer", "Marco Franceschetti", "Joscha Gr\u00fcger", "Francesco Leotta", "J\u00fcrgen Mangler", "Ronny Seiger", "Agnes Koschmider", "Stefanie Rinderle-Ma", "Barbara Weber", "Estefania Serral"], "title": "An object-centric core metamodel for IoT-enhanced event logs", "comment": null, "summary": "Advances in Internet-of-Things (IoT) technologies have prompted the\nintegration of IoT devices with business processes (BPs) in many organizations\nacross various sectors, such as manufacturing, healthcare and smart spaces. The\nproliferation of IoT devices leads to the generation of large amounts of IoT\ndata providing a window on the physical context of BPs, which facilitates the\ndiscovery of new insights about BPs using process mining (PM) techniques.\nHowever, to achieve these benefits, IoT data need to be combined with\ntraditional process (event) data, which is challenging due to the very\ndifferent characteristics of IoT and process data, for instance in terms of\ngranularity levels. Recently, several data models were proposed to integrate\nIoT data with process data, each focusing on different aspects of data\nintegration based on different assumptions and requirements. This fragmentation\nhampers data exchange and collaboration in the field of PM, e.g., making it\ntedious for researchers to share data. In this paper, we present a core model\nsynthesizing the most important features of existing data models. As the core\nmodel is based on common requirements, it greatly facilitates data sharing and\ncollaboration in the field. A prototypical Python implementation is used to\nevaluate the model against various use cases and demonstrate that it satisfies\nthese common requirements.", "AI": {"tldr": "A core data model for integrating IoT and process data is proposed, overcoming current fragmentation and enabling easier data sharing in process mining. A Python prototype validates its effectiveness across use cases.", "motivation": "The motivation is to address the challenges of integrating IoT data with traditional business process data for process mining. Due to differences in data granularity and fragmented data models, effective data sharing and collaboration are hard to achieve.", "method": "The authors synthesize existing data models into a core model that incorporates the most important and common features from current approaches. They develop a prototypical Python implementation to evaluate the model against practical use cases.", "result": "The core model successfully supports the integration of IoT and process data, facilitating data sharing and collaboration. The Python prototype demonstrates that the model meets common integration requirements across use cases.", "conclusion": "By synthesizing and standardizing the most important features of existing models, the proposed core model overcomes fragmentation. This greatly eases data exchange and collaboration in process mining for IoT-augmented business processes."}}
