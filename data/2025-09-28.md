<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 7]
- [cs.PL](#cs.PL) [Total: 2]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation](https://arxiv.org/abs/2509.20380)
*Samyak Jhaveri,Vanessa Klotzmann,Crista Lopes*

Main category: cs.SE

TL;DR: ACCeLLiuM introduces fine-tuned large language models for generating accurate OpenACC GPU directives. These outperform base LLMs, correctly producing valid pragmas in most cases. Dataset, models, and code are publicly released to foster reproducible research and lower GPU programming barriers.


<details>
  <summary>Details</summary>
Motivation: GPU programming is becoming widespread but remains complex. Directive-based frameworks like OpenACC help, but considerable expertise is still needed to use these directives correctly.

Method: The authors introduce ACCeLLiuM, two large language models (open weights) specifically fine-tuned for generating expert-level OpenACC directives for data-parallel loops. They created and publicly released a supervised fine-tuning dataset (ACCeLLiuM SFT dataset) consisting of 4,033 OpenACC pragma-loop pairs sourced from GitHub C/C++ repositories.

Result: Fine-tuned LLMs on the ACCeLLiuM dataset outperform base LLMs in generating valid OpenACC pragmas. On the test set, fine-tuned models correctly generate pragmas for 87% of data-parallel loops, with exact matches (directives, clauses, order, variables) in 50% of cases.

Conclusion: ACCeLLiuM LLMs significantly improve automated generation of OpenACC pragmas, thereby lowering the barrier for GPU offloading in serial programs. The public release of code, models, and dataset aims to establish a reproducible benchmark for LLM-powered OpenACC pragma generation.

Abstract: The increasing ubiquity of GPUs is accompanied by the increasing complexity
of their hardware and parallel programming frameworks. Directive-based parallel
programming standards like OpenACC simplify GPU programming to some extent by
abstracting away low-level complexities, but a fair amount of expertise is
still required in order to use those directives effectively.
  We introduce ACCeLLiuM, two open weights Large Language Models specifically
fine-tuned for generating expert OpenACC directives for data-parallel loops,
along with the supervised fine-tuning dataset that was used to train them. The
ACCeLLiuM SFT dataset contains 4,033 OpenACC pragma-loop pairs mined from
public GitHub C/C++ repositories, with 3,223 pairs for training and 810 for
testing. Experimental evaluations show a pronounced performance gap in
generating correct OpenACC pragmas between base LLMs and our fine-tuned
versions. On the held-out test set, base LLMs fail to consistently generate
valid pragmas, whereas LLMs fine-tuned on the ACCeLLiuM dataset generate valid
pragmas with the correct directive type for $87\%$ of the data-parallel loops,
and exact pragmas--including directives, clauses, clause order, and clause
variables--for $50\%$ of the cases. Even when not exact, generated pragmas
frequently incorporate the correct clauses in a different order than the
ground-truth label, or include additional clauses that enable finer control
over parallel execution, data movement, and concurrency, offering practical
value beyond strict string-matching. By publicly releasing the code, models,
and dataset as ACCeLLiuM we hope to establish a reproducible benchmark for
LLM-powered OpenACC pragma generation, and lower the barrier to automated GPU
offloading of serially written programs.

</details>


### [2] [Enhancing Python Programming Education with an AI-Powered Code Helper: Design, Implementation, and Impact](https://arxiv.org/abs/2509.20518)
*Sayed Mahbub Hasan Amiri,Md Mainul Islam*

Main category: cs.SE

TL;DR: An AI-powered chatbot using CodeLlama and GPT-4 was developed to help students with programming, especially debugging and understanding concepts. It outperformed existing tools, improved coding proficiency and speed, and was positively reviewed by students. This showcases how AI can be effectively used in education to foster deeper learning.


<details>
  <summary>Details</summary>
Motivation: Traditional coding tools and existing AI-driven assistants lack interactive, learning-focused support for students—IDEs/static analyzers are non-robotic, and tools like GitHub Copilot focus on code completion rather than learning. The paper aims to fill this gap by creating an AI chatbot that assists in debugging, syntax issues, and conceptual translation, supporting student learning rather than just task completion.

Method: The method involves integrating static code analysis, dynamic execution tracing, and large language models (LLMs) in a hybrid architecture. CodeLlama is used for code embedding, GPT-4 handles natural language interaction, and a Docker-based sandbox ensures secure code execution. The system is evaluated with mixed methods: performance on 1,500 student submissions, quantitative analysis of debugging time and proficiency, and qualitative feedback from 120 students.

Result: The chatbot achieved an 85% error resolution success rate, outperforming tools like pylint (62%) or standalone GPT-4 (73%). Students using the chatbot reduced debugging time by 59.3% and saw a 34% improvement in coding proficiency, particularly in recursion and exception handling. Qualitative feedback praised the chatbot's clarity and confidence-building, despite occasional latency and restrictive sanitization.

Conclusion: This research shows that an AI chatbot designed with both technical innovation and pedagogical sensitivity can significantly improve programming education, promoting conceptual understanding and educational equity instead of just code completion. The system demonstrates how AI can successfully augment human instruction.

Abstract: This is the study that presents an AI-Python-based chatbot that helps
students to learn programming by demonstrating solutions to such problems as
debugging errors, solving syntax problems or converting abstract theoretical
concepts to practical implementations. Traditional coding tools like Integrated
Development Environments (IDEs) and static analyzers do not give robotic help
while AI-driven code assistants such as GitHub Copilot focus on getting things
done. To close this gap, our chatbot combines static code analysis, dynamic
execution tracing, and large language models (LLMs) to provide the students
with relevant and practical advice, hence promoting the learning process. The
chatbots hybrid architecture employs CodeLlama for code embedding, GPT-4 for
natural language interactions, and Docker-based sandboxing for secure
execution. Evaluated through a mixed-methods approach involving 1,500 student
submissions, the system demonstrated an 85% error resolution success rate,
outperforming standalone tools like pylint (62%) and GPT-4 (73%). Quantitative
results revealed a 59.3% reduction in debugging time among users, with pre- and
post-test assessments showing a 34% improvement in coding proficiency,
particularly in recursion and exception handling. Qualitative feedback from 120
students highlighted the chatbots clarity, accessibility, and
confidence-building impact, though critiques included occasional latency and
restrictive code sanitization. By balancing technical innovation with
pedagogical empathy, this research provides a blueprint for AI tools that
prioritize educational equity and long-term skill retention over mere code
completion. The chatbot exemplifies how AI can augment human instruction,
fostering deeper conceptual understanding in programming education.

</details>


### [3] [State-of-the-Art in Software Security Visualization: A Systematic Review](https://arxiv.org/abs/2509.20385)
*Ishara Devendra,Chaman Wijesiriwardana,Prasad Wimalaratne*

Main category: cs.SE

TL;DR: As cybersecurity challenges grow, traditional security analysis methods are less effective. This paper systematically reviews recent research, categorizes visualization techniques, and defines key trends in software security visualization. Its findings spotlight the urgent need for new, adaptable visualization methods to enhance threat detection and security management.


<details>
  <summary>Details</summary>
Motivation: Traditional methods of analyzing software security—text-based and numerical approaches—are increasingly ineffective as software systems and threats become more complex. There is a need for more accessible and effective ways to interpret and act on security data.

Method: This paper conducts a systematic review of over 60 recent research papers related to software security visualization and develops a taxonomy categorizing existing visualization techniques into four types: graph-based, notation-based, matrix-based, and metaphor-based.

Result: The review underscores the evolution of software security visualization, identifies the strengths and weaknesses of various techniques, and structures the field into two primary areas: software development visualization (focusing on architectural depiction) and cybersecurity visualization (focusing on operational and threat-focused aspects). The study also highlights the necessity for continued innovation in visualization methods to keep pace with evolving security threats.

Conclusion: Innovative and adaptive visualization techniques are essential for effective software security management. The taxonomy and trends identified in this systematic review provide practical insights for improving threat detection, optimizing security responses, and guiding future research in this dynamic field.

Abstract: Software security visualization is an interdisciplinary field that combines
the technical complexity of cybersecurity, including threat intelligence and
compliance monitoring, with visual analytics, transforming complex security
data into easily digestible visual formats. As software systems get more
complex and the threat landscape evolves, traditional text-based and numerical
methods for analyzing and interpreting security concerns become increasingly
ineffective. The purpose of this paper is to systematically review existing
research and create a comprehensive taxonomy of software security visualization
techniques through literature, categorizing these techniques into four types:
graph-based, notation-based, matrix-based, and metaphor-based visualization.
This systematic review explores over 60 recent key research papers in software
security visualization, highlighting its key issues, recent advancements, and
prospective future research directions. From the comprehensive analysis, the
two main areas were distinctly highlighted as extensive software development
visualization, focusing on advanced methods for depicting software
architecture: operational security visualization and cybersecurity
visualization. The findings highlight the necessity for innovative
visualization techniques that adapt to the evolving security landscape, with
practical implications for enhancing threat detection, improving security
response strategies, and guiding future research.

</details>


### [4] [Dynamic ReAct: Scalable Tool Selection for Large-Scale MCP Environments](https://arxiv.org/abs/2509.20386)
*Nishant Gaurav,Adit Akarsh,Ankit Ranjan,Manoj Bajaj*

Main category: cs.SE

TL;DR: Dynamic ReAct introduces a set of architectures that allow AI agents to intelligently manage and select from large toolsets, reducing resource usage while preserving performance.


<details>
  <summary>Details</summary>
Motivation: The motivation is to solve the problem faced by ReAct agents when dealing with numerous tools in Model Control Protocol environments, where loading every tool is computationally infeasible due to the memory limitations of large language models.

Method: Five distinct architectures are proposed and evaluated, culminating in a search-and-load mechanism for dynamic and efficient tool selection.

Result: The approach reduces tool loading by up to 50% while maintaining task completion accuracy.

Conclusion: The work advances general-purpose AI agents that can dynamically adapt to diverse task environments, demonstrating effective scalable tool selection.

Abstract: We present Dynamic ReAct, a novel approach for enabling ReAct agents to ef-
ficiently operate with extensive Model Control Protocol (MCP) tool sets that
exceed the contextual memory limitations of large language models. Our approach
addresses the fundamental challenge of tool selection in environments
containing hundreds or thousands of available tools, where loading all tools
simultaneously is computationally infeasible. We propose and evaluate five
distinct architectures that progressively refine the tool selection process,
culminating in a search-and-load mechanism that achieves intelligent tool
selection with minimal computational overhead. Our experimental results
demonstrate that the proposed approach reduces tool loading by up to 50% while
maintaining task completion accuracy, advancing the path towards truly
general-purpose AI agents capable of dynamically adapting to diverse task
environments.

</details>


### [5] [Towards Systematic Specification and Verification of Fairness Requirements: A Position Paper](https://arxiv.org/abs/2509.20387)
*Qusai Ramadan,Jukka Ruohonen,Abhishek Tiwari,Adam Alami,Zeyd Boukhers*

Main category: cs.SE

TL;DR: Current approaches to fairness in software overlook requirement specification and verification. This paper proposes using knowledge graphs to formalize fairness requirements, discusses related challenges, and presents a plan for future research.


<details>
  <summary>Details</summary>
Motivation: Software systems can inadvertently discriminate against people based on protected attributes like gender and ethnicity. Prior research focuses on biased algorithms or data but overlooks the absence of well-specified fairness requirements and their verification. Experts' knowledge about fairness is often implicit, complicating the specification and verification process.

Method: The paper proposes the development of a knowledge graph-based framework to formalize fairness requirements. It suggests leveraging methodologies from related areas, such as security engineering, where knowledge graphs assist in formalizing and verifying requirements.

Result: The main result is the identification of challenges and research questions around specifying and verifying fairness requirements using knowledge graphs. The paper outlines a road map for future research but does not present experimental results.

Conclusion: A knowledge graph-based framework is a promising approach to specify and verify fairness requirements in software systems, addressing shortcomings in current practices.

Abstract: Decisions suggested by improperly designed software systems might be prone to
discriminate against people based on protected characteristics, such as gender
and ethnicity. Previous studies attribute such undesired behavior to flaws in
algorithmic design or biased data. However, these studies ignore that
discrimination is often the result of a lack of well-specified fairness
requirements and their verification. The fact that experts' knowledge about
fairness is often implicit makes the task of specifying precise and verifiable
fairness requirements difficult. In related domains, such as security
engineering, knowledge graphs have been proven to be effective in formalizing
knowledge to assist requirements specification and verification. To address the
lack of formal mechanisms for specifying and verifying fairness requirements,
we propose the development of a knowledge graph-based framework for fairness.
In this paper, we discuss the challenges, research questions, and a road map
towards addressing the research questions.

</details>


### [6] [Online-Optimized RAG for Tool Use and Function Calling](https://arxiv.org/abs/2509.20415)
*Yu Pan,Xiaocheng Li,Hanzhao Wang*

Main category: cs.SE

TL;DR: Embedding misalignment in retrieval-augmented generation systems causes retrieval errors and task failures. This paper proposes Online-Optimized RAG, which updates embeddings in real time with minimal feedback, boosting tool selection accuracy and overall performance in diverse applications, without modifying the underlying LLM.


<details>
  <summary>Details</summary>
Motivation: Retrieval-augmented generation (RAG) systems are commonly used for tool use and function calling by embedding user queries and matching them to tool descriptions. However, in practice, embedding misalignment caused by imperfect models or noisy descriptions can lead to incorrect retrieval results and task failures.

Method: The paper introduces Online-Optimized RAG, a deployment-time framework that adapts retrieval embeddings using minimal feedback from live interactions (such as task success). The system applies lightweight online gradient updates with negligible latency, requiring no changes to the underlying language model.

Result: Across various tool-use and document-retrieval scenarios, Online-Optimized RAG consistently enhances tool selection accuracy and end-task success rates.

Conclusion: Online-Optimized RAG offers a practical and robust solution for improving retrieval-alignments in RAG systems, is plug-and-play, and enables self-improving tool use without altering the core LLM.

Abstract: In many applications, retrieval-augmented generation (RAG) drives tool use
and function calling by embedding the (user) queries and matching them to
pre-specified tool/function descriptions. In this paper, we address an
embedding misalignment issue that often arises in practical applications due to
imperfect embedding models or noisy descriptions; such misalignment may lead to
incorrect retrieval and task failure. We introduce Online-Optimized RAG, a
deployment-time framework that continually adapts retrieval embeddings from
live interactions using minimal feedback (e.g., task success). Online-Optimized
RAG applies lightweight online gradient updates with negligible per-query
latency and requires no changes to the underlying LLM. The method is
plug-and-play: it supports both single- and multi-hop tool use, dynamic tool
inventories, and $K$-retrieval with re-ranking. We provide a problem-dependent
theoretical analysis that quantifies how the method's performance depends on
the initialization quality of the embeddings and other related quantities.
Across diverse tool-use and document-retrieval scenarios, our Online-Optimized
RAG consistently improves tool selection accuracy and end-task success, thus
providing a simple, practical path to robust, self-improving RAG systems.

</details>


### [7] [Formal Verification of Legal Contracts: A Translation-based Approach](https://arxiv.org/abs/2509.20421)
*Reiner Hähnle,Cosimo Laneve,Adele Veschetti*

Main category: cs.SE

TL;DR: The paper introduces a method to automatically verify Stipula legal contracts by translating them into annotated Java code and checking them with the KeY tool, proving this approach works well for many contract types.


<details>
  <summary>Details</summary>
Motivation: Legal contracts, especially involving asset transfers and obligations, require reliable and enforceable modeling tools. There is a need for formal verification methods that ensure the correctness of these contracts.

Method: The methodology involves translating Stipula contracts into Java code with annotations in the Java Modeling Language. The deductive verification tool KeY is used as the backend to verify the correctness.

Result: For a large subset of Stipula contracts, specifically those with disjoint cycles, both the translation and verification processes are fully automatic.

Conclusion: A general-purpose deductive verification tool, such as KeY, can be effectively applied in an automatic translation-then-verification approach to ensure the correctness of domain-specific contract languages like Stipula.

Abstract: Stipula is a domain-specific programming language designed to model legal
contracts with enforceable properties, especially those involving asset
transfers and obligations. This paper presents a methodology to formally verify
the correctness of Stipula contracts through translation into Java code
annotated with Java Modeling Language specifications. As a verification
backend, the deductive verification tool KeY is used. Both, the translation and
the verification of partial and total correctness for a large subset of Stipula
contracts, those with disjoint cycles, is fully automatic. Our work
demonstrates that a general-purpose deductive verification tool can be used
successfully in a translation approach.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [8] [Dual-Language General-Purpose Self-Hosted Visual Language and new Textual Programming Language for Applications](https://arxiv.org/abs/2509.20426)
*Mahmoud Samir Fayed*

Main category: cs.PL

TL;DR: The paper introduces PWCT2, a dual-language, general-purpose self-hosting visual programming language developed with and for easy future extension. Using the newly developed Ring textual language, PWCT2 is shown to be dramatically more efficient and space-saving compared to its predecessor. User feedback from a broad public release demonstrates its practicality and appeal, pushing VPLs closer to mainstream adoption.


<details>
  <summary>Details</summary>
Motivation: Most existing visual programming languages (VPLs) are domain-specific and are developed or improved using textual programming, presenting a barrier to non-programmers. There is a need for a more accessible, general-purpose, and self-sustaining VPL.

Method: The researchers first designed a new textual programming language called Ring, characterized by dynamic typing, lightweight implementation, and extensive syntax customization. Then, they used the original PWCT visual language to develop the Ring compiler and virtual machine, and subsequently developed PWCT2 (a self-hosting VPL) using the Ring language.

Result: PWCT2 achieved approximately 36 times faster code generation and required 20 times less storage for visual source files compared to its predecessor. It includes a mechanism to convert Ring code to visual code (self-hosting). PWCT2 consists of around 92,000 lines of Ring code and 394 visual components. It has been distributed on Steam, launched by 1,772 users with over 17,000 total hours recorded, and received positive user feedback.

Conclusion: PWCT2 provides a significant advancement in general-purpose, self-hosting visual programming languages, making development easier and more accessible. The integration of the Ring language and the move towards self-sustainability demonstrate major improvements in VPL capabilities, efficiency, and user adoption.

Abstract: Most visual programming languages (VPLs) are domain-specific, with few
general-purpose VPLs like Programming Without Coding Technology (PWCT). These
general-purpose VPLs are developed using textual programming languages and
improving them requires textual programming. In this thesis, we designed and
developed PWCT2, a dual-language (Arabic/English), general-purpose,
self-hosting visual programming language. Before doing so, we specifically
designed a textual programming language called Ring for its development. Ring
is a dynamically typed language with a lightweight implementation, offering
syntax customization features. It permits the creation of domain-specific
languages through new features that extend object-oriented programming,
allowing for specialized languages resembling Cascading Style Sheets (CSS) or
Supernova language. The Ring Compiler and Virtual Machine are designed using
the PWCT visual programming language where the visual implementation is
composed of 18,945 components that generate 24,743 lines of C code, which
increases the abstraction level and hides unnecessary details. Using PWCT to
develop Ring allowed us to realize several issues in PWCT, which led to the
development of the PWCT2 visual programming language using the Ring textual
programming language. PWCT2 provides approximately 36 times faster code
generation and requires 20 times less storage for visual source files. It also
allows for the conversion of Ring code into visual code, enabling the creation
of a self-hosting VPL that can be developed using itself. PWCT2 consists of
approximately 92,000 lines of Ring code and comes with 394 visual components.
PWCT2 is distributed to many users through the Steam platform and has received
positive feedback, On Steam, 1772 users have launched the software, and the
total recorded usage time exceeds 17,000 hours, encouraging further research
and development.

</details>


### [9] [Efficient Symbolic Computation vis Hash Consing](https://arxiv.org/abs/2509.20534)
*Bowen Zhu,Aayush Sabharwal,Songchen Tan,Yingbo Ma,Alan Edelman,Christopher Rackauckas*

Main category: cs.PL

TL;DR: The paper shows that introducing hash consing to JuliaSymbolics significantly cuts memory use and speeds up symbolic computation tasks, helping both classic algebra and AI systems run more efficiently by avoiding redundant subexpression storage.


<details>
  <summary>Details</summary>
Motivation: Symbolic computation systems often struggle with 'expression swell'—the redundant storage of structurally identical subexpressions, which leads to inefficiencies in memory usage and slows down performance. This is a significant problem in both traditional computer algebra systems and new AI-driven mathematical reasoning tools.

Method: The paper introduces the integration of hash consing into JuliaSymbolics, a symbolic computation library in Julia. By using a global weak-reference hash table, the system canonicalizes expressions and removes duplicates, ensuring only unique subexpressions are stored in memory. This method seamlessly supports Julia’s metaprogramming and just-in-time compilation features.

Result: Benchmarking across diverse computational domains shows substantial performance improvements: up to 3.2x faster symbolic computation, 2x less memory used, up to 5x faster code generation, 10x faster function compilation, and up to 100x faster numerical evaluation on larger models. While scenarios with fewer duplicate expressions may see smaller benefits or slight overheads initially, later computation stages still realize significant gains.

Conclusion: Incorporating hash consing into JuliaSymbolics meaningfully reduces memory usage and accelerates many core symbolic operations. This strengthens the scalability of symbolic computations and lays groundwork for further enhancements—such as integrating with e-graphs to enable smarter expression sharing in AI applications.

Abstract: Symbolic computation systems suffer from memory inefficiencies due to
redundant storage of structurally identical subexpressions, commonly known as
expression swell, which degrades performance in both classical computer algebra
and emerging AI-driven mathematical reasoning tools. In this paper, we present
the first integration of hash consing into JuliaSymbolics, a high-performance
symbolic toolkit in Julia, by employing a global weak-reference hash table that
canonicalizes expressions and eliminates duplication. This approach reduces
memory consumption and accelerates key operations such as differentiation,
simplification, and code generation, while seamlessly integrating with Julia's
metaprogramming and just-in-time compilation infrastructure. Benchmark
evaluations across different computational domains reveal substantial
improvements: symbolic computations are accelerated by up to 3.2 times, memory
usage is reduced by up to 2 times, code generation is up to 5 times faster,
function compilation up to 10 times faster, and numerical evaluation up to 100
times faster for larger models. While certain workloads with fewer duplicate
unknown-variable expressions show more modest gains or even slight overhead in
initial computation stages, downstream processing consistently benefits
significantly. These findings underscore the importance of hash consing in
scaling symbolic computation and pave the way for future work integrating hash
consing with e-graphs for enhanced equivalence-aware expression sharing in
AI-driven pipelines.

</details>
