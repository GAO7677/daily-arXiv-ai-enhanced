<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 17]
- [cs.PL](#cs.PL) [Total: 6]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Evaluating Large Language Models for Functional and Maintainable Code in Industrial Settings: A Case Study at ASML](https://arxiv.org/abs/2509.12395)
*Yash Mundhra,Max Valk,Maliheh Izadi*

Main category: cs.SE

TL;DR: LLMs can generate maintainable code for proprietary industrial environments if properly prompted, especially with few-shot and chain-of-thought methods; model size matters, while being code-specific provides only minor, context-dependent advantages.


<details>
  <summary>Details</summary>
Motivation: Large language models (LLMs) have demonstrated strong performance on open-source code, but their utility in proprietary industrial environments, where code is more specialized and interdependent, is underexplored. The paper aims to fill this gap by studying LLM code generation within a real-world, highly specialized industrial setting.

Method: The authors collaborated with the leveling department at ASML to develop a custom evaluation framework and benchmark based on ASML's proprietary codebase. They also proposed a new metric, build@k, to measure if LLM-generated code compiles and integrates in industrial repositories. The study compares various prompting methods, evaluates generic versus code-specific LLMs, and measures the effect of model size using both match-based and execution-based metrics.

Result: The results show that prompting techniques and model size strongly affect the quality of generated code, with few-shot and chain-of-thought prompting delivering the highest build success rates. Performance differences between code-specific and generic LLMs were relatively minor and varied by model family.

Conclusion: Prompting strategies and model size are key factors in successful code generation for highly specialized industrial repositories, while the advantage of code-specific LLMs over generic LLMs is context-dependent and not universally substantial.

Abstract: Large language models have shown impressive performance in various domains,
including code generation across diverse open-source domains. However, their
applicability in proprietary industrial settings, where domain-specific
constraints and code interdependencies are prevalent, remains largely
unexplored. We present a case study conducted in collaboration with the
leveling department at ASML to investigate the performance of LLMs in
generating functional, maintainable code within a closed, highly specialized
software environment.
  We developed an evaluation framework tailored to ASML's proprietary codebase
and introduced a new benchmark. Additionally, we proposed a new evaluation
metric, build@k, to assess whether LLM-generated code successfully compiles and
integrates within real industrial repositories. We investigate various
prompting techniques, compare the performance of generic and code-specific
LLMs, and examine the impact of model size on code generation capabilities,
using both match-based and execution-based metrics. The findings reveal that
prompting techniques and model size have a significant impact on output
quality, with few-shot and chain-of-thought prompting yielding the highest
build success rates. The difference in performance between the code-specific
LLMs and generic LLMs was less pronounced and varied substantially across
different model families.

</details>


### [2] [Understanding Prompt Management in GitHub Repositories: A Call for Best Practices](https://arxiv.org/abs/2509.12421)
*Hao Li,Hicham Masri,Filipe R. Cogo,Abdul Ali Bangash,Bram Adams,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: This paper empirically analyzes nearly 25,000 open-source prompts and finds major issues with formatting, duplication, and readability. It offers practical guidance to help developers manage and improve prompt quality in the evolving promptware ecosystem.


<details>
  <summary>Details</summary>
Motivation: With the rapid growth of foundation models and widespread use of promptware, there is an urgent need to improve prompt management practices and assure prompt quality, which are still largely unexplored and problematic in real-world usage.

Method: The authors conducted an empirical analysis on 24,800 prompts collected from 92 open-source GitHub repositories to investigate current practices and quality issues.

Result: The study identified key issues: inconsistent prompt formatting, significant duplication (both within and across projects), and frequent readability/spelling problems. Recommendations were formulated for developers to mitigate these challenges.

Conclusion: The paper concludes that there are substantial management and quality challenges in open-source promptware. Addressing these issues is vital for the field's progress, and their recommendations can help developers improve prompt usability and maintainability.

Abstract: The rapid adoption of foundation models (e.g., large language models) has
given rise to promptware, i.e., software built using natural language prompts.
Effective management of prompts, such as organization and quality assurance, is
essential yet challenging. In this study, we perform an empirical analysis of
24,800 open-source prompts from 92 GitHub repositories to investigate prompt
management practices and quality attributes. Our findings reveal critical
challenges such as considerable inconsistencies in prompt formatting,
substantial internal and external prompt duplication, and frequent readability
and spelling issues. Based on these findings, we provide actionable
recommendations for developers to enhance the usability and maintainability of
open-source prompts within the rapidly evolving promptware ecosystem.

</details>


### [3] [From Legacy Fortran to Portable Kokkos:An Autonomous Agentic AI Workflow](https://arxiv.org/abs/2509.12443)
*Sparsh Gupta,Kamalavasan Kamalakkannan,Maxim Moraru,Galen Shipman,Patrick Diehl*

Main category: cs.SE

TL;DR: The paper introduces an AI-driven workflow that translates and optimizes legacy Fortran code into portable Kokkos C++ using LLM agents, showing cost-effective, autonomous modernization for high-performance computing across diverse hardware. Paid LLMs succeeded where open-source ones often failed, highlighting AI's potential in scientific software transformation.


<details>
  <summary>Details</summary>
Motivation: Many scientific applications depend on legacy Fortran code designed for older, CPU-only systems. As HPC moves towards GPU-accelerated, heterogeneous platforms, there is a pressing need to make these Fortran codes portable. Existing frameworks like Kokkos provide modernization paths but require complex, manual porting. Leveraging LLMs for fully autonomous code translation and optimization in this context is not yet well-studied.

Method: The paper proposes an agentic AI workflow using specialized LLM 'agents.' These agents collectively handle the full pipeline: translating Fortran code to Kokkos C++, validating, compiling, running, testing, debugging, and optimizing the code for performance portability.

Result: The workflow successfully modernized a variety of Fortran benchmark kernels, generating Kokkos C++ programs that run efficiently on various hardware. Paid models (like GPT-5) performed well, creating optimized code that often outperformed the original Fortran. In contrast, open-source models frequently failed to generate functional code.

Conclusion: Agentic AI using LLMs can feasibly automate Fortran-to-Kokkos code transformation, making legacy scientific applications portable and efficient on modern supercomputers. The study establishes agentic LLM systems as promising tools for domain-specific, structured reasoning in HPC software modernization.

Abstract: Scientific applications continue to rely on legacy Fortran codebases
originally developed for homogeneous, CPU-based systems. As High-Performance
Computing (HPC) shifts toward heterogeneous GPU-accelerated architectures, many
accelerators lack native Fortran bindings, creating an urgent need to modernize
legacy codes for portability. Frameworks like Kokkos provide performance
portability and a single-source C++ abstraction, but manual Fortran-to-Kokkos
porting demands significant expertise and time. Large language models (LLMs)
have shown promise in source-to-source code generation, yet their use in fully
autonomous workflows for translating and optimizing parallel code remains
largely unexplored, especially for performance portability across diverse
hardware.
  This paper presents an agentic AI workflow where specialized LLM "agents"
collaborate to translate, validate, compile, run, test, debug, and optimize
Fortran kernels into portable Kokkos C++ programs. Results show the pipeline
modernizes a range of benchmark kernels, producing performance-portable Kokkos
codes across hardware partitions. Paid OpenAI models such as GPT-5 and
o4-mini-high executed the workflow for only a few U.S. dollars, generating
optimized codes that surpassed Fortran baselines, whereas open-source models
like Llama4-Maverick often failed to yield functional codes.
  This work demonstrates the feasibility of agentic AI for Fortran-to-Kokkos
transformation and offers a pathway for autonomously modernizing legacy
scientific applications to run portably and efficiently on diverse
supercomputers. It further highlights the potential of LLM-driven agentic
systems to perform structured, domain-specific reasoning tasks in scientific
and systems-oriented applications.

</details>


### [4] [Perspectives, Needs and Challenges for Sustainable Software Engineering Teams: A FinServ Case Study](https://arxiv.org/abs/2509.12466)
*Satwik Ghanta,Peggy Gregory,Gul Calikli*

Main category: cs.SE

TL;DR: This paper explores how employees in a financial services firm perceive and practice Sustainable Software Engineering (SSE). There is a disconnect: management is focused on technical and economic aspects, while developers care more about workload and well-being. A one-size-fits-all approach does not work; interventions must be tailored to both organizational and human needs.


<details>
  <summary>Details</summary>
Motivation: Organizations are increasingly recognizing the importance of Sustainable Software Engineering (SSE) due to its benefits such as improved reputation, profits, and efficiency. However, the term SSE is ambiguously defined, making it difficult for organizations—especially those in specific sectors like financial services—to agree on what sustainability means in practice for their context.

Method: The study used an exploratory qualitative case study approach, including interviews and a focus group with six higher management employees and 16 software engineers at a financial services company (FinServCo). Participants ranged from junior developers to team leaders.

Result: The study discovered significant differences in how sustainability is perceived across organizational levels. Higher management emphasized technical and economic sustainability, such as cloud migration and ensuring data availability for business continuity. Developers, on the other hand, focused on human-centric issues like workload management and reducing stress. There was notable skepticism about the authenticity of organizational sustainability initiatives. Many participants suggested a dedicated sustainability team, similar to security governance structures. The findings indicate a disconnect between organizational objectives and developers' day-to-day needs.

Conclusion: SSE in the financial services context requires context-sensitive and co-designed interventions, as there is a clear gap in how sustainability is perceived and prioritized between management and developers. To be truly effective, sustainability strategies must address both organizational goals and the real needs of employees.

Abstract: Sustainable Software Engineering (SSE) is slowly becoming an industry need
for reasons including reputation enhancement, improved profits and more
efficient practices. However, SSE has many definitions, and this is a challenge
for organisations trying to build a common and broadly agreed understanding of
the term. Although much research effort has gone into identifying general SSE
practices, there is a gap in understanding the sustainability needs of specific
organisational contexts, such as financial services, which are highly
data-driven, operate under strict regulatory requirements, and handle millions
of transactions day to day. To address this gap, our research focuses on a
financial services company (FinServCo) that invited us to investigate
perceptions of sustainability in their IT function: how it could be put into
practice, who is responsible for it, and what the challenges are. We conducted
an exploratory qualitative case study using interviews and a focus group with
six higher management employees and 16 software engineers comprising various
experience levels from junior developers to team leaders. Our study found a
clear divergence in how sustainability is perceived between organisational
levels. Higher management emphasised technical and economic sustainability,
focusing on cloud migration and business continuity through data availability.
In contrast, developers highlighted human-centric concerns such as workload
management and stress reduction. Scepticism toward organisational initiatives
was also evident, with some developers viewing them as a PR strategy. Many
participants expressed a preference for a dedicated sustainability team,
drawing analogies to internal structures for security governance. The
disconnect between organisational goals and individual developer needs
highlights the importance of context-sensitive, co-designed interventions.

</details>


### [5] [Good Vibrations? A Qualitative Study of Co-Creation, Communication, Flow, and Trust in Vibe Coding](https://arxiv.org/abs/2509.12491)
*Veronica Pimenova,Sarah Fakhoury,Christian Bird,Margaret-Anne Storey,Madeline Endres*

Main category: cs.SE

TL;DR: This paper presents the first in-depth qualitative study of vibe coding, a conversational and experimental programming approach with AI. Using interviews and online discussions, the authors characterize why, how, and where vibe coding works or fails, highlighting trust as a central factor regulating developer experience. They identify practical pain points and provide emerging best practices, laying groundwork for next-gen AI dev tools and future research.


<details>
  <summary>Details</summary>
Motivation: Vibe coding is a new, fast-growing paradigm in AI-assisted software development. Despite its popularity, there is limited empirical understanding of how real developers perceive and use it, with most studies focusing on theoretical or artifact-based analysis.

Method: The authors conduct a systematic qualitative investigation using over 190,000 words of data from semi-structured interviews, Reddit threads, and LinkedIn posts. They analyze developer perceptions and practices related to vibe coding.

Result: The study provides a grounded theory of vibe coding centered on flows of conversational interaction with AI, co-creation, and developer enjoyment. It identifies that trust in AI governs the developer’s movement between delegating tasks and co-creation, impacting their workflow. The paper also uncovers pain points—such as issues with specification, reliability, debugging, latency, code review, and collaboration—and outlines emerging best practices to address these problems.

Conclusion: Vibe coding relies on conversational, iterative co-design with AI, offering benefits in flow and experimentation but facing practical challenges in reliability and collaboration. The paper sets a foundation for future improvement in AI dev tools and further research directions.

Abstract: Vibe coding, a term coined by Andrej Karpathy in February 2025, has quickly
become a compelling and controversial natural language programming paradigm in
AI-assisted software development. Centered on iterative co-design with an AI
assistant, vibe coding emphasizes flow and experimentation over strict upfront
specification. While initial studies have begun to explore this paradigm, most
focus on analyzing code artifacts or proposing theories with limited empirical
backing. There remains a need for a grounded understanding of vibe coding as it
is perceived and experienced by developers. We present the first systematic
qualitative investigation of vibe coding perceptions and practice. Drawing on
over 190,000 words from semi-structured interviews, Reddit threads, and
LinkedIn posts, we characterize what vibe coding is, why and how developers use
it, where it breaks down, and which emerging practices aim to support it. We
propose a qualitatively grounded theory of vibe coding centered on
conversational interaction with AI, co-creation, and developer flow and joy. We
find that AI trust regulates movement along a continuum from delegation to
co-creation and supports the developer experience by sustaining flow. We
surface recurring pain points and risks in areas including specification,
reliability, debugging, latency, code review burden, and collaboration. We also
present best practices that have been discovered and shared to mitigate these
challenges. We conclude with implications for the future of AI dev tools and
directions for researchers investigating vibe coding.

</details>


### [6] [Ensembling Large Language Models for Code Vulnerability Detection: An Empirical Evaluation](https://arxiv.org/abs/2509.12629)
*Zhihong Sun,Jia Li,Yao Wan,Chuanyi Li,Hongyu Zhang,Zhi jin,Ge Li,Hong Liu,Chen Lyu,Songlin Hu*

Main category: cs.SE

TL;DR: Ensemble techniques, especially the proposed Dynamic Gated Stacking, can notably enhance the reliability and accuracy of code vulnerability detection by combining strengths of multiple LLMs and addressing class imbalance issues.


<details>
  <summary>Details</summary>
Motivation: Modern software's security relies heavily on accurate code vulnerability detection. Despite progress with Large Language Models (LLMs), their results can be inconsistent across versions and architectures. This instability urges a search for methods to make vulnerability detection more robust.

Method: The authors conduct extensive experiments with five LLMs (DeepSeek-Coder-6.7B, CodeLlama-7B, CodeLlama-13B, CodeQwen1.5-7B, StarCoder2-15B) on three datasets (Devign, ReVeal, BigVul), applying three ensemble strategies—Bagging, Boosting, and Stacking. They further propose Dynamic Gated Stacking (DGS), a specialized stacking technique inspired by Mixture of Experts (MoE), to better tackle vulnerability detection.

Result: Ensemble learning methods significantly enhance code vulnerability detection performance across LLMs. Boosting is especially effective on imbalanced datasets, while the proposed DGS method consistently outperforms standard Stacking, notably improving results on class imbalance and multi-class tasks.

Conclusion: Leveraging model complementarity via ensemble learning, especially using advanced methods like DGS, can make LLM-based vulnerability detection both more robust and effective. This approach helps mitigate detection inconsistencies and offers a promising direction for future security systems.

Abstract: Code vulnerability detection is crucial for ensuring the security and
reliability of modern software systems. Recently, Large Language Models (LLMs)
have shown promising capabilities in this domain. However, notable
discrepancies in detection results often arise when analyzing identical code
segments across different training stages of the same model or among
architecturally distinct LLMs. While such inconsistencies may compromise
detection stability, they also highlight a key opportunity: the latent
complementarity among models can be harnessed through ensemble learning to
create more robust vulnerability detection systems. In this study, we explore
the potential of ensemble learning to enhance the performance of LLMs in source
code vulnerability detection. We conduct comprehensive experiments involving
five LLMs (i.e., DeepSeek-Coder-6.7B, CodeLlama-7B, CodeLlama-13B,
CodeQwen1.5-7B, and StarCoder2-15B), using three ensemble strategies (i.e.,
Bagging, Boosting, and Stacking). These experiments are carried out across
three widely adopted datasets (i.e., Devign, ReVeal, and BigVul). Inspired by
Mixture of Experts (MoE) techniques, we further propose Dynamic Gated Stacking
(DGS), a Stacking variant tailored for vulnerability detection. Our results
demonstrate that ensemble approaches can significantly improve detection
performance, with Boosting excelling in scenarios involving imbalanced
datasets. Moreover, DGS consistently outperforms traditional Stacking,
particularly in handling class imbalance and multi-class classification tasks.
These findings offer valuable insights into building more reliable and
effective LLM-based vulnerability detection systems through ensemble learning.

</details>


### [7] [When Large Language Models Meet UAVs: How Far Are We?](https://arxiv.org/abs/2509.12795)
*Yihua Chen,Xingle Que,Jiashuo Zhang,Ting Chen,Guangshun Li,Jiachi Chen*

Main category: cs.SE

TL;DR: This paper reviews academic and industry work on combining drones (UAVs) and large language models (LLMs), finding a gap between theory-heavy research and practical industrial needs. Survey results highlight barriers and suggest ways to bridge the divide for better real-world use.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore the emerging integration of UAVs (drones) with large language models (LLMs), address the gap between academic research and industry practice, and understand barriers to real-world application.

Method: The authors conducted an empirical review of 74 research papers and 56 public GitHub projects related to LLMs in UAV systems, categorized task types, compared academic and industrial emphases, and distributed an online survey to industry practitioners.

Result: Academic research is more focused on theoretical modeling and diverse tasks, while industry projects emphasize practical operations such as flight control and human-machine interaction. 40.4% of surveyed practitioners have tried applying LLMs to UAVs, with several real-world barriers identified: technological maturity, performance, safety, and cost.

Conclusion: There is a misalignment between academic pursuits and industry needs, hindering effective LLM integration in UAVs. Key challenges and recommendations are outlined to enhance real-world adoption and future development.

Abstract: The integration of unmanned aerial vehicles (UAVs) and large language models
(LLMs) has emerged as a research direction of growing interest, with the
potential to address challenges in autonomous decision-making, human-UAV
interaction, and real-time adaptability. However, existing studies have
remained largely in preliminary exploration with a limited understanding of
real-world practice, risking a misalignment between academic research and
practical needs and hindering the translation of results. To examine and
address these potential challenges, we conducted an empirical study of 74
selected papers and 56 public GitHub projects, identified nine task types for
LLMs in UAV systems, and quantified their distribution. Our findings show that
academic research emphasizes theoretical modeling and task optimization with
dispersed attention across tasks. In contrast, industrial projects focus on
flight control, task planning, and human-machine interaction, prioritizing
operability and efficiency. To further capture industry perspectives, we
distributed an online questionnaire. We obtained 52 valid responses: 40.4% of
practitioners have attempted to apply LLMs to UAV tasks. We further identify
factors that impede real-world integration, including technological maturity,
performance, safety, cost, and other considerations. Finally, we highlight
challenges for future development and provide recommendations.

</details>


### [8] [LLM-Based Approach for Enhancing Maintainability of Automotive Architectures](https://arxiv.org/abs/2509.12798)
*Nenad Petrovic,Lukasz Mazur,Alois Knoll*

Main category: cs.SE

TL;DR: Automotive systems are hindered by maintenance and update complexities, but using LLMs like GPT-4o for automation shows early potential in easing these bottlenecks through tasks such as compliance, interface checking, and architecture suggestions.


<details>
  <summary>Details</summary>
Motivation: Automotive systems face significant flexibility challenges due to complex maintenance, updates, standardization, and heterogeneous components, leading to long and difficult procedures throughout their lifecycle.

Method: The paper investigates the use of Large Language Models (LLMs), specifically OpenAI's GPT-4o, to automate processes that could improve automotive system flexibility. This is explored through three case studies: updates and compliance, interface compatibility checking, and architecture modification suggestions.

Result: Early-stage research demonstrates proof-of-concept implementations using GPT-4o across the three case studies, indicating the potential of LLMs in automating complex tasks within automotive system workflows.

Conclusion: LLMs show promise for increasing the flexibility of automotive systems by supporting automation in several key areas, although the research is preliminary and further validation is needed.

Abstract: There are many bottlenecks that decrease the flexibility of automotive
systems, making their long-term maintenance, as well as updates and extensions
in later lifecycle phases increasingly difficult, mainly due to long
re-engineering, standardization, and compliance procedures, as well as
heterogeneity and numerosity of devices and underlying software components
involved. In this paper, we explore the potential of Large Language Models
(LLMs) when it comes to the automation of tasks and processes that aim to
increase the flexibility of automotive systems. Three case studies towards
achieving this goal are considered as outcomes of early-stage research: 1)
updates, hardware abstraction, and compliance, 2) interface compatibility
checking, and 3) architecture modification suggestions. For proof-of-concept
implementation, we rely on OpenAI's GPT-4o model.

</details>


### [9] [SateLight: A Satellite Application Update Framework for Satellite Computing](https://arxiv.org/abs/2509.12809)
*Jinfeng Wen,Jianshu Zhao,Zixi Zhu,Xiaomin Zhang,Qi Liang,Ao Zhou,Shangguang Wang*

Main category: cs.SE

TL;DR: SateLight enables efficient and reliable satellite application updates using containerization, differential data reduction, and fault tolerance, significantly cutting transmission latency and ensuring update correctness, validated by both simulation and real-world application.


<details>
  <summary>Details</summary>
Motivation: Satellite computing enables onboard data processing, which reduces dependency on ground systems and enhances responsiveness. However, efficiently updating application software on satellites is challenging due to heterogeneous applications, limited bandwidth, and harsh space environments. Existing terrestrial update solutions cannot meet these constraints.

Method: SateLight is introduced as a novel application update framework for satellites. It uses containerization for managing diverse applications, a content-aware differential update strategy to reduce data transmission, a fine-grained onboard update mechanism for reconstructing applications, and a layer-based fault-tolerance system for reliable recovery.

Result: Experimental validation shows that SateLight cuts transmission latency by up to 91.18% (average 56.54%) versus current baselines and achieves 100% update correctness for all tested applications. Its practicality is further confirmed via a real-world in-orbit satellite case study.

Conclusion: SateLight effectively enables efficient, reliable, and practical software updates for satellite computing environments, outperforming existing terrestrial solutions and addressing space-specific constraints.

Abstract: Satellite computing is an emerging paradigm that empowers satellites to
perform onboard processing tasks (i.e., \textit{satellite applications}),
thereby reducing reliance on ground-based systems and improving responsiveness.
However, enabling application software updates in this context remains a
fundamental challenge due to application heterogeneity, limited
ground-to-satellite bandwidth, and harsh space conditions. Existing software
update approaches, designed primarily for terrestrial systems, fail to address
these constraints, as they assume abundant computational capacity and stable
connectivity.
  To address this gap, we propose SateLight, a practical and effective
satellite application update framework tailored for satellite computing.
SateLight leverages containerization to encapsulate heterogeneous applications,
enabling efficient deployment and maintenance. SateLight further integrates
three capabilities: (1) a content-aware differential strategy that minimizes
communication data volume, (2) a fine-grained onboard update design that
reconstructs target applications, and (3) a layer-based fault-tolerant recovery
mechanism to ensure reliability under failure-prone space conditions.
Experimental results on a satellite simulation environment with 10
representative satellite applications demonstrate that SateLight reduces
transmission latency by up to 91.18% (average 56.54%) compared to the best
currently available baseline. It also consistently ensures 100% update
correctness across all evaluated applications. Furthermore, a case study on a
real-world in-orbit satellite demonstrates the practicality of our approach.

</details>


### [10] [Evaluating Large Language Models for Code Translation: Effects of Prompt Language and Prompt Design](https://arxiv.org/abs/2509.12973)
*Aamer Aljagthami,Mohammed Banabila,Musab Alshehri,Mohammed Kabini,Mohammad D. Alahmadi*

Main category: cs.SE

TL;DR: The study systematically compares LLMs and prompt styles for code translation between C++, Java, Python, and C#. Detailed, English prompts yield better results, and all LLMs tested outperform the traditional TransCoder baseline.


<details>
  <summary>Details</summary>
Motivation: LLMs have potential for automating source-code translation, which is essential for software migration and maintenance. However, there is a lack of comparative evidence on how different models, prompt styles, and languages affect code translation quality across various programming languages.

Method: A systematic empirical evaluation was conducted using multiple LLMs and the TransCoder baseline for code translation among C++, Java, Python, and C#. Performance was measured with BLEU and CodeBLEU metrics under two prompt styles and two prompt languages (English and Arabic), considering translation direction across language pairs.

Result: Detailed prompts consistently improve code translation performance across all models and language pairs. English prompts lead to better results than Arabic prompts (13-15% higher performance). The best LLM surpasses traditional baselines like TransCoder, especially on challenging translation pairs.

Conclusion: Prompt engineering and language selection significantly influence automated code translation quality. Detailed and English prompts are preferable. State-of-the-art LLMs offer superior performance over traditional methods, aiding software modernization and interoperability.

Abstract: Large language models (LLMs) have shown promise for automated source-code
translation, a capability critical to software migration, maintenance, and
interoperability. Yet comparative evidence on how model choice, prompt design,
and prompt language shape translation quality across multiple programming
languages remains limited. This study conducts a systematic empirical
assessment of state-of-the-art LLMs for code translation among C++, Java,
Python, and C#, alongside a traditional baseline (TransCoder). Using BLEU and
CodeBLEU, we quantify syntactic fidelity and structural correctness under two
prompt styles (concise instruction and detailed specification) and two prompt
languages (English and Arabic), with direction-aware evaluation across language
pairs. Experiments show that detailed prompts deliver consistent gains across
models and translation directions, and English prompts outperform Arabic by
13-15%. The top-performing model attains the highest CodeBLEU on challenging
pairs such as Java to C# and Python to C++. Our evaluation shows that each LLM
outperforms TransCoder across the benchmark. These results demonstrate the
value of careful prompt engineering and prompt language choice, and provide
practical guidance for software modernization and cross-language
interoperability.

</details>


### [11] [Validating Solidity Code Defects using Symbolic and Concrete Execution powered by Large Language Models](https://arxiv.org/abs/2509.13023)
*Ştefan-Claudiu Susan,Andrei Arusoaie,Dorel Lucanu*

Main category: cs.SE

TL;DR: The paper presents a smart contract vulnerability detection pipeline that uses both heuristic and formal methods, reducing false alarms and manual checking. Experiments show strong results for tough vulnerabilities, making smart contract auditing more reliable and less labor-intensive.


<details>
  <summary>Details</summary>
Motivation: High false alarm rates in static analysis tools and LLMs make it difficult to reliably detect vulnerabilities in Solidity Smart Contracts, creating a need for methods that can rigorously prove the presence of defects.

Method: The paper proposes a detection pipeline that integrates custom Slither-based detectors, Large Language Models, Kontrol, and Forge, using both symbolic and concrete execution to validate vulnerabilities and generate proofs.

Result: Experiments were conducted on seven types of critical defects, with detailed findings for three challenging vulnerabilities: Reentrancy, Complex Fallback, and Faulty Access Control Policies. The method was shown to reduce manual verification effort and improve detection accuracy.

Conclusion: Combining heuristic analysis (LLMs, detectors) with formal verification (Kontrol, Forge) creates a robust, automated framework for smart contract auditing. Despite limitations with LLMs (cost, inconsistency), the approach significantly advances reliable vulnerability detection by reducing false alarms and manual effort.

Abstract: The high rate of false alarms from static analysis tools and Large Language
Models (LLMs) complicates vulnerability detection in Solidity Smart Contracts,
demanding methods that can formally or empirically prove the presence of
defects. This paper introduces a novel detection pipeline that integrates
custom Slither-based detectors, LLMs, Kontrol, and Forge. Our approach is
designed to reliably detect defects and generate proofs. We currently perform
experiments with promising results for seven types of critical defects. We
demonstrate the pipeline's efficacy by presenting our findings for three
vulnerabilities -- Reentrancy, Complex Fallback, and Faulty Access Control
Policies -- that are challenging for current verification solutions, which
often generate false alarms or fail to detect them entirely. We highlight the
potential of either symbolic or concrete execution in correctly classifying
such code faults. By chaining these instruments, our method effectively
validates true positives, significantly reducing the manual verification
burden. Although we identify potential limitations, such as the inconsistency
and the cost of LLMs, our findings establish a robust framework for combining
heuristic analysis with formal verification to achieve more reliable and
automated smart contract auditing.

</details>


### [12] [GView: A Survey of Binary Forensics via Visual, Semantic, and AI-Enhanced Analysis](https://arxiv.org/abs/2509.13025)
*Raul Zaharia,Dragoş Gavriluţ,Gheorghiţă Mutu*

Main category: cs.SE

TL;DR: GView is an open-source forensic framework that uses AI and visual tools to improve cybersecurity analysis. It incorporates large language models and logical inference, offering an extensible platform that connects industry needs with academic research advancements.


<details>
  <summary>Details</summary>
Motivation: Cybersecurity threats are becoming increasingly complex and difficult to analyze due to their sophisticated and diverse nature. There is a need for advanced tools that enhance forensic analysis to keep up with these evolving threats.

Method: GView, an open-source forensic analysis framework, has been developed with AI and visual reasoning capabilities. It leverages large language models (LLMs) to improve dynamic reasoning and streamline forensic workflows. The framework also incorporates logical inference through predicates and inference rules, both on documents and user actions.

Result: GView has evolved into a sophisticated and extensible platform that enhances forensic investigations by blending practical industry requirements with academic research innovations. Its architecture allows for the integration of AI and logical inference, improving suggestions and analysis capabilities.

Conclusion: GView demonstrates significant potential as a tool that bridges the gap between practical cybersecurity forensics and academic research, owing to its extensible, AI-powered, and inference-based approach.

Abstract: Cybersecurity threats continue to become more sophisticated and diverse in
their artifacts, boosting both their volume and complexity. To overcome those
challenges, we present GView, an open-source forensic analysis framework with
visual and AI-enhanced reasoning. It started with focus on the practical
cybersecurity industry. It has evolved significantly, incorporating large
language models (LLMs) to dynamically enhance reasoning and ease the forensic
workflows. This paper surveys both the current state of GView with its
published papers alongside those that are in the publishing process. It also
includes its innovative use of logical inference through predicates and
inference rules for both the analyzed documents and the user's actions for
better suggestions. We highlight the extensible architecture, showcasing its
potential as a bridge between the practical forensics worlds with the academic
research.

</details>


### [13] [Automating Code Generation for Semiconductor Equipment Control from Developer Utterances with LLMs](https://arxiv.org/abs/2509.13055)
*Youngkyoung Kim,Sanghyeok Park,Misoo Kim,Gangho Yoon,Eunseok Lee,Simon S. Woo*

Main category: cs.SE

TL;DR: The paper proposes a novel prompting framework (PKE) that improves large language models' ability to generate challenging low-level semiconductor code, outperforming other methods and offering a promising approach to boost productivity in the field.


<details>
  <summary>Details</summary>
Motivation: Programming low-level equipment languages like ALPG for semiconductors is challenging due to their complexity and steep learning curve. Conventional large language models (LLMs) struggle with generating such code, necessitating new methods to harness LLMs for these specialized tasks.

Method: The paper introduces Progressive Knowledge Enhancement (PKE), a multi-stage prompting framework that guides LLMs to gradually extract and utilize their latent knowledge, starting from simple and advancing to complex examples, without requiring extensive model fine-tuning.

Result: Empirical evaluations on an industrial ALPG dataset show that PKE achieves 11.1% and 15.2% higher exact match scores than the second-best technique. The study also verifies that progressive knowledge extraction based on difficulty improves generation accuracy.

Conclusion: Progressive Knowledge Enhancement (PKE) significantly enhances LLMs' ability to generate low-level equipment code, outperforming existing methods and offering a practical solution for semiconductor software development, thus increasing productivity in this domain.

Abstract: Semiconductors form the backbone of modern electronics, with their
manufacturing and testing relying on highly specialized equipment and
domain-specific programming languages. Equipment languages such as the
Algorithmic Pattern Generator (ALPG) are critical for precise hardware control
but are challenging to program due to their low-level syntax and steep learning
curve. While large language models (LLMs) have shown promise in generating
high-level code from natural language, their effectiveness on low-level
equipment languages remains limited. To address this, we propose Progressive
Knowledge Enhancement (PKE), a novel multi-stage prompting framework that
progressively extracts and activates the latent knowledge within LLMs, guiding
them from simple to complex examples without extensive fine-tuning. Empirical
evaluation on an industrial ALPG dataset shows that PKE significantly
outperforms standard prompting and surpasses state-of-the-art methods in
generating correct ALPG code, achieving 11.1\% and 15.2\% higher exact match
scores compared to the second-best technique. Further analysis of individual
components confirms that progressive knowledge extraction based on difficulty
enhances accuracy. Our study offer a practical approach to boosting LLM
capabilities for specialized low-level programming, supporting greater
productivity in semiconductor software development.

</details>


### [14] [Accelerating Discovery: Rapid Literature Screening with LLMs](https://arxiv.org/abs/2509.13103)
*Santiago Matalonga,Domenico Amalfitano,Jean Carlo Rossa Hauck,Martín Solari,Guilherme H. Travassos*

Main category: cs.SE

TL;DR: The paper presents an LLM-based tool to assist in MVLRs, showing that it can match human researchers in filtering irrelevant literature with 90% accuracy, thus saving time while maintaining research quality, though researcher oversight is still important.


<details>
  <summary>Details</summary>
Motivation: Conducting Multi Vocal Literature Reviews (MVLRs) is highly time-consuming and labor-intensive due to the need to manually review and filter thousands of unstructured sources, many of which are irrelevant. The challenge is magnified in domains like avionics, as seen in their study on Context-Aware Software Systems Testing.

Method: The authors developed an on-premises, LLM-based tool using Retrieval Augmented Generation (RAG) to help with searching and filtering documents. They applied engineering best practices and validated the tool primarily through Positive Percent Agreement (PPA) with human researchers. Tool validation also included human judgment and statistical sampling via convenience sampling methods.

Result: The LLM-based tool achieved 90% agreement (PPA) with human researchers when identifying irrelevant sources. The authors provide development information to help others adapt the tool for their domains.

Conclusion: LLM-based tools are practical and effective for supporting rigorous MVLRs and can significantly reduce researchers' time spent on low-level tasks. However, continued human involvement is necessary to ensure research rigor is not compromised.

Abstract: Background: Conducting Multi Vocal Literature Reviews (MVLRs) is often time
and effort-intensive. Researchers must review and filter a large number of
unstructured sources, which frequently contain sparse information and are
unlikely to be included in the final study. Our experience conducting an MVLR
on Context-Aware Software Systems (CASS) Testing in the avionics domain
exemplified this challenge, with over 8,000 highly heterogeneous documents
requiring review. Therefore, we developed a Large Language Model (LLM)
assistant to support the search and filtering of documents. Aims: To develop
and validate an LLM based tool that can support researchers in performing the
search and filtering of documents for an MVLR without compromising the rigor of
the research protocol. Method: We applied sound engineering practices to
develop an on-premises LLM-based tool incorporating Retrieval Augmented
Generation (RAG) to process candidate sources. Progress towards the aim was
quantified using the Positive Percent Agreement (PPA) as the primary metric to
ensure the performance of the LLM based tool. Convenience sampling, supported
by human judgment and statistical sampling, were used to verify and validate
the tool's quality-in-use. Results: The tool currently demonstrates a PPA
agreement with human researchers of 90% for sources that are not relevant to
the study. Development details are shared to support domain-specific adaptation
of the tool. Conclusions: Using LLM-based tools to support academic researchers
in rigorous MVLR is feasible. These tools can free valuable time for
higher-level, abstract tasks. However, researcher participation remains
essential to ensure that the tool supports thorough research.

</details>


### [15] [Vulnerability Patching Across Software Products and Software Components: A Case Study of Red Hat's Product Portfolio](https://arxiv.org/abs/2509.13117)
*Jukka Ruohonen,Sani Abdullahi,Abhishek Tiwari*

Main category: cs.SE

TL;DR: This paper analyzes two decades of security patching in Red Hat products and finds inconsistent trends, with some signs that the growth in unresolved vulnerabilities (security debt) is slowing down.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from challenges in software maintenance and the rising concern of security debt, specifically regarding how vulnerabilities are patched in widely-used products.

Method: The paper uses time series analysis, particularly segmented regression analysis, on data about vulnerability patching in Red Hat's products and components from 1999 to 2024.

Result: The study finds that the number of vulnerable products and components fluctuates, often following a linear trend, but with visible breakpoints suggesting exceptions. The growth in security debt may be stabilizing over time, and the patterns don't match general vulnerability trends.

Conclusion: Trends in vulnerability patching for Red Hat products are inconsistent, sometimes linear but interrupted by change points, suggesting that security debt may be stabilizing rather than continuously increasing.

Abstract: Motivated by software maintenance and the more recent concept of security
debt, the paper presents a time series analysis of vulnerability patching of
Red Hat's products and components between 1999 and 2024. According to the
results based on segmented regression analysis, the amounts of vulnerable
products and components have not been stable; a linear trend describes many of
the series well. Nor do the amounts align well with trends characterizing
vulnerabilities in general. There are also visible breakpoints indicating that
the linear trend is not universally applicable and that the growing security
debt may be stabilizing.

</details>


### [16] [Optimizing Code Embeddings and ML Classifiers for Python Source Code Vulnerability Detection](https://arxiv.org/abs/2509.13134)
*Talaya Farasat,Joachim Posegga*

Main category: cs.SE

TL;DR: Combining Word2Vec embeddings with BiLSTM models outperforms advanced models for Python vulnerability detection, showing the importance of pairing the right embeddings with classifiers.


<details>
  <summary>Details</summary>
Motivation: Manual vulnerability detection is increasingly ineffective due to the expanding scale and complexity of source code, necessitating better automated solutions.

Method: The study evaluates three code embedding techniques (Word2Vec, CodeBERT, GraphCodeBERT) with two deep learning classifiers (BiLSTM and CNN) for detecting vulnerabilities in Python source code.

Result: CNN with GraphCodeBERT performs well, but BiLSTM with Word2Vec achieves the best and most consistent results overall, sometimes outperforming more advanced models.

Conclusion: Classical code embeddings like Word2Vec, when combined with sequence models such as BiLSTM, can outperform newer embedding-classifier pairings for automated detection of Python vulnerabilities. The study highlights the value of carefully choosing embedding-classifier combinations for best results.

Abstract: In recent years, the growing complexity and scale of source code have
rendered manual software vulnerability detection increasingly impractical. To
address this challenge, automated approaches leveraging machine learning and
code embeddings have gained substantial attention. This study investigates the
optimal combination of code embedding techniques and machine learning
classifiers for vulnerability detection in Python source code. We evaluate
three embedding techniques, i.e., Word2Vec, CodeBERT, and GraphCodeBERT
alongside two deep learning classifiers, i.e., Bidirectional Long Short-Term
Memory (BiLSTM) networks and Convolutional Neural Networks (CNN). While CNN
paired with GraphCodeBERT exhibits strong performance, the BiLSTM model using
Word2Vec consistently achieves superior overall results. These findings suggest
that, despite the advanced architectures of recent models like CodeBERT and
GraphCodeBERT, classical embeddings such as Word2Vec, when used with
sequence-based models like BiLSTM, can offer a slight yet consistent
performance advantage. The study underscores the critical importance of
selecting appropriate combinations of embeddings and classifiers to enhance the
effectiveness of automated vulnerability detection systems, particularly for
Python source code.

</details>


### [17] [Towards the Next Generation of Software: Insights from Grey Literature on AI-Native Applications](https://arxiv.org/abs/2509.13144)
*Lingli Cao,Shanshan Li,Ying Fan,Danyang Li,Chenxing Zhong*

Main category: cs.SE

TL;DR: AI-native applications, powered by large language models, require new software engineering approaches. This study defines their core features, quality measures, and tech stacks, offering a foundational blueprint for practitioners.


<details>
  <summary>Details</summary>
Motivation: Large language models are leading to a paradigm shift in software engineering, but practitioners lack systematic definitions, architecture, and guidance for AI-native applications.

Method: Grey literature review integrating conceptual perspectives from web searches with practical insights from GitHub open-source projects, using a structured protocol for source selection, quality assessment, and thematic analysis.

Result: Identified 106 pertinent studies. AI-native applications are defined by the central role of AI and their probabilistic nature. Key quality attributes involve reliability, usability, efficiency, and AI-specific observability. Common technology stacks include LLM orchestration frameworks, vector databases, and AI-native observability platforms.

Conclusion: This study introduces the first dual-layered engineering blueprint for AI-native applications, establishing foundational definitions, optimal qualities, and technology stacks that distinguish them from conventional systems.

Abstract: Background: The rapid advancement of large language models (LLMs) has given
rise to AI-native applications, a new paradigm in software engineering that
fundamentally redefines how software is designed, developed, and evolved.
Despite their growing prominence, AI-native applications still lack a unified
engineering definition and architectural blueprint, leaving practitioners
without systematic guidance for system design, quality assurance, and
technology selection.
  Objective: This study seeks to establish a comprehensive understanding of
AI-native applications by identifying their defining characteristics, key
quality attributes, and typical technology stacks, as well as by clarifying the
opportunities and challenges they present.
  Method: We conducted a grey literature review, integrating conceptual
perspectives retrieved from targeted Google and Bing searches with practical
insights derived from leading open-source projects on GitHub. A structured
protocol encompassing source selection, quality assessment, and thematic
analysis was applied to synthesize findings across heterogeneous sources.
  Results: We finally identified 106 studies based on the selection criteria.
The analysis reveals that AI-native applications are distinguished by two core
pillars: the central role of AI as the system's intelligence paradigm and their
inherently probabilistic, non-deterministic nature. Critical quality attributes
include reliability, usability, performance efficiency, and AI-specific
observability. In addition, a typical technology stack has begun to emerge,
comprising LLM orchestration frameworks, vector databases, and AI-native
observability platforms. These systems emphasize response quality,
cost-effectiveness, and outcome predictability, setting them apart from
conventional software systems.
  Conclusion: This study is the first to propose a dual-layered engineering
blueprint...

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [18] [Converting IEC 61131-3 LD into SFC Using Large Language Model: Dataset and Testing](https://arxiv.org/abs/2509.12593)
*Yimin Zhang,Mario de Sousa*

Main category: cs.PL

TL;DR: The paper tackles the challenge of converting Ladder Diagram to Sequential Function Chart in PLC programming using AI, specifically LLMs. After creating relevant datasets, they find that fine-tuned LLMs perform this task with high accuracy, demonstrating the approach's potential.


<details>
  <summary>Details</summary>
Motivation: Converting Ladder Diagram (LD) into Sequential Function Chart (SFC) in PLC programming is challenging due to the lack of domain-specific knowledge and state explosion, while previous algorithms struggle with these issues.

Method: The authors constructed several paired datasets of LD and SFC programs based on the IEC 61131-3 standard and explored using fine-tuned Large Language Models (LLMs) to automate the conversion process.

Result: Preliminary experiments showed that a fine-tuned LLM model could achieve up to 91% accuracy for LD-SFC conversion, with a minimum observed accuracy of 79%.

Conclusion: These results indicate that, with appropriate training and data representation, LLMs can effectively support automated LD-SFC conversion and present a promising future direction for this field.

Abstract: In the domain of Programmable Logic Controller (PLC) programming, converting
a Ladder Diagram (LD) into a Sequential Function Chart (SFC) is an inherently
challenging problem, primarily due to the lack of domain-specific knowledge and
the issue of state explosion in existing algorithms. However, the rapid
development of Artificial Intelligence (AI) - especially Large Language Model
(LLM) - offers a promising new approach.
  Despite this potential, data-driven approaches in this field have been
hindered by a lack of suitable datasets. To address this gap, we constructed
several datasets consisting of paired textual representations of SFC and LD
programs that conform to the IEC 61131-3 standard.
  Based on these datasets, we explored the feasibility of automating the LD-SFC
conversion using LLM. Our preliminary experiments show that a fine-tuned LLM
model achieves up to 91% accuracy on certain dataset, with the lowest observed
accuracy being 79%, suggesting that with proper training and representation,
LLMs can effectively support LD-SFC conversion. These early results highlight
the viability and future potential of this approach.

</details>


### [19] [Efficient Compilation of Algorithms into Compact Linear Programs](https://arxiv.org/abs/2509.13006)
*Shermin Khosravi,David Bremner*

Main category: cs.PL

TL;DR: This paper proposes a new compiler technique that generates much smaller LP formulations from algorithms, using hierarchical pipelining. Tested on benchmark problems, the method yields up to 25 times smaller LPs and faster solver performance, potentially transforming how LP-based models are created and solved.


<details>
  <summary>Details</summary>
Motivation: Existing methods for compiling algorithms into LPs generate formulations that, while polynomial in size, are often far too large for practical LP solvers. There is a need for approaches that produce much more compact LPs to improve solver performance and efficiency.

Method: The paper introduces a hierarchical linear pipelining technique, which decomposes nested program structures into synchronized regions with well-defined execution transitions. This allows constraints and variables to be localized within each region, effectively lowering overall LP size while maintaining generality and validity for all input sizes.

Result: The proposed technique was applied to the makespan problem (which is known for its exponential extension complexity) and the weighted minimum spanning tree problem (which also has large natural LPs). The approach achieved up to a 25-fold reduction in LP size and notable improvements in solver performance using both commercial and open-source LP solvers.

Conclusion: The novel hierarchical pipelining approach enables the systematic generation of substantially smaller and more efficient LP formulations from high-level algorithmic descriptions, making it feasible to solve instances previously intractable due to LP size.

Abstract: Linear Programming (LP) is widely applied in industry and is a key component
of various other mathematical problem-solving techniques. Recent work
introduced an LP compiler translating polynomial-time, polynomial-space
algorithms into polynomial-size LPs using intuitive high-level programming
languages, offering a promising alternative to manually specifying each set of
constraints through Algebraic Modeling Languages (AMLs). However, the resulting
LPs, while polynomial in size, are often extremely large, posing challenges for
existing LP solvers. In this paper, we propose a novel approach for generating
substantially smaller LPs from algorithms. Our goal is to establish
minimum-size compact LP formulations for problems in P having natural
formulations with exponential extension complexities. Our broader vision is to
enable the systematic generation of Compact Integer Programming (CIP)
formulations for problems with exponential-size IPs having polynomial-time
separation oracles. To this end, we introduce a hierarchical linear pipelining
technique that decomposes nested program structures into synchronized regions
with well-defined execution transitions -- functions of compile-time
parameters. This decomposition allows us to localize LP constraints and
variables within each region, significantly reducing LP size without the loss
of generality, ensuring the resulting LP remains valid for all inputs of size
$n$. We demonstrate the effectiveness of our method on two benchmark problems
-- the makespan problem, which has exponential extension complexity, and the
weighted minimum spanning tree problem -- both of which have exponential-size
natural LPs. Our results show up to a $25$-fold reduction in LP size and
substantial improvements in solver performance across both commercial and
non-commercial LP solvers.

</details>


### [20] [Pleasant Imperative Program Proofs with GallinaC](https://arxiv.org/abs/2509.13019)
*Frédéric Fort,David Nowak,Vlad Rusu*

Main category: cs.PL

TL;DR: GallinaC embeds a Turing-complete imperative language in the Gallina proof assistant, simplifying mathematical correctness proofs for imperative programs. It has shown promising initial results with machine-checked proofs, focusing next on integration with CompCert.


<details>
  <summary>Details</summary>
Motivation: Imperative programming is crucial for low-level trusted components, but mathematically proving correctness in current imperative languages is difficult due to permissive semantics. There is a need for a proof-oriented imperative language with well-behaved semantics that can be machine-checked.

Method: The authors introduce GallinaC, a shallow embedding of an imperative language within Gallina (the Rocq proof assistant’s functional programming language). It supports Turing-completeness with unbounded loops, allowing use of proof tactics from functional programming for imperative programs.

Result: A prototype of GallinaC has been implemented, demonstrating its viability by proving the correctness of a list reversal procedure for unbounded linked lists. The current focus is on establishing a forward simulation between GallinaC's IR and Cminor, CompCert’s intermediate language.

Conclusion: GallinaC provides a promising approach for proof-oriented imperative programming inside a proof assistant, enabling rigorous correctness proofs for low-level software components while retaining imperative idioms.

Abstract: Even with the increase of popularity of functional programming, imperative
programming remains a key programming paradigm, especially for programs
operating at lower levels of abstraction. When such software offers key
components of a Trusted Computing Base (TCB), e.g. an operating system kernel,
it becomes desirable to provide mathematical correctness proofs.
  However, current real-world imperative programming languages possess
"expressive", i.e. overly permissive, semantics. Thus, producing correctness
proofs of such programs becomes tedious and error-prone, requiring to take care
of numerous "administrative" details. Ideally, a proof-oriented imperative
language should feature well-behaved semantics while allowing imperative
idioms.
  To obtain a high-degree of confidence in the correctness of such a language,
its tools should be developed inside a proof-assistant such that program proofs
are machine checked.
  We present GallinaC, a shallow embedding of a Turing-complete imperative
language directly inside the functional programming language of the Rocq proof
assistant, Gallina. In particular, it features a truly generic and unbounded
while loop. Having a functional core means proofs about GallinaC programs may
use the same tactics as proofs about pure functional ones.
  Work on GallinaC is still under progress, but we present first promising
results. A prototype implementation has shown the viability of GallinaC with
the correctness proof of a list reversal procedure for linked-lists of unknown
size. We currently focus on the forward simulation between the GallinaC
intermediate representation (IR) and Cminor, the entry language of the CompCert
back-end.

</details>


### [21] [Navigating the Python Type Jungle](https://arxiv.org/abs/2509.13022)
*Andrei Nacu,Dorel Lucanu*

Main category: cs.PL

TL;DR: The paper addresses fragmentation in Python's typing system by developing a rigorous type-theoretical framework, paving the way for better type inference and more consistent specifications.


<details>
  <summary>Details</summary>
Motivation: Python's typing system, while powerful, suffers from a lack of unified theoretical foundation and fragmented specifications, motivating a need for formalization.

Method: The paper proposes a formal framework using type theory concepts to systematically describe Python's type system.

Result: The authors provide a formal foundation demonstrating that Python's type system can be described elegantly and consistently.

Conclusion: This formalization serves as an essential starting point for designing advanced type inference tools for Python.

Abstract: Python's typing system has evolved pragmatically into a powerful but
theoretically fragmented system, with scattered specifications. This paper
proposes a formalization to address this fragmentation. The central
contribution is a formal foundation that uses concepts from type theory to
demonstrate that Python's type system can be elegantly described. This work
aims to serve as a crucial first step toward the future development of type
inference tools.

</details>


### [22] [Try-Mopsa: Relational Static Analysis in Your Pocket](https://arxiv.org/abs/2509.13128)
*Raphaël Monat*

Main category: cs.PL

TL;DR: Try-Mopsa is a browser-based, JavaScript implementation of the Mopsa static analysis tool that preserves its core functionality while enabling easy access for users and students, addressing installation and adoption challenges.


<details>
  <summary>Details</summary>
Motivation: Static analyzers are often difficult to install due to their complexity and large dependencies, creating barriers for both adoption and for students learning static analysis.

Method: Development of Try-Mopsa, a client-side JavaScript version of the Mopsa static analysis platform, requiring modifications and adaptations to support web browsers and maintain core analysis features, including relational numerical domains.

Result: Try-Mopsa successfully offers the essential features of Mopsa as a responsive web application that works on both desktop and mobile devices, overcoming installation challenges.

Conclusion: Try-Mopsa serves as a convenient and accessible tool for onboarding and teaching static analysis, lowering barriers to use.

Abstract: Static analyzers are complex pieces of software with large dependencies. They
can be difficult to install, which hinders adoption and creates barriers for
students learning static analysis. This work introduces Try-Mopsa: a
scaled-down version of the Mopsa static analysis platform, compiled into
JavaScript to run purely as a client-side application in web browsers.
Try-Mopsa provides a responsive interface that works on both desktop and mobile
devices. Try-Mopsa features all the core components of Mopsa. In particular, it
supports relational numerical domains. We present the interface, changes and
adaptations required to have a pure JavaScript version of Mopsa. We envision
Try-Mopsa as a convenient platform for onboarding or teaching purposes.

</details>


### [23] [Rebound: Efficient, Expressive, and Well-Scoped Binding](https://arxiv.org/abs/2509.13261)
*Noé De Santo,Stephanie Weirich*

Main category: cs.PL

TL;DR: Rebound is a Haskell library that makes working with complex term bindings safer, easier, and faster by automating substitution and related operations, outperforming competing libraries in benchmarks.


<details>
  <summary>Details</summary>
Motivation: There is a need for safer and more automated handling of term representations and binding structures in Haskell, especially to reduce errors associated with de Bruijn indices and tedious manual implementations of substitution and alpha-equivalence.

Method: The Rebound library is introduced, utilizing first-class environments to statically track variable scopes. This approach automates substitution, alpha-equivalence, and related operations, and optimizes substitution applications. The library is demonstrated through the implementation of various language features and is benchmarked against other libraries.

Result: Rebound is expressive enough to implement sophisticated language features and abstract syntax operations, including a dependently-typed programming language type checker. Benchmarks show that Rebound outperforms competing libraries in terms of code speed.

Conclusion: Rebound successfully automates and optimizes handling of binding structures in Haskell, provides type safety for scope management, and delivers better performance than existing solutions while remaining expressive for implementing advanced language features.

Abstract: We introduce the Rebound library that supports well-scoped term
representations in Haskell and automates the definition of substitution,
alpha-equivalence, and other operations that work with binding structures. The
key idea of our design is the use of first-class environments that map
variables to expressions in some new scope. By statically tracking scopes,
users of this library gain confidence that they have correctly maintained the
subtle invariants that stem from using de Bruijn indices. Behind the scenes,
Rebound uses environments to optimize the application of substitutions, while
providing explicit access to these data structures when desired. We demonstrate
that this library is expressive by using it to implement a wide range of
language features with sophisticated uses of binding and several different
operations that use this abstract syntax. Our examples include pi-forall, a
tutorial implementation of a type checker for a dependently-typed programming
language. Finally, we benchmark Rebound to understand its performance
characteristics and find that it produces faster code than competing libraries.

</details>
