{"id": "2507.01272", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.01272", "abs": "https://arxiv.org/abs/2507.01272", "authors": ["Zixuan Zhu"], "title": "Advanced LPeg techniques: A dual case study approach", "comment": null, "summary": "This paper presents advanced optimization techniques for Lua Parsing\nExpression Grammars (LPeg) through two complementary case studies: a\nhigh-performance JSON parser and a sophisticated Glob-to-LPeg pattern\nconverter. We demonstrate how strategic grammar construction can dramatically\nimprove parsing performance without modifying the underlying LPeg library. For\nthe JSON parser, we implement substitution capture and table construction\noptimization to reduce memory allocation overhead and improve object\nprocessing. For the Glob converter, we introduce segment-boundary separation,\nimplement Cox's flattened search strategy, and develop optimized braced\ncondition handling to prevent exponential backtracking. Comprehensive\nbenchmarks demonstrate that our JSON parser achieves processing speeds up to\n125 MB/s on complex documents, consistently outperforming dkjson and showing\ncompetitive results against rxi_json across most test cases. Our Glob-to-LPeg\nconverter exhibits 14-92% better performance than Bun.Glob and runs 3-14 times\nfaster than Minimatch across diverse pattern matching scenarios. This research\nprovides practical optimization techniques for LPeg-based parsers, contributing\nvaluable strategies to the text processing ecosystem.", "AI": {"tldr": "Through careful grammar design and innovative optimization strategies, this paper demonstrates major performance improvements for LPeg-based parsers in Lua, achieving state-of-the-art results for both JSON parsing and glob pattern conversion, all without requiring any changes to the LPeg library.", "motivation": "LPeg (Lua Parsing Expression Grammars) is a widely used pattern-matching and parsing library, but its performance can be limited by the way grammars are constructed. There is a need for practical, effective optimization techniques to boost the speed and efficiency of LPeg-based parsers without altering the library itself.", "method": "The authors present two complementary case studies to develop and evaluate their optimization strategies. They design and optimize a high-performance JSON parser and a Glob-to-LPeg pattern converter. Optimization involves techniques like substitution capture, table construction optimization, segment-boundary separation, Cox's flattened search strategy, and optimized braced condition handling. They then comprehensively benchmark these tools against existing solutions.", "result": "The optimized JSON parser achieves speeds up to 125 MB/s, outperforming dkjson and showing competitive performance against rxi_json in most cases. The Glob-to-LPeg converter delivers 14\u201392% better performance than Bun.Glob and is 3\u201314 times faster than Minimatch across a variety of scenarios.", "conclusion": "Strategic grammar construction and optimization techniques can significantly improve the performance of LPeg-based parsers. The paper's proposed methods enable remarkable speed and efficiency gains without any need to change the LPeg library itself, offering substantial practical value to the text processing and Lua programming communities."}}
{"id": "2507.01664", "categories": ["cs.PL", "D.3.1; F.3.2"], "pdf": "https://arxiv.org/pdf/2507.01664", "abs": "https://arxiv.org/abs/2507.01664", "authors": ["Hector Gramaglia"], "title": "Globality and Regions", "comment": null, "summary": "We obtain a characterization of global variables by unifying abstraction with\nregion abstraction in a region-based language. More precisely, in a previous\nwork a language called global was presented, whose virtue is to provide a\nconceptually clear way of introducing imperative operations in a functional\nlanguage. Memory safety is provided by the concept of linear protection, which\nconnects the global system to a linear one. In this paper we show that the\nconcept of global variable provided by the global language arises from the\nTofte and Talping's region language through the unification of abstraction and\nregion abstraction.", "AI": {"tldr": "This paper shows that global variables in a region-based language can be understood as arising from the unification of abstraction and region abstraction, offering a clear theoretical basis for integrating imperative features into functional languages with strong memory safety.", "motivation": "The motivation is to precisely characterize global variables in a region-based language, and to clarify how imperative operations can be conceptually integrated into a functional language while ensuring memory safety.", "method": "The paper builds on prior work introducing a 'global' language and demonstrates, via theoretical analysis, that global variables as defined in the global language originate from the unification of abstraction and region abstraction in the Tofte and Talping's region language.", "result": "The main result is a demonstrated linkage: global variables in the global language stem from the merging of abstraction and region abstraction in the region-based language framework.", "conclusion": "The paper concludes that the unification of abstraction and region abstraction in a region-based language provides a clear and theoretically sound foundation for global variables and their memory safety guarantees, connecting imperative and functional paradigms."}}
{"id": "2507.01065", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.01065", "abs": "https://arxiv.org/abs/2507.01065", "authors": ["Christiaan Verwijs", "Evelien Acun-Roos", "Daniel Russo"], "title": "Is It Safe To Learn And Share? On Psychological Safety and Social Learning in (Agile) Communities of Practice", "comment": null, "summary": "As hybrid, distributed, and asynchronous work models become more prevalent,\ncontinuous learning in Agile Software Development (ASD) gains renewed\nimportance. Communities of Practice (CoPs) are increasingly adopted to support\nsocial learning beyond formal education, often relying on virtual\ncommunication. Psychological safety, a prerequisite for effective learning,\nremains insufficiently understood in these settings. This mixed-methods study\ninvestigates psychological safety within Agile CoPs through survey data from\n143 participants. Results indicate that psychological safety is significantly\nlower in online interactions compared to face-to-face settings. Moreover, low\npsychological safety reduces participants' intent to continue contributing and\navoidance of interpersonal risk. No significant differences emerged based on\ngender, community seniority, or content creation activity. However, differences\nby role and age group suggest potential generational or role-related effects.\nThematic analysis revealed exclusionary behavior, negative interaction\npatterns, and hostility as primary threats to psychological safety, often\nreinforced by tribalism and specific community dynamics. Suggested\ninterventions include establishing explicit norms, structured facilitation, and\nactive moderation. The findings were validated through member checking with 30\nparticipants. This study provides a comparative perspective on interaction\nmodalities and offers practical guidance for organizers seeking to cultivate\ninclusive, high-impact CoPs and similarly structured virtual or hybrid work\nenvironments.", "AI": {"tldr": "Online Agile Communities of Practice have lower psychological safety than face-to-face ones, which negatively impacts participation. Exclusionary and hostile behaviors are major threats. Differences arise by role and age, but not gender or seniority. Explicit norms and active moderation are needed for safer, more inclusive environments.", "motivation": "As remote, distributed, and hybrid work environments become increasingly common in Agile Software Development (ASD), continuous and effective learning through Communities of Practice (CoPs) is more important than ever. However, psychological safety\u2014a key enabler for effective learning\u2014remains poorly understood in these virtual or hybrid CoP settings.", "method": "The study uses a mixed-methods approach, employing surveys with 143 participants engaged in Agile CoPs. Quantitative results are complemented by a thematic analysis of participant experiences. The findings were validated through member checking with 30 participants.", "result": "Psychological safety is found to be significantly lower in online interactions than in face-to-face settings. Lower psychological safety diminishes the willingness to continue contributing and increases risk-aversion. No significant effect is found for gender, seniority, or content activity, but role and age group differences are observed. Key threats to psychological safety include exclusionary behavior, negative interactions, and hostility, often amplified by tribalism and specific community dynamics.", "conclusion": "Interaction modality (online versus face-to-face) has a strong impact on psychological safety in Agile CoPs\u2014lower in online settings. Mitigation strategies include explicit norms, structured facilitation, and active moderation. The study offers actionable guidance for fostering psychological safety and inclusivity in virtual and hybrid CoPs."}}
{"id": "2507.01103", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.01103", "abs": "https://arxiv.org/abs/2507.01103", "authors": ["Jonhnanthan Oliveira", "Rohit Gheyi", "M\u00e1rcio Ribeiro", "Alessandro Garcia"], "title": "Bugs in the Shadows: Static Detection of Faulty Python Refactorings", "comment": "Accepted at Brazilian Symposium on Software Engineering (SBES 2025)", "summary": "Python is a widely adopted programming language, valued for its simplicity\nand flexibility. However, its dynamic type system poses significant challenges\nfor automated refactoring - an essential practice in software evolution aimed\nat improving internal code structure without changing external behavior.\nUnderstanding how type errors are introduced during refactoring is crucial, as\nsuch errors can compromise software reliability and reduce developer\nproductivity. In this work, we propose a static analysis technique to detect\ntype errors introduced by refactoring implementations for Python. We evaluated\nour technique on Rope refactoring implementations, applying them to open-source\nPython projects. Our analysis uncovered 29 bugs across four refactoring types\nfrom a total of 1,152 refactoring attempts. Several of these issues were also\nfound in widely used IDEs such as PyCharm and PyDev. All reported bugs were\nsubmitted to the respective developers, and some of them were acknowledged and\naccepted. These results highlight the need to improve the robustness of current\nPython refactoring tools to ensure the correctness of automated code\ntransformations and support reliable software maintenance.", "AI": {"tldr": "A new static analysis detects type errors from automated Python refactoring. In evaluating refactoring tools, the method found 29 bugs, some present in major IDEs. This highlights the need to strengthen Python refactoring tools for safer automated code changes.", "motivation": "Python's dynamic type system makes it difficult to perform automated refactoring safely, as it can easily introduce type errors. Since reliable and efficient refactoring is important for software evolution and developer productivity, understanding and mitigating type errors introduced during refactoring is essential.", "method": "The authors propose a static analysis technique specifically designed to detect type errors that are introduced by refactoring implementations in Python. They evaluate this technique by applying Rope's refactoring tools to a set of open-source Python projects and analyze the results.", "result": "The analysis discovered 29 bugs arising from four different types of refactorings out of 1,152 attempts. Some of these bugs were also found in popular IDEs like PyCharm and PyDev. Reported bugs were submitted to the respective tool developers, and several were acknowledged and accepted.", "conclusion": "Current Python refactoring tools are not robust enough and can introduce type errors that compromise software reliability. There is a clear need to enhance these tools to ensure correct automated code transformations for reliable software maintenance."}}
{"id": "2507.01315", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.01315", "abs": "https://arxiv.org/abs/2507.01315", "authors": ["Taiming Wang", "Yanjie Jiang", "Chunhao Dong", "Yuxia Zhang", "Hui Liu"], "title": "Context-Aware Code Wiring Recommendation with LLM-based Agent", "comment": null, "summary": "Copy-paste-modify is a widespread and pragmatic practice in software\ndevelopment, where developers adapt reused code snippets, sourced from\nplatforms such as Stack Overflow, GitHub, or LLM outputs, into their local\ncodebase. A critical yet underexplored aspect of this adaptation is code\nwiring, which involves substituting unresolved variables in the pasted code\nwith suitable ones from the surrounding context. Existing solutions either rely\non heuristic rules or historical templates, often failing to effectively\nutilize contextual information, despite studies showing that over half of\nadaptation cases are context-dependent. In this paper, we introduce WIRL, an\nLLM-based agent for code wiring framed as a Retrieval-Augmented Generation\n(RAG) infilling task. WIRL combines an LLM, a customized toolkit, and an\norchestration module to identify unresolved variables, retrieve context, and\nperform context-aware substitutions. To balance efficiency and autonomy, the\nagent adopts a mixed strategy: deterministic rule-based steps for common\npatterns, and a state-machine-guided decision process for intelligent\nexploration. We evaluate WIRL on a carefully curated, high-quality dataset\nconsisting of real-world code adaptation scenarios. Our approach achieves an\nexact match precision of 91.7% and a recall of 90.0%, outperforming advanced\nLLMs by 22.6 and 13.7 percentage points in precision and recall, respectively,\nand surpassing IntelliJ IDEA by 54.3 and 49.9 percentage points. These results\nunderscore its practical utility, particularly in contexts with complex\nvariable dependencies or multiple unresolved variables. We believe WIRL paves\nthe way for more intelligent and context-aware developer assistance in modern\nIDEs.", "AI": {"tldr": "WIRL is an LLM-based tool that automates context-aware variable mapping when developers copy-paste code. It outperforms existing LLMs and IDEs like IntelliJ in accuracy and recall, showing promise for smarter, more helpful code adaptation features in developer tools.", "motivation": "Copy-paste-modify is a common practice among developers for incorporating external code snippets. However, a key challenge in this adaptation is 'code wiring,' which involves resolving and mapping variables from the pasted snippet to the developer's code context. Existing methods often do not leverage sufficient contextual information, leading to inaccurate or inefficient code adaptation. The motivation is to address this underexplored yet critical aspect efficiently.", "method": "The authors propose WIRL, an agent based on large language models (LLMs), which frames code wiring as a Retrieval-Augmented Generation (RAG) infilling task. WIRL uses a combination of LLMs, a custom toolkit, and an orchestration module to automatically identify unresolved variables, retrieve relevant code context, and perform precise substitutions. The system mixes deterministic rule-based actions with a state-machine-guided, LLM-driven decision process to balance speed and adaptability.", "result": "WIRL was evaluated on a curated dataset of real-world code adaptation cases. It achieved an exact match precision of 91.7% and recall of 90.0%. Compared to advanced LLMs, WIRL showed improvements of 22.6 and 13.7 percentage points in precision and recall, respectively. Against IntelliJ IDEA, it outperformed by 54.3 and 49.9 percentage points.", "conclusion": "WIRL significantly enhances the context-awareness and accuracy of code adaptation during copy-paste-modify workflows. Its hybrid approach makes it more effective than existing LLMs and IDE solutions, particularly when dealing with complex coding contexts and unresolved variables. WIRL sets a new direction for automated, intelligent developer assistance in modern IDEs."}}
{"id": "2507.01477", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.01477", "abs": "https://arxiv.org/abs/2507.01477", "authors": ["Lukas Krodinger", "Stephan Lukasczyk", "Gordon Fraser"], "title": "Combining Type Inference and Automated Unit Test Generation for Python", "comment": null, "summary": "Automated unit test generation is an established research field that has so\nfar focused on statically-typed programming languages. The lack of type\ninformation in dynamically-typed programming languages, such as Python,\ninhibits test generators, which heavily rely on information about parameter and\nreturn types of functions to select suitable arguments when constructing test\ncases. Since automated test generators inherently rely on frequent execution of\ncandidate tests, we make use of these frequent executions to address this\nproblem by introducing type tracing, which extracts type-related information\nduring execution and gradually refines the available type information. We\nimplement type tracing as an extension of the Pynguin test-generation framework\nfor Python, allowing it (i) to infer parameter types by observing how\nparameters are used during runtime, (ii) to record the types of values that\nfunction calls return, and (iii) to use this type information to increase code\ncoverage. The approach leads to up to 90.0% more branch coverage, improved\nmutation scores, and to type information of similar quality to that produced by\nother state-of-the-art type-inference tools.", "AI": {"tldr": "This paper proposes type tracing for Python unit test generation, dynamically inferring types during test execution, resulting in greatly improved code coverage and test effectiveness.", "motivation": "Automated test generation for dynamically-typed languages like Python is challenging due to missing type information, hindering effective test input selection.", "method": "Introduce 'type tracing,' which gathers and refines type information during repeated test executions within the Pynguin framework. Type tracing infers parameter types, records return types, and leverages this knowledge to guide test generation.", "result": "The proposed method achieves up to 90.0% more branch coverage and better mutation scores. It also infers types with quality similar to state-of-the-art type-inference tools.", "conclusion": "Type tracing significantly enhances automated unit test generation for Python by inferring and refining type information at runtime, leading to substantial coverage and quality improvements."}}
{"id": "2507.01628", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.01628", "abs": "https://arxiv.org/abs/2507.01628", "authors": ["Zilong He", "Pengfei Chen", "Hongyu Zhang", "Xiaoyun Li", "Guangba Yu", "Hongyang Chen", "Zibin Zheng"], "title": "DaiFu: In-Situ Crash Recovery for Deep Learning Systems", "comment": null, "summary": "Deep learning (DL) systems have been widely adopted in many areas, and are\nbecoming even more popular with the emergence of large language models.\nHowever, due to the complex software stacks involved in their development and\nexecution, crashes are unavoidable and common. Crashes severely waste computing\nresources and hinder development productivity, so efficient crash recovery is\ncrucial. Existing solutions, such as checkpoint-retry, are too heavyweight for\nfast recovery from crashes caused by minor programming errors or transient\nruntime errors. Therefore, we present DaiFu, an in-situ recovery framework for\nDL systems. Through a lightweight code transformation to a given DL system,\nDaiFu augments it to intercept crashes in situ and enables dynamic and instant\nupdates to its program running context (e.g., code, configurations, and other\ndata) for agile crash recovery. Our evaluation shows that DaiFu helps reduce\nthe restore time for crash recovery, achieving a 1372x speedup compared with\nstate-of-the-art solutions. Meanwhile, the overhead of DaiFu is negligible\n(under 0.40%). We also construct a benchmark spanning 7 distinct crash\nscenarios in DL systems, and show the effectiveness of DaiFu in diverse\nsituations.", "AI": {"tldr": "DaiFu is a new, lightweight recovery framework for deep learning systems, enabling fast in-situ crash recovery with minimal overhead. It is up to 1372x faster than existing methods and works well across various crash types.", "motivation": "Deep learning systems are widely used but frequently suffer from crashes due to complex software stacks, leading to significant resource waste and decreased developer productivity. Existing crash recovery solutions like checkpoint-retry are too slow and heavyweight for common programming or runtime errors, highlighting the need for faster, more efficient recovery methods.", "method": "The authors introduce DaiFu, an in-situ recovery framework for DL systems. DaiFu uses lightweight code transformation to enable the DL system to catch crashes on the spot and supports dynamic, immediate updates to the running context (such as code, configurations, and data) to facilitate agile crash recovery.", "result": "DaiFu significantly speeds up the recovery process after a crash: evaluation shows a 1372x improvement in restore time versus state-of-the-art solutions, while adding negligible performance overhead (less than 0.40%). Its effectiveness is demonstrated through a benchmark covering 7 different crash scenarios.", "conclusion": "DaiFu offers a practical, lightweight, and highly effective solution for crash recovery in deep learning systems, greatly reducing downtime and minimizing performance impact. Its framework is proven effective across diverse crash cases."}}
{"id": "2507.01827", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.01827", "abs": "https://arxiv.org/abs/2507.01827", "authors": ["Haichuan Hu", "Congqing He", "Hao Zhang", "Xiaochen Xie", "Quanjun Zhang"], "title": "APRMCTS: Improving LLM-based Automated Program Repair with Iterative Tree Search", "comment": null, "summary": "Automated Program Repair (APR) attempts to fix software bugs without human\nintervention, which plays a crucial role in software development and\nmaintenance. Recently, with the advances in Large Language Models (LLMs), a\nrapidly increasing number of APR techniques have been proposed with remarkable\nperformance. However, existing LLM-based APR techniques typically adopt\ntrial-and-error strategies, which suffer from two major drawbacks: (1)\ninherently limited patch effectiveness due to local exploration, and (2) low\nsearch efficiency due to redundant exploration. In this paper, we propose\nAPRMCTS, which uses iterative tree search to improve LLM-based APR. APRMCTS\nincorporates Monte Carlo Tree Search (MCTS) into patch searching by performing\na global evaluation of the explored patches and selecting the most promising\none for subsequent refinement and generation. APRMCTS effectively resolves the\nproblems of falling into local optima and thus helps improve the efficiency of\npatch searching. Our experiments on 835 bugs from Defects4J demonstrate that,\nwhen integrated with GPT-3.5, APRMCTS can fix a total of 201 bugs, which\noutperforms all state-of-the-art baselines. Besides, APRMCTS helps GPT-4o-mini,\nGPT-3.5, Yi-Coder-9B, and Qwen2.5-Coder-7B to fix 30, 27, 37, and 28 more bugs,\nrespectively. More importantly, APRMCTS boasts a significant performance\nadvantage while employing small patch size (16 and 32), notably fewer than the\n500 and 10,000 patches adopted in previous studies. In terms of cost, compared\nto existing state-of-the-art LLM-based APR methods, APRMCTS has time and\nmonetary costs of less than 20% and 50%, respectively. Our extensive study\ndemonstrates that APRMCTS exhibits good effectiveness and efficiency, with\nparticular advantages in addressing complex bugs.", "AI": {"tldr": "This paper presents APRMCTS, which combines LLMs and Monte Carlo Tree Search to significantly improve automated program repair. It outperforms state-of-the-art methods on standard benchmarks, fixes more bugs with less computation and cost, and particularly shines on complex bug fixes.", "motivation": "Automated Program Repair (APR) is essential for software maintenance, but recent LLM-based APR techniques face issues like local optima (limited patch effectiveness) and inefficiency (redundant exploration). There is a need for a more effective and efficient patch search approach.", "method": "This paper introduces APRMCTS, a novel APR method that combines Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS). APRMCTS performs an iterative global evaluation of candidate patches and refines the most promising ones using MCTS, rather than relying on trial-and-error.", "result": "Experiments on 835 bugs from the Defects4J benchmark show that APRMCTS, when used with GPT-3.5, fixes 201 bugs, beating all existing baselines. It also improves bug-fixing numbers for several prominent LLMs by 27-37 bugs each and is effective even with much smaller patch sizes (16 and 32 versus 500-10,000 in prior work) while cutting time and cost significantly (to less than 20% and 50% of previous methods, respectively).", "conclusion": "APRMCCTS achieves state-of-the-art APR performance with increased effectiveness and efficiency. Its global-search approach overcomes local optima and redundant searches, making it especially strong for fixing complex bugs, with substantially lower computational and monetary costs than previous LLM-based APR techniques."}}
