<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 18]
- [cs.PL](#cs.PL) [Total: 1]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [How Software Engineers Engage with AI: A Pragmatic Process Model and Decision Framework Grounded in Industry Observations](https://arxiv.org/abs/2507.17930)
*Vahid Garousi,Zafar Jafarov*

Main category: cs.SE

TL;DR: This paper explores how software engineers use AI tools like Copilot and ChatGPT in real-world settings, introducing a practical process model and a decision framework to help developers balance effort and quality when using AI-generated solutions.


<details>
  <summary>Details</summary>
Motivation: The motivation of this paper is to understand how software engineers practically engage with AI tools like GitHub Copilot and ChatGPT, particularly regarding how they trust, refine, or reject AI-generated outputs during their daily software engineering tasks. This area has been underexplored despite the growing impact of AI on software development workflows.

Method: The authors use a combination of practitioner reports and direct observations in three industry settings across Turkiye and Azerbaijan to gather real-world data on AI-assisted software engineering practices.

Result: The results include a pragmatic process model that maps out typical AI-assisted software engineering activities, such as prompt design, inspection, fallback, and refinement. Additionally, the authors propose a 2D decision framework to help developers weigh the trade-offs between the effort saved by using AI tools and the quality of the resultant outputs.

Conclusion: The paper concludes that their process model and decision framework provide structured and lightweight guidance, supporting more thoughtful and effective use of AI tools in software engineering. These contributions further the discussion on integrating human oversight with AI assistance in practice.

Abstract: Artificial Intelligence (AI) has the potential to transform Software
Engineering (SE) by enhancing productivity, efficiency, and decision support.
Tools like GitHub Copilot and ChatGPT have given rise to "vibe coding"-an
exploratory, prompt-driven development style. Yet, how software engineers
engage with these tools in daily tasks, especially in deciding whether to
trust, refine, or reject AI-generated outputs, remains underexplored. This
paper presents two complementary contributions. First, a pragmatic process
model capturing real-world AI-assisted SE activities, including prompt design,
inspection, fallback, and refinement. Second, a 2D decision framework that
could help developers reason about trade-offs between effort saved and output
quality. Grounded in practitioner reports and direct observations in three
industry settings across Turkiye and Azerbaijan, our work illustrates how
engineers navigate AI use with human oversight. These models offer structured,
lightweight guidance to support more deliberate and effective use of AI tools
in SE, contributing to ongoing discussions on practical human-AI collaboration.

</details>


### [2] [Use as Directed? A Comparison of Software Tools Intended to Check Rigor and Transparency of Published Work](https://arxiv.org/abs/2507.17991)
*Peter Eckmann,Adrian Barnett,Alexandra Bannach-Brown,Elisa Pilar Bascunan Atria,Guillaume Cabanac,Louise Delwen Owen Franzen,Małgorzata Anna Gazda,Kaitlyn Hair,James Howison,Halil Kilicoglu,Cyril Labbe,Sarah McCann,Vladislav Nachev,Martijn Roelandse,Maia Salholz-Hillel,Robert Schulz,Gerben ter Riet,Colby Vorland,Anita Bandrowski,Tracey Weissgerber*

Main category: cs.SE

TL;DR: Automated tools can help check scientific rigor and transparency, but no single tool is best for all criteria. Combining tools can improve performance. The paper offers practical recommendations for improving these tools and shares its code and data for reproducibility.


<details>
  <summary>Details</summary>
Motivation: There is a reproducibility crisis in science, partly caused by lack of standardization and transparency in reporting. Existing checklists to improve reporting are not reliably used or enforced, so automated tools have been developed to check rigor criteria.

Method: The authors conducted a broad comparison of 11 different automated tools across 9 rigor criteria (from the ScreenIT group) to assess their effectiveness in detecting adherence to transparency and standardization guidelines.

Result: Some rigor criteria (e.g., detecting open data) had a clear best-performing tool, while for others (e.g., detection of inclusion/exclusion criteria) combining tools gave better results than any single tool. The study also identified areas for improvement for developers of such tools.

Conclusion: No single tool is sufficient to guarantee rigor and transparency in scientific reporting; combining tools is more effective for some criteria. Recommendations are provided for stakeholders and developers to improve automated detection tools. The study’s resources are publicly available.

Abstract: The causes of the reproducibility crisis include lack of standardization and
transparency in scientific reporting. Checklists such as ARRIVE and CONSORT
seek to improve transparency, but they are not always followed by authors and
peer review often fails to identify missing items. To address these issues,
there are several automated tools that have been designed to check different
rigor criteria. We have conducted a broad comparison of 11 automated tools
across 9 different rigor criteria from the ScreenIT group. We found some
criteria, including detecting open data, where the combination of tools showed
a clear winner, a tool which performed much better than other tools. In other
cases, including detection of inclusion and exclusion criteria, the combination
of tools exceeded the performance of any one tool. We also identified key areas
where tool developers should focus their effort to make their tool maximally
useful. We conclude with a set of insights and recommendations for stakeholders
in the development of rigor and transparency detection tools. The code and data
for the study is available at https://github.com/PeterEckmann1/tool-comparison.

</details>


### [3] [An Empirical Study of GenAI Adoption in Open-Source Game Development: Tools, Tasks, and Developer Challenges](https://arxiv.org/abs/2507.18029)
*Xiang Echo Chen,Wenhan Zhu,Guoshuai Albert Shi,Michael W. Godfrey*

Main category: cs.SE

TL;DR: This paper investigates how open-source game developers discuss and integrate generative AI by analyzing GitHub issues, revealing unique patterns, challenges, and adoption trends for GenAI compared to traditional AI and other topics.


<details>
  <summary>Details</summary>
Motivation: While generative AI (GenAI) has begun transforming game design and development, there is little empirical knowledge about how open-source developers actually use, discuss, and integrate GenAI compared to traditional AI in real-world projects. This paper seeks to fill that gap.

Method: The authors analyze GitHub issue discussions related to AI in open-source game development. They construct a dataset of game repositories, then use open card sorting and thematic analysis to label and compare issues related to GenAI, traditional AI (TradAI), and topics not involving AI (NonAI).

Result: The study characterizes the tools, tasks, and challenges unique to GenAI adoption and how they differ from TradAI and NonAI topics. It provides comparative insight into usage patterns, developer concerns, and GenAI integration practices in the open-source game community.

Conclusion: GenAI is influencing the workflows and challenges faced by open-source game developers in distinctive ways. The findings highlight differences in the adoption and discussion of GenAI versus other AI and non-AI technologies, shedding light on its growing impact in collaborative software development.

Abstract: The growing capabilities of generative AI (GenAI) have begun to reshape how
games are designed and developed, offering new tools for content creation,
gameplay simulation, and design ideation. While prior research has explored
traditional uses of AI in games, such as controlling agents or generating
procedural content. There is limited empirical understanding of how GenAI is
adopted by developers in real-world contexts, especially within the open-source
community. This study aims to explore how GenAI technologies are discussed,
adopted, and integrated into open-source game development by analyzing issue
discussions on GitHub. We investigate the tools, tasks, and challenges
associated with GenAI by comparing GenAI-related issues to those involving
traditional AI (TradAI) and NonAI topics. Our goal is to uncover how GenAI
differs from other approaches in terms of usage patterns, developer concerns,
and integration practices. To address this objective, we construct a dataset of
open-source game repositories that discuss AI-related topics. We apply open
card sorting and thematic analysis to a stratified sample of GitHub issues,
labelling each by type and content. These annotations enable comparative
analysis across GenAI, TradAI, and NonAI groups, and provide insight into how
GenAI is shaping the workflows and pain points of open-source game developers.

</details>


### [4] [Your ATs to Ts: MITRE ATT&CK Attack Technique to P-SSCRM Task Mapping](https://arxiv.org/abs/2507.18037)
*Sivana Hamer,Jacob Bowen,Md Nazmul Haque,Chris Madden,Laurie Williams*

Main category: cs.SE

TL;DR: This paper creates a mapping between P-SSCRM tasks and MITRE ATT&CK techniques (and other frameworks), enabling better, proactive management of software supply chain risks.


<details>
  <summary>Details</summary>
Motivation: Software supply chain attacks are a serious and increasing threat. Organizations require comprehensive frameworks to proactively manage these risks. However, there is a need for clear guidance on how specific tasks align with recognized attack models and other frameworks.

Method: The paper uses four independent strategies to create a mapping between MITRE ATT&CK attack techniques and P-SSCRM tasks. Each P-SSCRM task was also cross-referenced with tasks from 10 other prominent government and industry frameworks.

Result: The outcome is a detailed mapping showing how specific P-SSCRM tasks mitigate MITRE ATT&CK software supply chain attack techniques. It also provides indirect mappings to other important frameworks, helping organizations understand overlaps and coverage.

Conclusion: The mapping enables software organizations to better understand and select risk mitigation activities relevant to software supply chain attacks. It additionally bridges MITRE ATT&CK with other frameworks, improving harmonization and comprehensive defense strategies.

Abstract: The MITRE Adversarial Tactics, Techniques and Common Knowledge (MITRE ATT&CK)
Attack Technique to Proactive Software Supply Chain Risk Management Framework
(P-SSCRM) Task mapping described in this document helps software organizations
to determine how different tasks mitigate the attack techniques of software
supply chain attacks. The mapping was created through four independent
strategies to find agreed-upon mappings. Because each P-SSCRM task is mapped to
one or more tasks from the 10 frameworks, the mapping we provide is also a
mapping between MITRE ATT&CK and other prominent government and industry
frameworks.

</details>


### [5] [Factors Impacting Faculty Adoption of Project-Based Learning in Computing Education: a Survey](https://arxiv.org/abs/2507.18039)
*Ahmad D. Suleiman,Yiming Tang,Daqing Hou*

Main category: cs.SE

TL;DR: Despite its recognized benefits, project-based learning is not widely or consistently adopted by computing educators due to institutional barriers and resource constraints. Support such as collaboration, professional development, and incentives increases adoption. Systemic support structures are needed to enable broader and sustained use of PjBL.


<details>
  <summary>Details</summary>
Motivation: Project-based learning (PjBL) is recognized for its benefits in enhancing student motivation, engagement, and critical skills in computing education, yet its adoption by faculty is inconsistent. The motivation of the paper is to systematically identify and understand the barriers and enablers to the adoption of PjBL among computing educators.

Method: The study used a mixed-methods approach, collecting data from 80 computing faculty through an online survey with closed-ended questions to quantify barriers, enablers, and resource needs, and an open-ended question for qualitative insights. Quantitative data were analyzed statistically, and qualitative data underwent thematic analysis.

Result: The results show that PjBL is valued but selectively adopted due to challenges like limited institutional support, time constraints, difficulties in project design, and securing resources. Successful adoption is associated with access to peer collaboration, professional development, and institutional incentives. Borrowing project ideas from research, industry, and colleagues also facilitates adoption.

Conclusion: There are significant obstacles to widespread adoption of PjBL in computing education, mainly due to insufficient institutional resources and support. Systemic support structures are needed to help faculty experiment with and scale PjBL effectively.

Abstract: This research full paper investigates the factors influencing computing
educators' adoption of project-based learning (PjBL) in software engineering
and computing curricula. Recognized as a student-centered pedagogical approach,
PjBL has the potential to enhance student motivation, engagement, critical
thinking, collaboration, and problem-solving skills. Despite these benefits,
faculty adoption remains inconsistent due to challenges such as insufficient
institutional support, time constraints, limited training opportunities,
designing or sourcing projects, and aligning them with course objectives. This
research explores these barriers and investigates the strategies and resources
that facilitate a successful adoption. Using a mixed-methods approach, data
from 80 computing faculty were collected through an online survey comprising
closed-ended questions to quantify barriers, enablers, and resource needs,
along with an open-ended question to gather qualitative insights. Quantitative
data were analyzed using statistical methods, while qualitative responses
underwent thematic analysis. Results reveal that while PjBL is widely valued,
its adoption is often selective and impacted by challenges in planning and
managing the learning process, designing suitable projects, and a lack of
institutional support, such as time, funding, and teaching assistants. Faculty
are more likely to adopt or sustain PjBL when they have access to peer
collaboration, professional development, and institutional incentives. In
addition, sourcing projects from research, industry partnerships, and borrowing
from peers emerged as key facilitators for new projects. These findings
underscore the need for systemic support structures to empower faculty to
experiment with and scale PjBL practices.

</details>


### [6] [An Empirical Study of Complexity, Heterogeneity, and Compliance of GitHub Actions Workflows](https://arxiv.org/abs/2507.18062)
*Edward Abrokwah,Taher A. Ghaleb*

Main category: cs.SE

TL;DR: This paper analyzes a large set of GitHub Actions CI workflows in open-source Java, Python, and C++ repositories, uncovering common complexities, structure patterns, and alignment with best practices. Results indicate where workflows meet or miss established practices and propose clearer guidance and documentation to enhance future CI use.


<details>
  <summary>Details</summary>
Motivation: While GitHub Actions (GHA) is a widely used CI service with documented best practices, there is limited empirical understanding of how real-world, open-source GHA CI workflows actually follow these practices. There is concern that many such workflows are unnecessarily complex and do not adhere to the intended simplicity of CI.

Method: The study utilizes a large dataset of GHA workflows drawn from open-source Java, Python, and C++ repositories. It analyzes the structure, complexity, heterogeneity, and compliance of these workflows through empirical investigation. The research aims to identify complex patterns, recurring structures, and variations by programming language, as well as to assess alignment with documented best practices.

Result: The study expects to find areas where open-source GHA workflows strongly adhere to best practices, as well as areas showing unnecessary complexity or poor alignment. Differences in workflow design across programming languages are also anticipated to be revealed.

Conclusion: The analysis will provide insights for both researchers and CI tool developers, pointing out where CI documentation and guidelines can be improved to foster better adherence to best practices. The findings advocate for clearer guidelines, better documentation, and more comprehensive examples to assist CI users.

Abstract: Continuous Integration (CI) has evolved from a tooling strategy to a
fundamental mindset in modern CI engineering. It enables teams to develop,
test, and deliver software rapidly and collaboratively. Among CI services,
GitHub Actions (GHA) has emerged as a dominant service due to its deep
integration with GitHub and a vast ecosystem of reusable workflow actions.
Although GHA provides official documentation and community-supported best
practices, there appears to be limited empirical understanding of how
open-source real-world CI workflows align with such practices. Many workflows
might be unnecessarily complex and not aligned with the simplicity goals of CI
practices. This study will investigate the structure, complexity,
heterogeneity, and compliance of GHA workflows in open-source software
repositories. Using a large dataset of GHA workflows from Java, Python, and C++
repositories, our goal is to (a) identify workflow complexities, (b) analyze
recurring and heterogeneous structuring patterns, (c) assess compliance with
GHA best practices, and (d) uncover differences in CI pipeline design across
programming languages. Our findings are expected to reveal both areas of strong
adherence to best practices and areas for improvement where needed. These
insights will also have implications for CI services, as they will highlight
the need for clearer guidelines and comprehensive examples in CI documentation.

</details>


### [7] [Identifier Name Similarities: An Exploratory Study](https://arxiv.org/abs/2507.18081)
*Carol Wong,Mai Abe,Silvia De Benedictis,Marissa Halim,Anthony Peruma*

Main category: cs.SE

TL;DR: This paper develops a preliminary taxonomy for types of identifier name similarity in code, with the aim of improving studies of program comprehension and developer collaboration.


<details>
  <summary>Details</summary>
Motivation: Poorly chosen identifier names in code increase cognitive load and hinder collaboration, even if the names seem readable in isolation. Similar-looking or similar-function names can cause misunderstandings.

Method: The authors conducted an exploratory study, developing a preliminary taxonomy to categorize types of identifier name similarity in software projects.

Result: They created an initial taxonomy that categorizes various forms of identifier name similarity.

Conclusion: The taxonomy is intended as a platform for further research, helping to analyze the impact of name similarity on code comprehension, maintainability, and collaboration, and is open to refinement and expansion.

Abstract: Identifier names, which comprise a significant portion of the codebase, are
the cornerstone of effective program comprehension. However, research has shown
that poorly chosen names can significantly increase cognitive load and hinder
collaboration. Even names that appear readable in isolation may lead to
misunderstandings in contexts when they closely resemble other names in either
structure or functionality. In this exploratory study, we present our
preliminary findings on the occurrence of identifier name similarity in
software projects through the development of a taxonomy that categorizes
different forms of identifier name similarity. We envision our initial taxonomy
providing researchers with a platform to analyze and evaluate the impact of
identifier name similarity on code comprehension, maintainability, and
collaboration among developers, while also allowing for further refinement and
expansion of the taxonomy.

</details>


### [8] [Understanding the Supply Chain and Risks of Large Language Model Applications](https://arxiv.org/abs/2507.18105)
*Yujie Ma,Lili Quan,Xiaofei Xie,Qiang Hu,Jiongchi Yu,Yao Zhang,Sen Chen*

Main category: cs.SE

TL;DR: The paper introduces the first benchmark dataset mapping LLM supply chains, revealing deeply nested dependencies and widespread vulnerabilities. Their analysis highlights the urgent need for holistic supply chain security measures to ensure the safety of LLM-based applications.


<details>
  <summary>Details</summary>
Motivation: Large Language Models (LLMs) are increasingly deployed in various domains, but their complex supply chains introduce significant security risks that are not well understood or systematically benchmarked.

Method: The authors compiled the first comprehensive dataset of LLM supply chain components, collecting data from 3,859 LLM applications. They conducted interdependency analysis, mapped ecosystem structures, and gathered risk-related issues from public vulnerability databases to empirically assess dependencies and vulnerabilities.

Result: They identified extensive and deeply nested dependencies among LLM applications, models, datasets, and libraries. Their analysis surfaced significant vulnerabilities throughout the LLM supply chain, with the majority found in third-party libraries.

Conclusion: Comprehensive security analysis of LLM supply chains is urgently needed, rather than focusing solely on models or datasets. The paper offers a foundational dataset and practical recommendations to improve security and trust in LLM-based systems.

Abstract: The rise of Large Language Models (LLMs) has led to the widespread deployment
of LLM-based systems across diverse domains. As these systems proliferate,
understanding the risks associated with their complex supply chains is
increasingly important. LLM-based systems are not standalone as they rely on
interconnected supply chains involving pretrained models, third-party
libraries, datasets, and infrastructure. Yet, most risk assessments narrowly
focus on model or data level, overlooking broader supply chain vulnerabilities.
While recent studies have begun to address LLM supply chain risks, there
remains a lack of benchmarks for systematic research.
  To address this gap, we introduce the first comprehensive dataset for
analyzing and benchmarking LLM supply chain security. We collect 3,859
real-world LLM applications and perform interdependency analysis, identifying
109,211 models, 2,474 datasets, and 9,862 libraries. We extract model
fine-tuning paths, dataset reuse, and library reliance, mapping the ecosystem's
structure. To evaluate security, we gather 1,555 risk-related issues-50 for
applications, 325 for models, 18 for datasets, and 1,229 for libraries from
public vulnerability databases.
  Using this dataset, we empirically analyze component dependencies and risks.
Our findings reveal deeply nested dependencies in LLM applications and
significant vulnerabilities across the supply chain, underscoring the need for
comprehensive security analysis. We conclude with practical recommendations to
guide researchers and developers toward safer, more trustworthy LLM-enabled
systems.

</details>


### [9] [NoCode-bench: A Benchmark for Evaluating Natural Language-Driven Feature Addition](https://arxiv.org/abs/2507.18130)
*Le Deng,Zhonghao Jiang,Jialun Cao,Michael Pradel,Zhongxin Liu*

Main category: cs.SE

TL;DR: The paper introduces NoCode-bench, a benchmark for evaluating LLMs on natural language-driven software development tasks. Results show that even the best LLMs succeed in only 15.79% of tasks, indicating that fully NL-driven no-code development is not yet feasible with current models.


<details>
  <summary>Details</summary>
Motivation: Natural language-driven no-code development aims to enable users to develop software using natural language instead of code, thus improving productivity and accessibility. The paper investigates whether large language models (LLMs) can achieve this, identifying the need to assess current LLM capabilities on realistic NL-driven software development tasks.

Method: The authors introduce NoCode-bench, a benchmark comprising 634 real-world feature addition tasks from 10 projects, where each task links software documentation changes (NL specifications) with code implementations validated by test cases. A high-quality, human-verified subset (NoCode-bench Verified) further supports reliable model evaluation. They use NoCode-bench to systematically test LLMs on these tasks and report their performance.

Result: Top-performing LLMs achieve a task success rate of only 15.79%, revealing major limitations in their ability to perform feature addition via NL instructions. Notable challenges include understanding entire codebases, making edits across files, and invoking tools as needed.

Conclusion: Current LLMs face significant obstacles in fully enabling NL-driven no-code software development, demonstrated by their low success rates on realistic tasks. NoCode-bench provides a foundation for measuring progress and identifying bottlenecks in this domain.

Abstract: Natural language-driven no-code development allows users to specify software
functionality using natural language (NL) instead of editing source code,
promising increased productivity and democratized development. Large language
models (LLMs) show potential in enabling this paradigm. In this context,
software documentation acts as an NL specification for functionality. This work
introduces NoCode-bench, a benchmark designed to evaluate LLMs on real-world
NL-driven feature addition tasks, consisting of 634 tasks across 10 projects
and 114k code changes. Each task pairs documentation updates with corresponding
code implementations, validated by developer-written test cases. A subset of
114 high-quality, human-verified instances, NoCode-bench Verified, ensures
reliable evaluation. Our experiments reveal that, despite high token usage, the
best LLMs achieve a task success rate of only 15.79%, highlighting challenges
in cross-file editing, codebase understanding, and tool calling. These findings
indicate that LLMs are not yet ready for fully NL-driven no-code development.
NoCode-bench lays the foundation for future advances in this area.

</details>


### [10] [SMECS: A Software Metadata Extraction and Curation Software](https://arxiv.org/abs/2507.18159)
*Stephan Ferenz,Aida Jafarbigloo,Oliver Werth,Astrid Nieße*

Main category: cs.SE

TL;DR: The SMECS tool streamlines and simplifies the process of generating and refining metadata for research software, making it easier to support FAIR principles by automating extraction and offering an intuitive curation interface.


<details>
  <summary>Details</summary>
Motivation: Creating high-quality metadata for research software is crucial for findability and reusability under the FAIR principles, but it is resource-intensive for researchers.

Method: The authors developed SMECS, a software tool that automatically extracts metadata from sources like GitHub and provides an interactive, user-friendly interface for researchers to curate and export this metadata as CodeMeta files.

Result: Usability experiments demonstrated that SMECS offers a satisfactory user experience for metadata creation and curation.

Conclusion: SMECS simplifies and supports the creation of high-quality metadata, aiding the FAIRification of research software by making metadata generation easier and more accessible.

Abstract: Metadata play a crucial role in adopting the FAIR principles for research
software and enables findability and reusability. However, creating
high-quality metadata can be resource-intensive for researchers and research
software engineers. To address this challenge, we developed the Software
Metadata Extraction and Curation Software (SMECS) which integrates the
extraction of metadata from existing sources together with a user-friendly
interface for metadata curation. SMECS extracts metadata from online
repositories such as GitHub and presents it to researchers through an
interactive interface for further curation and export as a CodeMeta file. The
usability of SMECS was evaluated through usability experiments which confirmed
that SMECS provides a satisfactory user experience. SMECS supports the
FAIRification of research software by simplifying metadata creation.

</details>


### [11] [GenAI for Automotive Software Development: From Requirements to Wheels](https://arxiv.org/abs/2507.18223)
*Nenad Petrovic,Fengjunjie Pan,Vahid Zolfaghari,Krzysztof Lebioda,Andre Schamschurko,Alois Knoll*

Main category: cs.SE

TL;DR: The paper presents a GenAI-driven method that automates requirements-to-code for automotive ADAS systems, combining LLMs, MDE, and RAG to produce both testing and implementation code efficiently, aiming for faster, more reliable development cycles.


<details>
  <summary>Details</summary>
Motivation: The paper is motivated by the need to streamline and automate the development of automotive software, especially for autonomous and Advanced Driver Assistance Systems (ADAS). Current processes are time-consuming, and achieving compliance and consistency with requirements is challenging.

Method: The proposed method uses GenAI, particularly Large Language Models (LLMs), to automate the transformation of requirements into code for both test scenarios and ADAS capability implementations. It incorporates Model-Driven Engineering (MDE) for requirements consistency checking, and employs Retrieval Augmented Generation (RAG) to enhance test scenario generation using regulatory documents.

Result: The approach can automatically generate simulation test scenarios, code for simulation (Python), and embedded target code (C++) for ADAS features. It also checks consistency in requirements and leverages external, regulation-based knowledge to improve test generation.

Conclusion: This GenAI-enabled workflow improves automotive software development by reducing compliance cycles, re-engineering effort, and overall development/testing time for ADAS functionalities.

Abstract: This paper introduces a GenAI-empowered approach to automated development of
automotive software, with emphasis on autonomous and Advanced Driver Assistance
Systems (ADAS) capabilities. The process starts with requirements as input,
while the main generated outputs are test scenario code for simulation
environment, together with implementation of desired ADAS capabilities
targeting hardware platform of the vehicle connected to testbench. Moreover, we
introduce additional steps for requirements consistency checking leveraging
Model-Driven Engineering (MDE). In the proposed workflow, Large Language Models
(LLMs) are used for model-based summarization of requirements (Ecore metamodel,
XMI model instance and OCL constraint creation), test scenario generation,
simulation code (Python) and target platform code generation (C++).
Additionally, Retrieval Augmented Generation (RAG) is adopted to enhance test
scenario generation from autonomous driving regulations-related documents. Our
approach aims shorter compliance and re-engineering cycles, as well as reduced
development and testing time when it comes to ADAS-related capabilities.

</details>


### [12] [An Empirical Study on Embodied Artificial Intelligence Robot (EAIR) Software Bugs](https://arxiv.org/abs/2507.18267)
*Zeqin Liao,Zibin Zheng,Peifan Reng,Henglong Liang,Zixu Gao,Zhixiang Chen,Wei Li,Yuhong Nan*

Main category: cs.SE

TL;DR: The paper systematically studies bugs in Embodied AI Robots, identifies unique bug symptoms and causes, and maps them to system modules to improve bug management and guide future research.


<details>
  <summary>Details</summary>
Motivation: Embodied Artificial Intelligence Robots (EAIR) are increasingly used, but understanding of their system bugs is lacking, impeding the development of effective techniques for their reliability.

Method: The authors performed a systematic study by collecting and analyzing 885 EAIR system bugs from 80 projects, classifying the bugs by symptoms, underlying causes, and affected modules.

Result: The study classified the bugs into 18 causes, 15 symptoms, and 13 modules. It identified 8 symptoms and 8 causes specific to EAIR systems, highlighting unique challenges such as functional failures and safety hazards. The research also created a mapping between bug causes and the modules most frequently affected.

Conclusion: This work provides the first comprehensive understanding of EAIR bugs, outlines specific areas for improvement in bug prediction, detection, and repair, and helps direct future research and diagnostic efforts more efficiently.

Abstract: Embodied Artificial Intelligence Robots (EAIR) is an emerging and rapidly
evolving technological domain. Ensuring their program correctness is
fundamental to their successful deployment. However, a general and in-depth
understanding of EAIR system bugs remains lacking, which hinders the
development of practices and techniques to tackle EAIR system bugs.
  To bridge this gap, we conducted the first systematic study of 885 EAIR
system bugs collected from 80 EAIR system projects to investigate their
symptoms, underlying causes, and module distribution. Our analysis takes
considerable effort, which classifies these bugs into 18 underlying causes, 15
distinct symptoms, and identifies 13 affected modules. It reveals several new
interesting findings and implications which help shed light on future research
on tackling or repairing EAIR system bugs. First, among the 15 identified
symptoms, our findings highlight 8 symptoms specific to EAIR systems, which is
characterized by severe functional failures and potential physical hazards.
Second, within the 18 underlying causes, we define 8 EAIR-specific causes, the
majority of which stem from the intricate issues of AI- agent reasoning and
decision making. Finally, to facilitate precise and efficient bug prediction,
detection, and repair, we constructed a mapping between underlying causes and
the modules in which they most frequently occur, which enables researchers to
focus diagnostic efforts on the modules most susceptible to specific bug types.

</details>


### [13] [Scheduzz: Constraint-based Fuzz Driver Generation with Dual Scheduling](https://arxiv.org/abs/2507.18289)
*Yan Li,Wenzhang Yang,Yuekun Wang,Jian Gao,Shaohua Wang,Yinxing Xue,Lijun Zhang*

Main category: cs.SE

TL;DR: Scheduzz is an LLM-based tool for automating library fuzzing. By understanding API usage, it generates smarter fuzz drivers and schedules tests efficiently, outperforming existing methods in coverage and bug detection while reducing wasted resources.


<details>
  <summary>Details</summary>
Motivation: Fuzzing libraries typically requires manual and expert-driven crafting of fuzz drivers, which is labor-intensive and error-prone. Automated approaches exist but struggle to respect proper API usage patterns, leading to wasted computation and false positives.

Method: Scheduzz, the proposed method, uses large language models (LLMs) to understand rational library usage and extract constraints on API combinations. It introduces a dual scheduling framework that treats driver generation and fuzzing campaigns as an online optimization problem, selectively generating and executing fuzz drivers for maximal efficiency.

Result: In tests on 33 real-world libraries, Scheduzz achieved significantly higher coverage than existing techniques—outperforming UTopia in most cases and showing substantial improvements (1.62x, 1.50x, 1.89x higher coverage) over CKGFuzzer, Promptfuzz, and OSS-Fuzz. It also identified 33 previously unknown bugs, 3 with assigned CVEs.

Conclusion: Scheduzz advances automated library fuzzing by using LLMs to generate more rational fuzz drivers and efficiently manages computation, resulting in greater coverage and the discovery of more bugs.

Abstract: Fuzzing a library requires experts to understand the library usage well and
craft high-quality fuzz drivers, which is tricky and tedious. Therefore, many
techniques have been proposed to automatically generate fuzz drivers. However,
they fail to generate rational fuzz drivers due to the lack of adherence to
proper library usage conventions, such as ensuring a resource is closed after
being opened. To make things worse, existing library fuzzing techniques
unconditionally execute each driver, resulting in numerous irrational drivers
that waste computational resources while contributing little coverage and
generating false positive bug reports.
  To tackle these challenges, we propose a novel automatic library fuzzing
technique, Scheduzz, an LLM-based library fuzzing technique. It leverages LLMs
to understand rational usage of libraries and extract API combination
constraints. To optimize computational resource utilization, a dual scheduling
framework is implemented to efficiently manage API combinations and fuzz
drivers. The framework models driver generation and the corresponding fuzzing
campaign as an online optimization problem. Within the scheduling loop,
multiple API combinations are selected to generate fuzz drivers, while
simultaneously, various optimized fuzz drivers are scheduled for execution or
suspension.
  We implemented Scheduzz and evaluated it in 33 real-world libraries. Compared
to baseline approaches, Scheduzz significantly reduces computational overhead
and outperforms UTopia on 16 out of 21 libraries. It achieves 1.62x, 1.50x, and
1.89x higher overall coverage than the state-of-the-art techniques CKGFuzzer,
Promptfuzz, and the handcrafted project OSS-Fuzz, respectively. In addition,
Scheduzz discovered 33 previously unknown bugs in these well-tested libraries,
3 of which have been assigned CVEs.

</details>


### [14] [YATE: The Role of Test Repair in LLM-Based Unit Test Generation](https://arxiv.org/abs/2507.18316)
*Michael Konstantinou,Renzo Degiovanni,Jie M. Zhang,Mark Harman,Mike Papadakis*

Main category: cs.SE

TL;DR: YATE fixes incorrect tests produced by language models, leading to much better test coverage and bug detection than existing LLM-based methods, without extra computational cost.


<details>
  <summary>Details</summary>
Motivation: Language models are increasingly used for automated test generation in software development, but they often generate many syntactically and semantically incorrect tests. These discarded, incorrect tests present a missed opportunity since fixing them could directly improve testing coverage and generate better test seeds.

Method: The authors propose YATE, a technique that repairs incorrect tests generated by language models using rule-based static analysis and targeted re-prompting. This approach aims to salvage valuable test logic from initially incorrect outputs.

Result: YATE was evaluated on 6 open-source projects, achieving an average of 32.06% more line coverage and 21.77% more mutants killed compared to plain language model-based methods. YATE also outperformed four other LLM-based test generation techniques (HITS, SYMPROMPT, TESTSPARK, COVERUP), showing 22% higher line coverage, 20% higher branch coverage, and 20% more mutants killed, with a similar number of LLM invocations.

Conclusion: Repairing incorrect LLM-generated tests using rule-based analysis and re-prompting can significantly boost the effectiveness of automated test generation, providing higher coverage and fault detection at a comparable computational cost.

Abstract: Recent advances in automated test generation utilises language models to
produce unit tests. While effective, language models tend to generate many
incorrect tests with respect to both syntax and semantics. Although such
incorrect tests can be easily detected and discarded, they constitute a "missed
opportunity" -- if fixed, they are often valuable as they directly add testing
value (they effectively target the underlying program logic to be tested) and
indirectly form good seeds for generating additional tests. To this end, we
propose a simple technique for repairing some of these incorrect tests through
a combination of rule-based static analysis and re-prompting. We evaluate this
simple approach, named YATE, on a set of 6 open-source projects and show that
it can effectively produce tests that cover on average 32.06% more lines and
kill 21.77% more mutants than a plain LLM-based method. We also compare YATE
with four other LLM-based methods, namely HITS, SYMPROMPT, TESTSPARK and
COVERUP and show that it produces tests that cover substantially more code.
YATE achieves 22% higher line coverage, 20% higher branch coverage and kill 20%
more mutants at a comparable cost (number of calls to LLMs).

</details>


### [15] [Gotta catch 'em all! Towards File Localisation from Issues at Large](https://arxiv.org/abs/2507.18319)
*Jesse Maarleveld,Jiapan Guo,Daniel Feitosa*

Main category: cs.SE

TL;DR: Bug-specific localisation methods don't work well for general issue localisation tasks. The authors propose a new dataset creation pipeline, show the importance of project-specific tuning, and call for research on general-purpose localisation models.


<details>
  <summary>Details</summary>
Motivation: Existing research mainly focuses on bug localisation or selectively targets only specific issue types. There is a need to address file localisation for all issue types in a comprehensive manner.

Method: The authors developed a data pipeline to create issue file localisation datasets that can handle arbitrary branching and merging. They evaluated baseline performance using traditional information retrieval techniques and conducted statistical analyses to study known biases from bug localisation in the context of broader issues.

Result: Methods tailored to bugs do not generalise well to other issue types, highlighting the need for general-purpose models. There are small but statistically significant performance differences across issue types, and the impact of identifiers is generally minor. Project-specific factors significantly affect results, suggesting the need for adaptable methods.

Conclusion: General-purpose localisers are needed instead of bug-specific approaches, and project adaptability is important due to varied project characteristics and issue types.

Abstract: Bug localisation, the study of developing methods to localise the files
requiring changes to resolve bugs, has been researched for a long time to
develop methods capable of saving developers' time. Recently, researchers are
starting to consider issues outside of bugs. Nevertheless, most existing
research into file localisation from issues focusses on bugs or uses other
selection methods to ensure only certain types of issues are considered as part
of the focus of the work. Our goal is to work on all issues at large, without
any specific selection.
  In this work, we provide a data pipeline for the creation of issue file
localisation datasets, capable of dealing with arbitrary branching and merging
practices. We provide a baseline performance evaluation for the file
localisation problem using traditional information retrieval approaches.
Finally, we use statistical analysis to investigate the influence of biases
known in the bug localisation community on our dataset.
  Our results show that methods designed using bug-specific heuristics perform
poorly on general issue types, indicating a need for research into general
purpose models. Furthermore, we find that there are small, but statistically
significant differences in performance between different issue types. Finally,
we find that the presence of identifiers have a small effect on performance for
most issue types. Many results are project-dependent, encouraging the
development of methods which can be tuned to project-specific characteristics.

</details>


### [16] [FMI Meets SystemC: A Framework for Cross-Tool Virtual Prototyping](https://arxiv.org/abs/2507.18339)
*Nils Bosbach,Meik Schmidt,Lukas Jünger,Matthias Berthold,Rainer Leupers*

Main category: cs.SE

TL;DR: The paper introduces a framework enabling SystemC-based virtual platforms to interact with external simulators via the FMI standard, allowing for realistic and integrated co-simulation. This facilitates thorough and early software testing even before physical hardware is available, streamlining development and certification workflows.


<details>
  <summary>Details</summary>
Motivation: As system complexity increases, comprehensive testing and virtual prototyping become more important. Existing simulation tools are fragmented and do not natively integrate, especially SystemC-based virtual platforms (VPs), which lack native support for the Functional Mock-up Interface (FMI) standard. This hinders the ability to co-simulate hardware/software systems with realistic external inputs.

Method: The authors propose a new framework that enables control and interaction between SystemC-based VPs and external simulation tools via the FMI standard. They demonstrate this with a case study where a SystemC-simulated temperature sensor receives real-time values from an external tool through FMI, without modifying the target software.

Result: The framework successfully enables SystemC-based VPs to receive realistic environmental data like temperature or velocity from external simulation tools. This allows for more extensive and earlier software testing and verification, including compliance with standards like ISO 26262 before the actual hardware is available.

Conclusion: Integrating SystemC-based virtual platforms with external simulators via FMI enhances virtual prototyping, enabling earlier and more realistic software testing. This approach can speed up development cycles and regulatory certification processes by allowing comprehensive pre-hardware software testing.

Abstract: As systems become more complex, the demand for thorough testing and virtual
prototyping grows. To simulate whole systems, multiple tools are usually needed
to cover different parts. These parts include the hardware of a system and the
environment with which the system interacts. The Functional Mock-up Interface
(FMI) standard for co-simulation can be used to connect these tools.
  The control part of modern systems is usually a computing unit, such as a
System-on-a-Chip (SoC) or Microcontroller Unit (MCU), which executes software
from a connected memory and interacts with peripherals. To develop software
without requiring access to physical hardware, full-system simulators, the
so-called Virtual Platforms (VPs), are commonly used. The IEEE-standardized
framework for VP development is SystemC TLM. SystemC provides interfaces and
concepts that enable modular design and model exchange. However, SystemC lacks
native FMI support, which limits the integration into broader co-simulation
environments.
  This paper presents a novel framework to control and interact with
SystemC-based VPs using the FMI. We present a case study showing how a
simulated temperature sensor in a SystemC simulation can obtain temperature
values from an external tool via FMI. This approach allows the unmodified
target software to run on the VP and receive realistic environmental input data
such as temperature, velocity, or acceleration values from other tools. Thus,
extensive software testing and verification is enabled. By having tests ready
and the software pre-tested using a VP once the physical hardware is available,
certifications like ISO 26262 can be done earlier.

</details>


### [17] [Automated Code Review Using Large Language Models with Symbolic Reasoning](https://arxiv.org/abs/2507.18476)
*Busra Icoz,Goksel Biricik*

Main category: cs.SE

TL;DR: The paper introduces a hybrid approach that combines symbolic reasoning and LLMs to automate code review, demonstrating improved accuracy and efficiency over existing models.


<details>
  <summary>Details</summary>
Motivation: Manual code review is subjective and time consuming, and while code review is well suited for automation, current AI approaches, including LLMs, lack sufficient logical reasoning to fully automate the process.

Method: The authors propose a hybrid approach that integrates symbolic reasoning techniques with Large Language Models (LLMs) to automate code review. They test this approach using the CodexGlue dataset and compare several models (CodeT5, CodeBERT, and GraphCodeBERT) to evaluate the effectiveness of the proposed integration.

Result: The results indicate that combining symbolic reasoning and prompting techniques with LLMs improves both the accuracy and efficiency of automated code review.

Conclusion: Integrating symbolic reasoning with LLMs is an effective way to enhance automated code review, surpassing the capabilities of LLMs alone in terms of accuracy and efficiency.

Abstract: Code review is one of the key processes in the software development lifecycle
and is essential to maintain code quality. However, manual code review is
subjective and time consuming. Given its rule-based nature, code review is well
suited for automation. In recent years, significant efforts have been made to
automate this process with the help of artificial intelligence. Recent
developments in Large Language Models (LLMs) have also emerged as a promising
tool in this area, but these models often lack the logical reasoning
capabilities needed to fully understand and evaluate code. To overcome this
limitation, this study proposes a hybrid approach that integrates symbolic
reasoning techniques with LLMs to automate the code review process. We tested
our approach using the CodexGlue dataset, comparing several models, including
CodeT5, CodeBERT, and GraphCodeBERT, to assess the effectiveness of combining
symbolic reasoning and prompting techniques with LLMs. Our results show that
this approach improves the accuracy and efficiency of automated code review.

</details>


### [18] [A Deep Dive into Retrieval-Augmented Generation for Code Completion: Experience on WeChat](https://arxiv.org/abs/2507.18515)
*Zezhou Yang,Ting Peng,Cuiyun Gao,Chaozheng Wang,Hailiang Huang,Yuetang Deng*

Main category: cs.SE

TL;DR: The paper finds that advanced RAG methods (combining lexical and semantic search) significantly improve code completion in large, closed-source codebases, and are validated as useful by industry developers.


<details>
  <summary>Details</summary>
Motivation: The motivation of this paper is to address the unexplored challenges of applying retrieval-augmented generation (RAG) methods for code completion within industrial-scale, closed-source codebases, where potential distribution shifts from open-source environments may limit the effectiveness of existing techniques.

Method: The authors conducted an empirical study of widely-used RAG methods, specifically identifier-based RAG and similarity-based RAG, on the large proprietary codebase of WeChat. They evaluated 26 open-source LLMs (ranging from 0.5B to 671B parameters) and tested different retrieval techniques for similarity-based RAG, including lexical (BM25) and semantic (GTE-Qwen) retrieval, as well as their combination. They also conducted a developer survey to assess practical usefulness.

Result: Both RAG methods are effective in closed-source repositories, with similarity-based RAG outperforming identifier-based RAG. Advanced retrieval techniques improve the effectiveness of similarity-based RAG, especially BM25 for lexical and GTE-Qwen for semantic retrieval. The combination of lexical and semantic retrieval produces the best results owing to their complementary advantages. Developer feedback also supports the usefulness of RAG methods in practice.

Conclusion: Retrieval-augmented generation (RAG) methods, especially when combining advanced lexical and semantic retrieval techniques, significantly enhance code completion performance for large-scale, closed-source codebases like WeChat. These methods are validated as practical tools for real-world developers, bridging the gap between open-source research and proprietary software engineering needs.

Abstract: Code completion, a crucial task in software engineering that enhances
developer productivity, has seen substantial improvements with the rapid
advancement of large language models (LLMs). In recent years,
retrieval-augmented generation (RAG) has emerged as a promising method to
enhance the code completion capabilities of LLMs, which leverages relevant
context from codebases without requiring model retraining. While existing
studies have demonstrated the effectiveness of RAG on public repositories and
benchmarks, the potential distribution shift between open-source and
closed-source codebases presents unique challenges that remain unexplored. To
mitigate the gap, we conduct an empirical study to investigate the performance
of widely-used RAG methods for code completion in the industrial-scale codebase
of WeChat, one of the largest proprietary software systems. Specifically, we
extensively explore two main types of RAG methods, namely identifier-based RAG
and similarity-based RAG, across 26 open-source LLMs ranging from 0.5B to 671B
parameters. For a more comprehensive analysis, we employ different retrieval
techniques for similarity-based RAG, including lexical and semantic retrieval.
Based on 1,669 internal repositories, we achieve several key findings: (1) both
RAG methods demonstrate effectiveness in closed-source repositories, with
similarity-based RAG showing superior performance, (2) the effectiveness of
similarity-based RAG improves with more advanced retrieval techniques, where
BM25 (lexical retrieval) and GTE-Qwen (semantic retrieval) achieve superior
performance, and (3) the combination of lexical and semantic retrieval
techniques yields optimal results, demonstrating complementary strengths.
Furthermore, we conduct a developer survey to validate the practical utility of
RAG methods in real-world development environments.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [19] [Higher-Order Behavioural Conformances via Fibrations](https://arxiv.org/abs/2507.18509)
*Henning Urbat*

Main category: cs.PL

TL;DR: This paper presents a unified categorical framework for Howe's method, enabling generalized, sound proofs of congruence for behavioral equivalence and distances in higher-order (including probabilistic) languages.


<details>
  <summary>Details</summary>
Motivation: Coinduction is crucial for proving behavioral equivalence in higher-order programming languages, especially as these languages gain quantitative features like probabilities. Existing proof techniques like Howe's method are complex and must be tailored to each specific language and behavioral conformance notion. The paper seeks a more uniform, general approach to simplify and standardize these proofs.

Method: The authors introduce a categorical framework for Howe's method, based on two layers: (1) abstract higher-order specifications (AHOS) for modeling the operational semantics of languages, and (2) modeling behavioral conformances using fibrations over the base category of AHOS. This structure allows the approach to apply across various languages and types of behavioral conformance.

Result: The paper establishes a fundamental congruence theorem: given natural assumptions about the categorical structures and operational semantics, the greatest behavioral conformance (such as bisimilarity or behavioral distance) in an AHOS-modeled operational semantics forms a congruence. The theory is demonstrated by showing congruence results for bisimilarity and behavioral pseudometrics in probabilistic higher-order languages.

Conclusion: The proposed categorical approach generalizes and abstracts Howe's method, offering a sound, uniform process for proving congruence of behavioral conformances in a wide range of higher-order languages, including those with probabilistic features.

Abstract: Coinduction is a widely used technique for establishing behavioural
equivalence of programs in higher-order languages. In recent years, the rise of
languages with quantitative (e.g.~probabilistic) features has led to extensions
of coinductive methods to more refined types of behavioural conformances, most
notably notions of behavioural distance. To guarantee soundness of coinductive
reasoning, one needs to show that the behavioural conformance at hand forms a
program congruence, i.e. it is suitably compatible with the operations of the
language. This is usually achieved by a complex proof technique known as
\emph{Howe's method}, which needs to be carefully adapted to both the specific
language and the targeted notion of behavioural conformance. We develop a
uniform categorical approach to Howe's method that features two orthogonal
dimensions of abstraction: (1) the underlying higher-order language is modelled
by an \emph{abstract higher-order specification} (AHOS), a novel and very
general categorical account of operational semantics, and (2) notions of
behavioural conformance (such as relations or metrics) are modelled via
fibrations over the base category of an AHOS. Our main result is a fundamental
congruence theorem at this level of generality: Under natural conditions on the
categorical ingredients and the operational rules of a language modelled by an
AHOS, the greatest behavioural (bi)conformance on its operational model forms a
congruence. We illustrate our theory by deriving congruence of bisimilarity and
behavioural pseudometrics for probabilistic higher-order languages.

</details>
